<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Wiki Snagger
      </h1>
      <p>
        I'm looking for a way to take the html generated by any wiki and copying it into a local folder.  This should be helpful when trying to use <a href="WikiServer.html">WikiServer</a> to create html which can then be distributed to others, or uploaded into a web folder.
      </p>
      <p>
        Have you tried any of these?  Do you know a better way?...
      </p>
      <p>
        A product called "Site Snagger" is featured in a tutorial by PC Magazine - <a href="http://www.pcmag.com/article2/0,4149,35556,00.asp">http://www.pcmag.com/article2/0,4149,35556,00.asp</a>
      </p>
      <p>
        A product called "Page Sucker" is profiled here - <a href="http://www.downloadfreetrial.com/internet/inte12308.html">http://www.downloadfreetrial.com/internet/inte12308.html</a>
      </p>
      <p>
        A product called "Web Copier" is featured in a tutorial at download.com - <a href="http://download.com.com/1200-2001-5086518.html">http://download.com.com/1200-2001-5086518.html</a>
      </p>
      <hr/>
      <p>
        It seems that a review of utilities in this category is here - <a href="http://www.webattack.com/shareware/downloader/swoffline.html">http://www.webattack.com/shareware/downloader/swoffline.html</a>
      </p>
      <hr/>
      <p>
        Plucker is an excellent open-source choice, particularly for PDA's.
      </p>
      <hr/>
      <p>
        The canonical utility to do this (and a lot more) on Linux systems is 'wget'; it's both gratis and libre and available at <a href="http://www.gnu.org/software/wget/.">http://www.gnu.org/software/wget/.</a>  There are also ports to other systems, including <a href="MicrosoftWindows.html">MicrosoftWindows</a>.
      </p>
      <hr/>
      <p>
        Typing ctrl-s in your browser is adequate in most cases. The above products tend to assume you need local copies of referenced pictures, etc., which you probably wouldn't in the case of wiki pages.
      </p>
      <p>
        <em>no no... that won't do at all... we're talking whole wikis... not just pages within a wiki</em>
      </p>
      <hr/>
      <p>
        Here's a silly idea I had. It's a completely different way of "using <a href="WikiServer.html">WikiServer</a> to create html which can then be distributed to others".
      </p>
      <ul>
        <li>
           write the part of the wiki that converts from "plain text" to "html" in <a href="JavaScript.html">JavaScript</a>.
        </li>
        <li>
           Distribute the raw "plain text" files.
        </li>
        <li>
           Somehow get the browser your audience uses to run that <a href="JavaScript.html">JavaScript</a> so they see nicely formatted HTML.
        </li>
      </ul>
      <p>
        Possible implementation routes:
      </p>
      <ul>
        <li>
           <strong>no frames</strong> Rename each .txt file to .html, escape any <> brackets, and add just enough HTML (a header, a footer, and a reference to the .jsp translation script).
        </li>
        <li>
           <strong>Keep the .txt files pure.</strong> Only 1 html file. A menu (left frame) of all the .txt files. Each time the user clicks on something on the menu, that .txt file is loaded (into an invisible frame), then use the <a href="JavaScript.html">JavaScript</a> to translate to HTML and display (right frame).
        </li>
      </ul>
      <hr/>
    </div>
  </body>
</html>