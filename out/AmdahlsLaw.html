<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Amdahls Law
      </h1>
      <p>
        Proposed in 1967, Amdahls' Law examines the theoretical maximum speedup obtained by using parallel processing.
      </p>
      <ul>
        <li>
           <a href="GeneAmdahl.html">GeneAmdahl</a>, "Validity of the Single Processor Approach to Achieving Large-Scale Computing Capabilities", AFIPS Conference Proceedings, (30), pp. 483-485, 1967
        </li>
      </ul>
      <p>
        If <em>N</em> is the number of processors, <em>s</em> is the time spent by a processor on serial part of a program, and <em>p</em> is the time spent by a processor on a parallel part of a program, then the maximum possible speedup is given by:
      </p>
      <ul>
        <li>
           <em>(s+p) / (s+p/N)</em>
        </li>
      </ul>
      <p>
        which simplifies (by setting <em>s+p=1</em>) to
      </p>
      <ul>
        <li>
           <em>1 / (s+p/N)</em> or <em>N / (sN+p)</em>
        </li>
      </ul>
      <p>
        This "Law" has been re-evaluated since and its underlying assumptions challenged. <a href="TheInterestedReader.html">TheInterestedReader</a> might choose to look at
      </p>
      <ul>
        <li>
           <a href="http://www.scl.ameslab.gov/Publications/AmdahlsLaw/Amdahls.html">http://www.scl.ameslab.gov/Publications/AmdahlsLaw/Amdahls.html</a>
        </li>
        <li>
           <a href="http://www.cis.temple.edu/~shi/docs/amdahl/amdahl.html">http://www.cis.temple.edu/~shi/docs/amdahl/amdahl.html</a>
        </li>
      </ul>
      <hr/>
      <p>
        Although we should point out that Gustavson's Law which modifies Amdahl's Law only applies in somewhat exotic circumstances such as massively parallel systems rather than just ordinary clustering.
      </p>
      <hr/>
      <p>
        The section below was added by Juan Jose Arrieta-Camacho (<a href="http://hysteria.cheme.cmu.edu)">http://hysteria.cheme.cmu.edu)</a> based on Steinar Hauan's (www.andrew.cmu.edu/~steinhau) lecture notes on High Performance Computing
      </p>
      <p>
        Amdahl's Law:
        If <em>ts</em> is the run time and <em>f</em> its parallelizable fraction, with <em>n</em> CPUs, the total time <em>tt</em> becomes:
      </p>
      <ul>
        <li>
           <em>tt=f*ts+(1-f)*ts/n</em>
        </li>
      </ul>
      <p>
        assuming infinite amount of processors and perfect communication (i.e. no loss of speed due to comunication time), the speedup factor <em>S(n)</em>(ratio of serial to parallel times, <em>ts/tp</em>) will be increased AT MOST:
      </p>
      <code>
        <em>  ts               n           1</em>\lim<em>S(n) =</em><br/>
        ----------------- = ----------- =  ---<em>\</em>s-->inf<br/>
        f*ts+(1-s)*tp/n     1+(n-1)*f      f<em></em><br/>
      </code>
      <hr/>
      <p>
        "Amdahl's Law -- Simplified":
      </p>
      <ul>
        <li>
           "Each component of a computer system contributes delay to the system. If you make a single component of the system infinitely fast... system throughput will still exhibit the combined delays of the other components"
        </li>
      </ul>
      <p>
        -- <a href="GeneAmdahl.html">GeneAmdahl</a> - one of the creators of IBM System 360 Architecture
      </p>
      <p>
        ...which also has bearing on optimizing software.
      </p>
      <hr/>
      <p>
        <a href="CategoryOptimization.html">CategoryOptimization</a>
      </p>
    </div>
  </body>
</html>