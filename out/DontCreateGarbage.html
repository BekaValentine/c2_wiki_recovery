<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Dont Create Garbage
      </h1>
      <p>
        Category: <a href="JavaIdioms.html">JavaIdioms</a>
      </p>
      <p>
        This is probably an Anti<em></em><a href="JavaIdiom.html">JavaIdiom</a>. It should really be called DontNeedlesslyCopyData or ChooseTheBestAlgorithm, neither of which are Java-specific.
      </p>
      <hr/>
      <p>
        So performance is an issue in your <a href="JavaLanguage.html">JavaLanguage</a> program? Check for temporary objects which might take time from <a href="GarbageCollection.html">GarbageCollection</a>.
      </p>
      <p>
        <em>Negative Example</em>
      </p>
      <code>
        String data[100] = { /* 100 strings */ }; <br/>
      </code>
      <code>
        String create_report(String[] data) {<br/>
        String result = "";<br/>
        for(int i = 0; i < data.length, i++) {<br/>
        result += data[i];<br/>
        }<br/>
        return result;<br/>
        }<br/>
      </code>
      <p>
        Here the code <em>result += data[i];</em> creates a new <em>String</em> instance every time the code is executed. So there are 100 objects created in the loop, of which only the last one is of interest and returned to the caller. The remaining 99, plus the initial result object are subject to <a href="GarbageCollection.html">GarbageCollection</a>. A <a href="SignalToNoiseRatio.html">SignalToNoiseRatio</a> of 1/100 in the above example.
      </p>
      <p>
        For the given example, the intermediate objects can be avoided by using String<strong>'Buffer. Other garbage-creating loops require more creative work to fix them.</strong>
      </p>
      <p>
        <em>Positive Example</em>
      </p>
      <code>
        String data[100] = { /* 100 strings */ };<br/>
      </code>
      <code>
        String create_report(String[] data) {<br/>
        // Still not fast enough ? a char array can be used ;-)<br/>
        <a href="StringBuffer.html">StringBuffer</a> result = new <a href="StringBuffer.html">StringBuffer</a>(totalNumOfChars(data));<br/>
        for(int i = 0; i < data.length, i++) {<br/>
        result.append(data[i]);<br/>
        }<br/>
        return new result.toString();<br/>
        }<br/>
      </code>
      <code>
        // show how ridiculous this can become:<br/>
        // when using this method the internal size of the <a href="StringBuffer.html">StringBuffer</a> char array can be allocated once.<br/>
        int totalNumOfChars(String[] data) {<br/>
        int total = 0;<br/>
        for(int i=0; i < data.length; i++) {<br/>
        total += data[i].length();<br/>
        }<br/>
        return total;<br/>
        }<br/>
      </code>
      <hr/>
      <p>
        In <a href="LispLanguage.html">LispLanguage</a> parlance: don't <em>cons</em> too much (<em>cons</em> is the Lisp built-in procedure that allocates a new pair). The typical way to avoid too much <em>cons</em>-ing is to use mutation instead (e.g., Java's String<strong>'Buffer can be mutated in-place, whereas String cannot).</strong>
      </p>
      <p>
        This is not <em>always</em> better; some generational <a href="GarbageCollector.html">GarbageCollector</a> algorithms
        rely on a "write barrier". Breaking this barrier (by assignment) can be very
        costly, more costly than the memory allocation that you're trying to optimize away.
      </p>
      <p>
        -- <a href="StephanHouben.html">StephanHouben</a>
      </p>
      <p>
        The time taken by the <a href="GarbageCollector.html">GarbageCollector</a> is proportional to the number of <em>live</em> objects, not to the amount of garbage. The generational garbage collector in the <a href="HotSpotVm.html">HotSpotVm</a> allocates new objects in a "nursery"; allocating a new object or collecting dead objects in the nursery involves only a couple of <a href="PointerArithmetic.html">PointerArithmetic</a> operations. Live objects are moved out of the nursery if they are still alive when it is collected.
      </p>
      <p>
        <em>The above is not always true in my experience. We do have an algorithm that does a lot of String creation. These objects do survive and you run into full </em><a href="GarbageCollection.html">GarbageCollection</a> more often, <a href="HotSpot.html">HotSpot</a> or no <a href="HotSpot.html">HotSpot</a>.<em></em>
      </p>
      <p>
        Creating garbage will affect performance mainly if <a href="ThrowawayObject.html">ThrowawayObject</a><strong>'s used within an inner loop have time-consuming constructors, which is not often the case.</strong>
      </p>
      <hr/>
      <p>
        The biggest problem with that code was not creating garbage, but running in quadratic time. It would still take quadratic time even with a smart allocator that reused the garbage immediately. This is like comparing an exponential-time recursive algorithm for a <a href="FibonacciSequence.html">FibonacciSequence</a> to a linear-time iterative one, and then concluding that recursion is slow.
      </p>
      <p>
        <em>See </em><a href="RulesOfOptimization.html">RulesOfOptimization</a> rule 1<em></em>
      </p>
      <p>
        <em>Explain, please, why the code should run in quadratic time.</em>
      </p>
      <p>
        The overhead is caused by <em>data copying</em> not by <a href="GarbageCollection.html">GarbageCollection</a>. In the first example, every time the the loop appends strings, it concatenates two strings to create a new string, copying the data of both strings into the array of the new string. Concatenating two strings is O(N), where N is the length of the first string <em>or</em> the total length of both strings, depending on how you implement your strings (with <a href="LinkedList.html">LinkedList</a>s or vectors). So if you have N strings, you end up running in O(1+2+3+...+N) = O(N^2) time.
      </p>
      <p>
        The StringBuffer class, on the other hand, writes data into an array which doubles in size whenever it runs out of space. The complexity of data copying involved in growing the array is O(N) in total (1+2+4+8+...+N<em>ish</em> = O(N)). The complexity of copying the strings into the array is O(N). Therefore, the complexity of the algorithm that uses the StringBuffer is also O(N).
      </p>
      <p>
        This simple complexity analysis is something every programmer should be able to do.
      </p>
      <p>
        The cost of += is indeed O(N^2), but you are over generous on your assessment of <a href="StringBuffer.html">StringBuffer</a>. It is not linear. It is O(lgN N), which is still better than O(N^2), but not as good as O(N).  To see this, note that there are lgN data copying occurrences with a maximum cost of N<em>ish</em>. If you don't believe me, try to find a constant c such that (1+2+4+8+...+N<em>ish</em>) <= cN for all N.
      </p>
      <p>
        <em>eh? N</em>ish<em> is less than 2*N isn't it? Then the sum is <= 2N + N + N/2 + ... +1 <= 4N. lgN operations with a maximum cost of N each does not necessarily make </em>NlgN.<em></em>
      </p>
      <p>
        Note that if you have a <a href="LinkedList.html">LinkedList</a> implementation of strings, a solution is to concatenate the strings in backward order, i.e., loop from 100 to 1 and prepend data[i] at every step. Provided that the data[i] strings are of bounded length, this gives you linear-time complexity.
      </p>
      <p>
        If you are a <a href="CeeLanguage.html">CeeLanguage</a> programmer, use an array which you mutate, and every time you run out of space, realloc() the array with a <em>doubled</em> size, just as the String<strong>'Buffer does. This can be shown to be, both in space and in time, as least as efficient as the </strong><a href="LinkedList.html">LinkedList</a> solution.  
      </p>
      <p>
        If you are a <a href="CeePlusPlus.html">CeePlusPlus</a> programmer, you can use a std::string in the same manner as a Java String<strong>'Buffer, because std::strings are mutable, and should grow using an O(N) algorithm like the one above.</strong>
      </p>
      <p>
        (As an aside, one of my <a href="HeroicDebugging.html">HeroicDebugging</a> stories involved working out why one of our <a href="MicrosoftWindows.html">MicrosoftWindows</a> programs ran ridiculously slowly. I eventually discovered that the stringstream implementation in Microsoft's standard <a href="CeePlusPlus.html">CeePlusPlus</a> library grew the buffer by <em>a single character</em> when it ran out of space. This gave string concatenation algorithms O(N*N*N) complexity!
      </p>
      <p>
        <em>No, a </em><a href="CeeLanguage.html">CeeLanguage</a> programmer (I'm one) would first calculate the total needed array size, then do one malloc to get a correctly sized memory block and then fill it with the strings. And he would do the same in <a href="JavaLanguage.html">JavaLanguage</a>. No reallocation at all. -- <a href="HelmutLeitner.html">HelmutLeitner</a><em></em>
      </p>
      <p>
        <em>If one can predetermine the size of the array, one doesn't need any of the algorithms described on this page. Realloc, or copying into larger arrays, is needed when one </em>cannot<em> calculate the total array size required, e.g., when you are reading data from a network connection. -- </em><a href="NatPryce.html">NatPryce</a><em></em>
      </p>
      <p>
        Or, if calculating the array size is slow, reallocing can be more efficient. It's also less error prone.
      </p>
      <hr/>
      <p>
        I see this as an <a href="AntiPattern.html">AntiPattern</a>. Instead, I argue against <a href="PrematureOptimization.html">PrematureOptimization</a>.
      </p>
      <p>
        Instead:
      </p>
      <ol>
        <li>
           Write a <a href="UnitTest.html">UnitTest</a>.
        </li>
        <li>
           Write code that passes it (including code like the above Negative Example).
        </li>
        <li>
           Measure the actual performance of your code (the whole thing, not just Negative Example).
        </li>
        <li>
           Use your performance data to identify the bottleneck.
        </li>
        <li>
           <a href="RefactorMercilessly.html">RefactorMercilessly</a> to speed up the bottleneck(s), ensuring that each refactoring still passes your <a href="UnitTest.html">UnitTest</a>s.
        </li>
        <li>
           Loop (Measure, analyze, refactor) until you achieve the desired performance.
        </li>
      </ol>
      <p>
        The measured impact of storage management (storage allocation and deallocation) on performance is less than 5% on virtually all modern <a href="VirtualMachine.html">VirtualMachine</a>s (<a href="JavaVirtualMachine.html">JavaVirtualMachine</a> or <a href="SmalltalkLanguage.html">SmalltalkLanguage</a>). The code rot and resulting smell introduced by voodoo patterns such as <a href="DontCreateGarbage.html">DontCreateGarbage</a> usually harm, not help, performance. -- <a href="TomStambaugh.html">TomStambaugh</a>
      </p>
      <p>
        If only that 5% matched my measurements. If you're not careful to avoid creating garbage, <a href="GarbageCollection.html">GarbageCollection</a> can easily take most of your CPU cycles. Eliminating object creation in a real, medium-sized project improved its performance by a factor of nearly 10. Some idioms don't count as optimization: they're just good practice. -- <a href="JamesDennett.html">JamesDennett</a>
      </p>
      <p>
        <em>What </em><a href="JavaVirtualMachine.html">JavaVirtualMachine</a> are you using? My experience with <a href="SunMicrosystems.html">SunMicrosystems</a>' VM sans <a href="HotSpot.html">HotSpot</a> may mirror yours, but <a href="HotSpot.html">HotSpot</a> improves matters quite a bit. <a href="IbmCorporation.html">IbmCorporation</a>'s <a href="VirtualMachine.html">VirtualMachine</a>, is substantially better than <a href="HotSpot.html">HotSpot</a> for a large number of object create and destroy operations. -- <a href="MarkAddleman.html">MarkAddleman</a><em></em>
      </p>
      <ol>
        <li>
           In matters of performance, you should not ask how many objects will be created but how long will they stick around. The smaller the scope the faster they can be collected.
        </li>
        <li>
           Most of us are developing <a href="DataBase.html">DataBase</a> <a href="WebApplication.html">WebApplication</a>s. You can calculate the nth premier number before a simple query returns with almost no performance impact. I have actually done this kind of test in a <a href="JavaTwoEnterpriseEdition.html">JavaTwoEnterpriseEdition</a> application (web & <a href="EnterpriseJavaBeans.html">EnterpriseJavaBeans</a> in same <a href="JavaVirtualMachine.html">JavaVirtualMachine</a>). My conclusion was that database queries take 75% of the execution time. Yes, business logic + html transfer + bloated ejb executes in 25% of the time.
        </li>
        <li>
           If improvement of StringArray to String conversion is still an issue, it's better to avoid this kind of mismatch. (High level performance optimization is almost always faster/better than low level.) Talk string arrays or string (or something else) but not say both. Still too slow? Use char arrays (or on the stream).
        </li>
      </ol>
      <p>
        -- PhilipVanBogaert
      </p>
      <hr/>
      <p>
        <em>I see this as an </em><a href="AntiPattern.html">AntiPattern</a>. Instead, I argue against <a href="PrematureOptimization.html">PrematureOptimization</a>.<em></em>
      </p>
      <p>
        This is only an <a href="AntiPattern.html">AntiPattern</a> <em>if</em> you're doing it as a <a href="PrematureOptimization.html">PrematureOptimization</a>. If you <em>have</em> profiled your code and observed that <a href="GarbageCollection.html">GarbageCollection</a> overhead is an issue, <a href="DontCreateGarbage.html">DontCreateGarbage</a> is a perfectly appropriate idiom to apply.
      </p>
      <p>
        <em>If cows walk and pigs fly, it might be time to rethink biology. If storage management is taking a significant share of your overall performance, then something else is dreadfully wrong. In any case, it sounds like we agree that one should never begin a design with </em><a href="DontCreateGarbage.html">DontCreateGarbage</a> in mind.<em></em>
      </p>
      <p>
        Agreed. But it is also okay to have <a href="DontCreateGarbage.html">DontCreateGarbage</a> in mind as a design progresses. You suggest above that we should "Loop (Measure, analyze, refactor) until you achieve the desired performance." <a href="DontCreateGarbage.html">DontCreateGarbage</a> can be a useful and appropriate pattern in the context of the "analyze, refactor" part. I think I misspoke above in talking about "observing that GC overhead is an issue". It's not the <a href="GarbageCollection.html">GarbageCollection</a> overhead that you're fighting against (the roughly 5%, as you say); it's the fact that you're creating, using, and throwing away, say, O(N^2) garbage instead of O(N). It's perfectly fine to start with a simple solution that uses all that O(N^2) space (and therefore O(N^2) time). But when that solution becomes inadequate performance-wise, one useful tool in the MatureOptimization toolbox is to know where large amounts of storage are being used and discarded, and to think about how that can be eliminated. This is certainly a common pattern in the <a href="LispLanguage.html">LispLanguage</a> community (as <a href="StephanHouben.html">StephanHouben</a> states above, "Don't cons too much").
      </p>
      <p>
        <em>If you do *anything* O(N^2) instead of O(N) times, you have a problem that you may have to solve. If you are constrained by space, then the problem is the *space* you're using, whether garbage or not. If you do anything other than create and destroy the space (and presumably you do, otherwise you wouldn't create it) then the time you spend is probably dominated by the other operations. In either case, it seems to me that the problem, when it occurs, is the unnecessary O(N^2) vs O(N) repetition, not the garbage.</em>
      </p>
      <p>
        <em>So perhaps we can agree to suggest that </em>ReduceLoopCounts and RefactorToUseLessSpace are sometimes useful performance optimizations, in the context of a performance benchmark that indicates a problem.<em></em>
      </p>
      <p>
        Yes. Maybe one way of looking at it is that <a href="DontCreateGarbage.html">DontCreateGarbage</a> is an interesting special case of ReduceLoopCounts, where the excess order of magnitude in speed is being spent creating memory that will almost immediately be thrown away. The unfortunate fact is that these extraneous loop counts are often hidden underneath library abstraction barriers. So the programmer is forced to pop a level off the abstraction stack in order to see the problem and fix it. The Java String-concatenate versus <a href="StringBuffer.html">StringBuffer</a>-append example (mentioned above) is a case in point.
      </p>
      <hr/>
      <p>
        Not all optimization is premature - String concatenation is very expensive in Java, because of design decisions made to support other aspects of strings. .NET has the same issue, as does Python. This is well known and the use of other techniques to join strings (like Javas <a href="StringBuffer.html">StringBuffer</a>) are normal programming practice, rather than <a href="PrematureOptimization.html">PrematureOptimization</a>. I don't think the mantra of <a href="PrematureOptimization.html">PrematureOptimization</a> is an excuse for being stupid about something. 
      </p>
      <hr/>
      <p>
        <a href="CategoryJava.html">CategoryJava</a>
      </p>
    </div>
  </body>
</html>