<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Clifford Algebra Inverse Discussion
      </h1>
      <p>
        <em></em><a href="CliffordAlgebraInverseDiscussion.html">CliffordAlgebraInverseDiscussion</a> is for the discussion of the inversion of <a href="CliffordAlgebra.html">CliffordAlgebra</a> objects, which has been developed by <a href="DougMerritt.html">DougMerritt</a>, <a href="JohnFletcher.html">JohnFletcher</a> and others. As various topics are resolved it will become CliffordAlgebraInverse.<em> -- </em><a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <hr/>
      <p>
        Your page <a href="CliffordAlgebraIdempotents.html">CliffordAlgebraIdempotents</a> seems to suggest use of the binomial theorem for negative powers - but no justification is given. <em>See added material on </em><a href="CliffordAlgebraIdempotents.html">CliffordAlgebraIdempotents</a> and comments below.<em> -- </em><a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <p>
        <em>Good point. To phrase it a different way, it appears that invertible/non-invertible elements and questions of division algebras has not been addressed at all on the clifford algebra web pages, yet must be, prior to generalizing powers that way. -- Doug</em>
      </p>
      <p>
        That gets into a whole other area which addresses these points. <a href="CliffordAlgebra.html">CliffordAlgebra</a>s are isomorphic each to a matrix representation, which does not contain the geometric information. What it does mean is that any object is invertible unless the matrix is singular, which is the case for the idempotent objects. For all objects the characteristic polynomial of the matrix also applies to the Clifford object, and if the polynomial can be found, then the inversion can also be found. There is some reference to this in the Snygg paper I reference on <a href="CliffordAlgebraIdempotents.html">CliffordAlgebraIdempotents</a> and also some examples in this paper of mine, also from the AGACSE2001 conference. -- <a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <p>
        <a href="http://www.ceac.aston.ac.uk/research/staff/jpf/papers/paper24/index.php">http://www.ceac.aston.ac.uk/research/staff/jpf/papers/paper24/index.php</a>
      </p>
      <p>
        What of the fact that for a negative power, the binomial expansion isn't finite and needn't converge?
      </p>
      <p>
        <em>See </em><a href="CliffordAlgebraIdempotents.html">CliffordAlgebraIdempotents</a>. I do not know if the Snygg paper is on line.<em> -- </em><a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <p>
        I'm still not happy with this. Appealing to representations is indirect, and I would think of questionable rigor. The Snygg argument you present does not appear to prove the <strong>existence</strong> of e1^-1, nor does it appear to say anything about the existence of inverses of non-units. The whole question of what is invertible and what is not, approached directly rather through representations, seems to me to still be completely up in the air. -- <a href="DougMerritt.html">DougMerritt</a>
      </p>
      <p>
        <em>As I understand it the relevant definition of an inverse is that if there exists</em> <strong>a</strong> <em>and</em> <strong>b</strong> <em>such that</em>
      </p>
      <code>
        <strong>a b</strong> = 1<br/>
      </code>
      <p>
        <em>then each is the inverse of the other. In this case</em>
      </p>
      <code>
        <strong>e1 e1</strong> = 1<br/>
      </code>
      <p>
        <em>so that the inverse exists and is</em> <strong>e1</strong> <em>itself. Please explain what more you want.</em>
      </p>
      <p>
        <em>There is something about the general inverse on </em><a href="HestenesOerstedMedalLecture.html">HestenesOerstedMedalLecture</a> p.12 and 13.<em> </em>
      </p>
      <p>
        <em>I think that full</em> <strong>proof</strong> <em>is beyond what I have been expecting to provide in these pages. That needs a text book e.g. </em><a href="CliffordAlgebrasAndSpinors.html">CliffordAlgebrasAndSpinors</a>. I would have recommended a debate on rigor with Lounesto himself, but sadly he died several years ago. He was a great contributor and debator on news groups.<em> -- </em><a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <p>
        My point related specifically to using the binomial theorem as a starting point, as it needn't converge when applied to complex (or real) numbers for a negative (or non-integer) exponent.
      </p>
      <p>
        <em>Rereading what I had put on </em><a href="CliffordAlgebraIdempotents.html">CliffordAlgebraIdempotents</a>, I can see where you could see a direct implication, where what I mean was that this was the result. I hope that the way I have put it now makes this clear. Do you have a problem with the way that it is now?<em> -- </em><a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <p>
        <em>There are many cases in </em><a href="CliffordAlgebra.html">CliffordAlgebra</a> where series are truncated where they would not be in real algebra. In this case, the binomial theorem works differently for this pair of idempotent objects and coefficients, because they are the eigen solutions and eigenvalues of the characteristic polynomial of the object. All I am doing is quoting from the Snygg paper, which I was looking at last night and would have put some bits in from it, but the edit code was not working last night. Snygg shows that in general it is possible to break down any <a href="CliffordAlgebra.html">CliffordAlgebra</a> object apart from a scalar into a sum of terms. It is the fact that for a vector and some other similar objects the characteristic polynomial is quadratic with real roots and this means that the decomposition is very straightforward.<em> -- </em><a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <p>
        Your first mention of the binomial theorem uses it for a non-negative integer exponent, but you should make that explicit. For any other exponent, you can't use the word "theorem", because you haven't established or referenced a general binomial theorem. Similar problems could easily occur for other series.
      </p>
      <p>
        <em>I suggest that you contribute a page on the </em>BinomialTheorem. As far as I am concerned, BinomialTheorem is a phrase in common usage to cover the expansion of powers of a term, and it is the use of the word theorem which is a little unusual, as the simpler results can be established very easily. The point about the expression with the -1 power is that I do not use an expansion.<em> -- </em><a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <p>
        I wasn't criticizing the results but the non-exclusion of infinite series. I don't know a version of Taylor's theorem or the binomial theorem for <a href="CliffordAlgebra.html">CliffordAlgebra</a> except where the series is finite (i.e., where the theorem is a trivial identity). Infinite series can be a pain - for example, a Taylor series may converge to a different function from the one you used to generate it.
      </p>
      <p>
        <em>Thanks for that. That is interesting. My reference, which is Snygg, does not claim originality in this. He in turn references Hestenes, which is accessible here via </em><a href="HestenesOerstedMedalLecture.html">HestenesOerstedMedalLecture</a>. He also references Sobczyk. e.g.<em></em>
      </p>
      <p>
        G. Sobczyk, The missing spectral basis in algebra and number theory, <em>Amer. Math. Monthly</em> <strong>108</strong> (2001)
      </p>
      <p>
        <em>I think what tends to happen in </em><a href="CliffordAlgebra.html">CliffordAlgebra</a> is that the odd and even powers in a series will separate out, in the same way that<em></em>
      </p>
      <code>
        exp(<strong>i</strong>x) = cos(x) + <strong>i</strong>sin(x)<br/>
      </code>
      <p>
        <em>This will come up when I get to the even subalgebra in 3 dimensional Clifford Algebra. The infinite series turn out to be the familiar ones in the reals for which we have results. I have pondered the chicken and egg question about this and</em>
      </p>
      <code>
        exp(x) = 1 + x + x^2/2 etc<br/>
      </code>
      <p>
        <em>as to which result is fundamental, this series or the Taylor series, as they seem to me to be mutually deductible, which is not satisfactory. Can you enlighten me?</em>
      </p>
      <p>
        The expansion of exp(x) is a particular Taylor Series, but can be derived directly. Although you can select the even powers from any power series, doing so might affect convergence.
      </p>
      <p>
        <em>I think the ones that crop up in </em><a href="CliffordAlgebra.html">CliffordAlgebra</a> are cos, sin, cosh and sinh. I cannot think of anything else. I will keep a look out for anything else.<em> -- </em><a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <p>
        Those 4 are special cases of exp() over the complex with respectively non-negative spatial curvatures and negative spatial curvatures, so in the absence of a more precise criteria of what class of functions you're implicitly talking about, you have in fact of necessity covered everything.
      </p>
      <p>
        The exp() function is uniquely fundamental because it is uniquely the identity under differential/integral operators. That remains true regardless of the particular representation used for it, such as Taylor series. In other words, look for the function that is such an identity, and you can then derive a Taylor series or whatever you like as a representation of it.
      </p>
      <p>
        It turns out to be absolutely convergent, which is handy, but of course we know that we can't arbitrarily assume any kind of convergence for infinite series in general, which is the issue being raised above.
      </p>
      <p>
        It doesn't <strong>always</strong> matter; sometimes all we need to do is manipulate formal infinite series, in which case we don't need to worry about convergence -- but if you want to actually do computations, then you need to prove that the particular infinite series you're working with does in fact converge, since some will and some won't, and others will do so only conditionally, etc, etc.
      </p>
      <p>
        It wasn't clear to me that you (John) had any strong intention to work with infinite series in <a href="CliffordAlgebra.html">CliffordAlgebra</a>, anyway, so if not, the point raised disappears if you just throw in a disclaimer that you only mean to be talking about finite series.
      </p>
      <p>
        Note, however, that invertibility immediately implies infinite series unless one can prove otherwise, so we're back to that simple issue again, it hasn't entirely gone away yet. -- Doug
      </p>
      <p>
        <em>I had not set out to work with infinite series at all. It becomes an issue in that exponentials of bivectors are used as the representation of rotations in </em><a href="CliffordAlgebra.html">CliffordAlgebra</a> of 3 dimensions and more. On invertibility I am not sure what you are saying. Suppose for an object<em> </em>'a<strong> <em>I can find another object</em> </strong>b<strong> <em>such that their product is a scalar.</em></strong>
      </p>
      <code>
        <strong>a b</strong> = <em>m</em><br/>
      </code>
      <p>
        <em>The inversion of</em> <strong>a</strong> <em>is then</em>
      </p>
      <code>
        <strong>b</strong>/<em>m</em><br/>
      </code>
      <p>
        <em>If</em> <strong>a</strong> <em>and</em> <strong>b</strong> <em>are complex numbers then</em> <strong>b</strong> <em>needs to be the conjugate of</em> <strong>a</strong><em>. There are corresponding objects for </em><a href="CliffordAlgebra.html">CliffordAlgebra</a> vectors too.<em> -- </em><a href="JohnFletcher.html">JohnFletcher</a> 
      </p>
      <p>
        Ok...<strong>now</strong> suppose you cannnot find such an object. -- Doug
      </p>
      <p>
        <em>Suppose that I can instead find an object</em> <strong>b</strong> <em>such that the product of</em> <strong>a</strong> <em>and</em> <strong>b</strong> <em>gives a result</em> <strong>p</strong> <em>which is invertible using an object</em> <strong>q</strong><em>. Then we can invert</em> <strong>a</strong> <em>as well.</em>
      </p>
      <code>
        <strong>a b</strong> = <strong>p</strong><br/>
        <strong>p q</strong> = <em>m</em><br/>
        <strong>p</strong>^-1 = <strong>q</strong>/<em>m</em><br/>
        <strong>a</strong>^-1 <strong>p</strong>= <strong>b</strong><br/>
        <strong>a</strong>^-1 = <strong>b p</strong>^-1 = <strong>b q</strong>/<em>m</em><br/>
      </code>
      <p>
        <em>(For rigor on the next section please see </em><a href="CliffordAlgebrasAndSpinors.html">CliffordAlgebrasAndSpinors</a> chapter 8, but for the moment please consider this.)<em></em>
      </p>
      <p>
        <em>The key to this is clearly to find</em> <strong>b</strong><em>. I can do this, relying on understanding of the underlying matrix basis.  Suppose that the matrix representation of</em> <strong>a</strong> <em>is</em> <strong>A</strong><em>, and take the transpose of</em> <strong>A</strong> <em>to be</em> <strong>B</strong><em>, which will have a corresponding </em><a href="CliffordAlgebra.html">CliffordAlgebra</a> object<em> </em>'b<strong><em>. Then the product</em> </strong>AB<strong> <em>will be a symmetric matrix which is guaranteed to have real eigenvalues which will be positive or zero. Excluding the zero case (singular), these eigenvalues will provide the basis for the inversion of the product</em></strong>
      </p>
      <code>
        <strong>a b</strong> = <strong>p</strong><br/>
      </code>
      <p>
        <em>which is what is required. I am not sure if this covers every possible </em><a href="CliffordAlgebra.html">CliffordAlgebra</a> object, but it certainly widens the range over which the Snygg method is applicable. There remains the case where the matrix has multiplicity in its eigenvalues, which has been considered by Snygg. Also, there is no need at any stage to identify a particular matrix basis. The object<em> </em>'b<strong> <em>is a copy of</em> </strong>a<strong> <em>with some of the terms changed in sign. If all the basis vectors square to +1 then the sign changes are those of the</em> </strong>reversion<strong> <em>as defined in Clifford Algebra.</em></strong>
      </p>
      <p>
        [<em>Note to self: define</em> <strong>reversion</strong> <em>in </em><a href="CliffordAlgebraDetails.html">CliffordAlgebraDetails</a>. In the meantime reference <a href="CliffordAlgebrasAndSpinors.html">CliffordAlgebrasAndSpinors</a> p.14-15 for discussion of this for the 2D case.<em>] -- </em><a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <hr/>
      <p>
        You've written a lot of great material, here and on other pages, and I appreciate that.
      </p>
      <p>
        I'm afraid that I was not, however, very clear about my concern in the discussion thread on this page. As I understand it, a still-open issue (pedagogical, on this page) concerns division/invertibility, not in a complicated sense, but in a basic sense. A <a href="CliffordAlgebra.html">CliffordAlgebra</a> is not a full division algebra, unless I am very confused. Yet discussion mostly (but not entirely) <strong>sounds</strong> like we're dealing with a full division algebra. Some non-zero elements are invertible, others aren't. That's a really big deal, but I'm concerned that that basic concern has been glossed over. That's all. Sorry if it sounded like I was concerned about something more complicated.
      </p>
      <p>
        In that kind of basic-property axiomatic sense, I probably would next be concerned as to whether we have established (stated, proved, given as axiom, appeal to authority, whatever) whether there are separate right and left multiplications, or whether they are the same. Then there are norms...Etc. It's a bit of a nitpick at the application level, but important to establish somewhere along the line in the theoretical underpinnings. -- <a href="DougMerritt.html">DougMerritt</a>
      </p>
      <hr/>
      <p>
        I think you are correct to say that the general <a href="CliffordAlgebra.html">CliffordAlgebra</a> is not a division algebra. It contains within it three algebras which are division algebras, complex numbers, quaternions and octonions.  See <a href="CliffordAlgebrasAndSpinors.html">CliffordAlgebrasAndSpinors</a> p.300. -- <a href="JohnFletcher.html">JohnFletcher</a>
      </p>
      <hr/>
      <p>
        See also <a href="CliffordAlgebra.html">CliffordAlgebra</a>
      </p>
      <hr/>
      <p>
        <a href="CategoryMath.html">CategoryMath</a>
      </p>
    </div>
  </body>
</html>