<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Massively Parallel Processing
      </h1>
      <p>
        A system that has many processors (usually MPP systems start at 16 CPUs).  
      </p>
      <p>
        Typically, we have something called nodes, which usually have one to four CPUs, and some memory.  It is the presence of memory that set MPP apart from <a href="SymmetricMultiprocessing.html">SymmetricMultiprocessing</a>.  SMP has one set of memory for the whole system, whereas MPP doesn't.  This makes programming for MPP more difficult; it isn't that much different from programming a bunch of machines on a network to work together, which is actually how an increasing number of supercomputers are designed.  A large number of single or dual processor linux machines connected using a special super fast network (or at least a well laid out normal network).
        The <a href="ConnectionMachine.html">ConnectionMachine</a> Mark-I had 16384 processors, although it was designed to be expanded to 65536.
      </p>
      <p>
        The most successful MPP applications have been for problems that can be broken down into many separate, independent operations on vast quantities of data. In data mining, there is a need to perform multiple searches of a static database. In artificial intelligence, there is the need to analyze multiple alternatives, as in a chess game. Often MPP systems are structured as clusters of processors. Within each cluster the processors interact as in a SMP system. It is only between the clusters that messages are passed. Because operands may be addressed either via messages or via memory addresses, some MPP systems are called NUMA machines, for Non-Uniform Memory Addressing. 
      </p>
      <p>
        The cost of communications is fairly large, and the speed fairly low.  For this reason the search is always on to find algorithms that can run independently in lots of separate processors, only communicating occasionally. Google, for example, uses 1000s of cheap PCs rather than a special-purpose parallel machine.
      </p>
      <p>
        It's an interesting, although perhaps ultimately pointless, debate as to when 1000s of networked machines can be regarded as "a super-computer".
      </p>
      <hr/>
      <p>
        See <a href="ConcurrentProgramming.html">ConcurrentProgramming</a>, <a href="DistributedComputing.html">DistributedComputing</a>
      </p>
    </div>
  </body>
</html>