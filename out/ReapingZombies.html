<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Reaping Zombies
      </h1>
      <p>
        I've been running a version of wiki with the web server software built in. I based it on example code in my perl book. Lo and behold the cribbed code doesn't clean up after itself. It seems that for every fork() you should do a wait(), but in the server there isn't any convenient place to wait. My favorite unix expert, MikeZuhl, pointed out the oxymoronic wait-NOHANG, whose usage is not obvious. Mike suggested a while loop watching wait status. I found this prone to infinite looping and still unlikely to get the last zombie. I settled to an unrolled version of the most likely loop: <em>reap more than you sow</em>. Here's our continuing correspondence on the subject...
      </p>
      <hr/>
      <p>
        <strong>Ward:</strong>
      </p>
      <p>
        Here's my incremental reaper. A burst of activity can produce quite a number of zombies, which this will reap soon enough. Under light load, there tends to be one uncollected zombie at all times. I can't see how to reap it without delaying my accept, which I don't want to do.
      </p>
      <code>
        for(;;) {<br/>
        ($addr = accept(NS,S)) || die "accept: $!";<br/>
        if (($child = fork()) == O) {<br/>
        &service();<br/>
        }<br/>
        close(NS);<br/>
        waitpid(-1, $WNOHANG);<br/>
        waitpid(-1, $WNOHANG);<br/>
        }<br/>
      </code>
      <p>
        <strong>Mike:</strong>
      </p>
      <p>
        It's almost 2am and I may not be thinking right, but try this:
      </p>
      <code>
        for(;;) {<br/>
        ($addr = accept(NS,S)) || die "accept: $!";<br/>
        if (($child = fork()) == O) {   # main forks intermediate<br/>
        if (($child = fork()) == O) {   # which forks leaf<br/>
        &service();             # which does work<br/>
        }<br/>
        exit;                   # intermediate quits<br/>
        # (also leaf quits here)<br/>
        }<br/>
        close(NS);<br/>
        wait();         # clean up intermediate proc<br/>
        }<br/>
      </code>
      <p>
        The intermediate process spawns the service routine (with a pipe, socket, or whatever) and immediately exits. The leaf-node child now has no parent, so it gets inherited by the init process which is patient and waits for everything. The remaining wait() collects the short-lived intermediate process.
      </p>
      <p>
        <em>Mike - I found that you also need a setpgrp() call or the process will have its parent set to its grandparent.</em>
      </p>
      <p>
        <strong>Ward:</strong>
      </p>
      <p>
        Ahh. Yes, I remember this "double fork" being discussed back in the Purdue days. I just never made the connection because I'd never coded it myself. Is this standard operating practice?
      </p>
      <p>
        <strong>Mike:</strong>
      </p>
      <p>
        Well, you only really need it for dispatching daemons and you don't dispatch daemons very often, so the situation doesn't come up enough to really call it "standard operating practice". One sort of related thing that is SOP is to set the process group to the current PID, thus creating a new process group. That shields the process from keyboard interrupt without disabling interrupts. You do it for background processes, but it really doesn't apply to daemons.
      </p>
      <hr/>
      <p>
        High performance servers don't repeatedly fork processes. Instead, they keep a pool of pre-forked processes that they distribute work to as it arrives.
      </p>
      <p>
        DennisDeBruler points out in his PLoP I paper that really high performance servers don't mess with processes at all. -- <a href="WardCunningham.html">WardCunningham</a>
      </p>
      <hr/>
      <p>
        From the Solaris 2.4 signal() man page:
      </p>
      <ul>
        <li>
           If any of the above functions are used to set SIGCHLD's disposition to SIG_IGN, the calling process's child processes will not create zombie processes when they terminate (see exit(2)). If the calling process subsequently waits for its children, it blocks until all of its children terminate; it then returns a value of -1 with errno set to ECHILD (see wait(2), waitid(2)).
        </li>
      </ul>
      <p>
        -- <a href="MichaelLindner.html">MichaelLindner</a>
      </p>
      <hr/>
      <p>
        May I ask why forking processes is needed for a CGI app? I once wrote a wiki in PHP for the heck of it, and I never encountered a need to fork processes explicitly. Perhaps it was an efficiency-oriented decision? (I won't claim my version was optimized.)
      </p>
      <hr/>
      <p>
        <a href="CategoryWiki.html">CategoryWiki</a>
      </p>
    </div>
  </body>
</html>