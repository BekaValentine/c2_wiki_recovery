<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Manifest Typing Considered Good
      </h1>
      <p>
        Some time after the page was initially created, I realized that the title should read <strong>some manifest typing considered good</strong>. Of course, that would be too long and boring for a title, so I'll let the slight misnomer stay. This should be taken as a plea that current languages with <a href="TypeInference.html">TypeInference</a> have turned the design knob all the way to the other extreme, leading to some "<a href="BadEngineeringPropertiesOfFunctionalLanguages.html">BadEngineeringPropertiesOfFunctionalLanguages</a>" (to paraphrase Cardelli).
      </p>
      <hr/>
      <p>
        "Wouldn't you be delighted if your Fairy Godmother offered to wave her wand over your program to remove all its errors and only made the condition that you should write out and key in your whole program three times!  The way to shorten programs is to use procedures, not to omit vital declarative information." ~ <a href="CarHoare.html">CarHoare</a>, Turing Award Lecture
      </p>
      <hr/>
      <p>
        In a <a href="StaticTyping.html">StaticTyping</a> environment, people began to complain that <a href="ManifestTyping.html">ManifestTyping</a> is a "drag" on developer productivity and a cludge standing in the way of beautiful code and <a href="EconomyOfExpression.html">EconomyOfExpression</a>. And therefore we have one more step before somebody writes ManifestTypingConsideredHarmful ...
      </p>
      <p>
        Or is it? This page can be considered a pre-emptive strike.
      </p>
      <p>
        <em>Against code that doesn't use enough type declarations, or do you mean to attack languages that allow any type declarations to be omitted?</em>
      </p>
      <p>
        <strong>The historical argument</strong>
      </p>
      <p>
        The discussion started long time ago, and comes with <a href="DynamicTyping.html">DynamicTyping</a> advocates alleging that <a href="ManifestTyping.html">ManifestTyping</a> forces them to "say things which are not true" (that would be <a href="KentBeck.html">KentBeck</a>), or to put it in more general terms - "saying things (the manifest type that is) that are true now but maybe false later". 
      </p>
      <p>
        Some <a href="StaticTyping.html">StaticTyping</a> advocates then got really shamed into defensive mode. After all, how can one defend something that forces good folks into lying? Thus they took refuge into a "superior" feature of advanced programming languages like ML (StandardMl, <a href="ObjectiveCaml.html">ObjectiveCaml</a>), <a href="HaskellLanguage.html">HaskellLanguage</a>, <a href="CleanLanguage.html">CleanLanguage</a>, etc. - that being <a href="TypeInference.html">TypeInference</a>. And thanks to this wonderful feature it looks like you're not forced to say much at all in those languages. They almost look like dynamically typed source code to the reader that does not pay close attention. And from then onward, <a href="ManifestTyping.html">ManifestTyping</a> (ala mainstream industrial languages like <a href="CeePlusPlus.html">CeePlusPlus</a> and <a href="JavaLanguage.html">JavaLanguage</a>) has been looked on like the black sheep of the <a href="StaticTyping.html">StaticTyping</a> camp, while <a href="TypeInference.html">TypeInference</a> is the <a href="HolyGrail.html">HolyGrail</a>.
      </p>
      <p>
        <em>There are two features in these languages which let you say "less". Type inference is the lesser, letting you write down the same old programs, just without writing down a type for every declaration. (Taking as a sanity-saving given that no reasonable language requires a declared type for every expression, and every sub-expression of those expressions, and so on). Parametric polymorphism is the greater, letting expressions actually have types that don't require (or at least require many fewer) things that are not true. Consider a trivial apply function, apply f x = f x. This function requires only and just that x be a suitable argument for f, and all the languages you mention can express exactly that requirement, with a type something like "forall a, b : (a -> b) -> a -> b". In </em><a href="ObjectiveCaml.html">ObjectiveCaml</a> this sort of thing extends to the object system (<a href="ObjectiveCaml.html">ObjectiveCaml</a> is the only one of these language that really has an object system), with types meaning things like "a function taking two arguments, where the first is an object having at least a method called foo which can be applied to the second argument". It is of course a great help that with type inference it's not necessary to keep copying bits of these types all over the place, or in some cases to even bother figuring out these minimum requirements of your code yourself.<em></em>
      </p>
      <p>
        <em>Close, but not quite. </em><a href="TypeInference.html">TypeInference</a> has been around since the 70's (ML), and certainly isn't the result of anybody shaming anybody into anything.<em></em>
      </p>
      <ul>
        <li>
           Yes, <a href="TypeInference.html">TypeInference</a> has existed for a long time, but only very recently it has been argued that <a href="ManifestTyping.html">ManifestTyping</a> is bad and <a href="TypeInference.html">TypeInference</a> is the one true way to move static typing forward. This page tries to bring an alternate perspective. Every language researchers and their friends, and their PhD students, overwhelm us with ever so complex papers how to move <a href="TypeInference.html">TypeInference</a> forward in new languages or extensions of existing one (ML,Haskell, etc). This page tries to bring a modest engineering perspective about the real trade-offs, and about whether <a href="ManifestTyping.html">ManifestTyping</a> is such a big problem after all.
        </li>
      </ul>
      <p>
        <strong>Why things are not as simple as they appear to be.</strong>
      </p>
      <p>
        Well, it turns out that if we take a closer look (in the tradition of <a href="BadEngineeringPropertiesOfOoLanguages.html">BadEngineeringPropertiesOfOoLanguages</a>) languages with <a href="TypeInference.html">TypeInference</a> have this glitzy feature that you do not have to declare the type of an identifier while the language itself will infer the most general type for it, but on the other hand they suffer from some not so good engineering properties, especially with regards to their <a href="EconomyOfExpression.html">EconomyOfExpression</a> and <a href="EconomyOfExecution.html">EconomyOfExecution</a>, and although nobody suspected (or rather nobody was curious to look) <a href="TypeInference.html">TypeInference</a> plays a very important role in determining this unwanted properties.
      </p>
      <p>
        To begin with, let us note that no <a href="StaticTyping.html">StaticTyping</a> language with <a href="TypeInference.html">TypeInference</a> has really been put to heavy use in "production" (industrial) environments. And some of the engineering properties and potentially not so good language design decision still have to withstand some relevant empirical validation.
      </p>
      <p>
        At first let's look at simple case:
      </p>
      <code>
        let f1 x y = x + y<br/>
      </code>
      <p>
        x and y are bound to be integers in ML-family of languages, without the programmer having to spend his precious keystrokes to declare it. The compiler in its infinite wisdom saw that the + operator is applied in x + y and then decided that x and y have to be integers. <strong>But what is the price paid for it?</strong>
      </p>
      <p>
        Well, the price we pay in ML is that for floats we have to turn our time-honored "+" into "+." as in
      </p>
      <code>
        let f2 x y = x +. y<br/>
      </code>
      <p>
        <em>[ A </em><a href="LanguageLawyer.html">LanguageLawyer</a> says: The above example's actually O'Caml. In Standard ML (<a href="SmlLanguage.html">SmlLanguage</a>) at least, "+" works for both integers and real numbers, so you'd need to give a hint to the <a href="TypeInference.html">TypeInference</a> mechanism. Consider:<em></em>
      </p>
      <code>
        fun f1 x = x + 1;<br/>
        fun f2 x y = x + y : int;<br/>
      </code>
      <p>
        <em>vs:</em>
      </p>
      <code>
        fun f1 x = x + 1.0;<br/>
        fun f2 x y = x + y : real;<br/>
      </code>
      <p>
        <em>]</em>
      </p>
      <ul>
        <li>
           Point taken, and I was aware of it, except that + and the other arithmetic operators are a one time special in the ML language, so the discussion would apply to any other user defined functions. A developer of complex, quaternions, matrices and vector would have to name the functions add_complex, add_matrix, or with module names like in Matrix.Add, etc, see the discussion below. So that's why I "cheated" by using OCAML to illustrate the basic idea that overloading is made difficult or sacrificed in order to support <a href="TypeInference.html">TypeInference</a>.
        </li>
      </ul>
      <p>
        Here x and y are floats. Now the ML die-hard advocates would suggest that the notation "+." has some kind of subtle advantages since it alerts the code writer and the code maintainer that + as in integer addition and +. as in floating point addition are very different operators with very different algebraical properties, so they should be honoured with different names. Well, that might be so, but having to write just the simple "+" had a much sweeter <a href="EconomyOfExpression.html">EconomyOfExpression</a> feel to it (Except, surely, that having +. give you the type of the expression is a lot more economic than declaring the types of the variables and then putting a standard + between them). 
      </p>
      <p>
        Whatever, we'll grant them that argument (although I am really curious what they will do when they'll have to implement a more serious numeric tower - at least like Java, C++, if not Scheme/lisp like, where will they draw more + operators). However the problem can only be waved away with regards to +/+. What happens with a function name like "length"? Length can be length of strings, length of lists, length of arrays, length of (your arbitrary data structure goes here). And then the code becomes:
      </p>
      <code>
        let f1 s =<br/>
        let l= Strings.length s<br/>
        ...<br/>
      </code>
      <p>
        or 
      </p>
      <code>
        let f2 a =<br/>
        let l= Arrays.length a<br/>
        ...<br/>
      </code>
      <p>
        A clear breach of <a href="EconomyOfExpression.html">EconomyOfExpression</a>, because whereas in Java (yeah, I know, bad design ... ) the developer would have to say
      </p>
      <code>
        void method(String s) {<br/>
        s.length();<br/>
        s.substring(...);<br/>
        s.endsWith(...);<br/>
        }<br/>
      </code>
      <p>
        Declaring that s is String <a href="OnceAndOnlyOnce.html">OnceAndOnlyOnce</a>, in the superior language <a href="ObjectiveCaml.html">ObjectiveCaml</a>, the developer will be spared of the declaration of String attached to the identifier, <strong>but</strong> because name collisions screw <a href="TypeInference.html">TypeInference</a>, he will have to prefix all string operators with the name of the Strings module:
      </p>
      <code>
        let f s= <br/>
        let l= Strings.length s<br/>
        and s2= Strings.substring ...<br/>
        and condition= Strings.endsWith ...<br/>
      </code>
      <p>
        And so on, so forth. <a href="EconomyOfExpression.html">EconomyOfExpression</a> got badly screwed in ML family, essentially because names of operators on data are used to disambiguate the type of the data for the purpose of <a href="TypeInference.html">TypeInference</a>, as opposed to using the data type to disambiguate the name of the operator. The type for a datum (identifier) has to be declared only once, however, while names of function operating on that data are likely to occur many more times. The trade-off does present a clear advantage for the Java style languages versus the ML family (at least in this regard).
      </p>
      <hr/>
      <p>
        <strong>But name collisions do not exist for Haskell. </strong>
      </p>
      <p>
        <strong>And they also do not exist for objects in </strong><a href="ObjectiveCaml.html">ObjectiveCaml</a>.<strong></strong>
      </p>
      <p>
        It should be noted that this is problem only exists in the ML family (it gets mocked in <a href="FunctionalWeenie.html">FunctionalWeenie</a>), and is not a property of statically-typed languages in general. Haskell has no problem overloading the + operator for both integers and non-integer forms. Of course, many languages use other syntactic cues to help the type inference engine, such as the convention that "5" is an integer and "5.0" is a float. (The length suffices of C/C++ - L or U - are another example of this). 
      </p>
      <p>
        Name collisions only screw type inference in ML and CAML. Haskell solved this problem with <a href="TypeClasses.html">TypeClasses</a> long ago. And it's been discovered that the much vaunted (and seldom documented) Module Calculus of Ocaml is doable in Haskell as well. Now if they could only make Haskell actually run fast...
      </p>
      <ul>
        <li>
           Actually, Haskell ranks among the fastest running languages in the GreatProgrammingLanguageShootout (as of 2006-03-28).
        </li>
      </ul>
      <p>
        <em>Well, part of why it doesn't run that fast </em>'is<strong> because </strong><a href="TypeClasses.html">TypeClasses</a> as a feature, helps some with the <a href="EconomyOfExpression.html">EconomyOfExpression</a> but impacts the <a href="EconomyOfExecution.html">EconomyOfExecution</a>. Of course there's the ever so dear hope for the <a href="SufficientlySmartCompiler.html">SufficientlySmartCompiler</a>.<em></em>
      </p>
      <ul>
        <li>
           Not true!  While GHC does implement type classes by dictionary passing, this isn't the only way to do so.  JHC compiles away all types and type classes, so they cannot be a reason for (perceived) lack of performance.  (There are a few other reasons, though.)
        </li>
      </ul>
      <p>
        <em>But do we get </em><a href="TypeInference.html">TypeInference</a> for free with <a href="TypeClasses.html">TypeClasses</a>, at least if we disconsider the <a href="EconomyOfExecution.html">EconomyOfExecution</a>? Well, let's discuss this further. Of course, I need to dust off my Haskell first :)<em></em>
      </p>
      <p>
        Yes.
      </p>
      <p>
        <a href="TypeClasses.html">TypeClasses</a> carry their "methods" around as <a href="HigherOrderFunction.html">HigherOrderFunction</a>s. The speed hit is the same as a <a href="VeeTable.html">VeeTable</a> indirection, i.e the difference between <a href="CeeLanguage.html">CeeLanguage</a> and <a href="CeePlusPlus.html">CeePlusPlus</a>. Most people consider that reasonable for all but the most performance-critical code.
      </p>
      <p>
        (And those that don't are really arguing against <a href="AdHocPolymorphism.html">AdHocPolymorphism</a>, as there's no way to avoid the extra indirection unless you require that every name be bound at compile-time to a function. Otherwise, the runtime needs to decide what method to call, and that requires an indirection.)
      </p>
      <ul>
        <li>
           <em>Well, there's no need to argue against </em><a href="AdHocPolymorphism.html">AdHocPolymorphism</a>, when in the presence of <a href="ManifestTyping.html">ManifestTyping</a> and in the absence of <a href="TypeInference.html">TypeInference</a> you can resolve the name at compile-time by taking into account the type of the operands, rather than do it the other way around (aka carriage before the horses) by inferring the type of the operands from the name of the operator. Just good old Ada, Pl/Sql, C++, Java name overloading. Yes, if you take <a href="TypeInference.html">TypeInference</a> as a premise, you'll end up having to have the complications available in Haskell or the ugliness available in ML family. But this page is set to argue that maybe <a href="TypeInference.html">TypeInference</a> should not be taken as a given or a goal, from which all other design trade-offs occur. <em></em>
        </li>
      </ul>
      <p>
        <a href="HaskellLanguage.html">HaskellLanguage</a> lacks <a href="EconomyOfExecution.html">EconomyOfExecution</a> because of pervasive <a href="ImplicitLazyEvaluation.html">ImplicitLazyEvaluation</a>, not because of its type system. Basically, the expense is the cost of packaging up thunks for <a href="CallByNeed.html">CallByNeed</a> on <em>every single expression</em>. Haskell compilers don't actually work like that - they do GraphReduction of <a href="LambdaCalculus.html">LambdaCalculus</a> expressions - but that's effectively what's going on. -- <a href="JonathanTang.html">JonathanTang</a>
      </p>
      <ul>
        <li>
           <em>Given that there's no implementation of type classes in a strict language, given also that there is some doubts as to overcoming the technical challenges associated with implemented type classes in a strict language, one would have to be circumspect before assuming that </em><a href="TypeInference.html">TypeInference</a> in Haskell and the choice of a type system based on type classes have nothing to do with <a href="EconomyOfExecution.html">EconomyOfExecution</a>. See, for example, <a href="http://groups.google.com/groups?hl=en&lr=&c2coff=1&frame=right&th=dec1b16537048ef6&seekm=b20b8d03.0405190152.b62aa84%40posting.google.com#link25.''">http://groups.google.com/groups?hl=en&lr=&c2coff=1&frame=right&th=dec1b16537048ef6&seekm=b20b8d03.0405190152.b62aa84%40posting.google.com#link25.''</a>
        </li>
      </ul>
      <p>
        I suggest you take a look at Wadler's original <a href="TypeClasses.html">TypeClasses</a> papers. <a href="http://homepages.inf.ed.ac.uk/wadler/topics/type-classes.html.">http://homepages.inf.ed.ac.uk/wadler/topics/type-classes.html.</a>
      </p>
      <ul>
        <li>
           The original paper also presents an inefficient mechanism, that is good to provide semantics by simple translation and also good enough for Haskell that is not a speed star anyways. In any case pending a real implementation of a ML-like language with type classes, there's nothing we can assume about what will result. Haskellers envy ML's refined module system and ML-ers envy Haskell's type classes, and that for over a decade already.
        </li>
      </ul>
      <p>
        From "How to make <a href="AdHocPolymorphism.html">AdHocPolymorphism</a> less Ad-Hoc":
      </p>
      <p>
        "However, type classes should be judged independently of Haskell; they could just as well be incorporated into another language, such as standard ML."
      </p>
      <p>
        The papers present a strategy to transform a program with typeclasses into a <a href="HindleyMilnerTypeInference.html">HindleyMilnerTypeInference</a> system without typeclasses. Nowhere does the algorithm make use of Haskell's <a href="LazyEvaluation.html">LazyEvaluation</a> rules. It's just as possible to write a preprocessor to add typeclasses to <a href="ObjectiveCaml.html">ObjectiveCaml</a>.
      </p>
      <ul>
        <li>
           The main problem from an engineering perspective is: <strong>nobody did</strong>. It may be possible as you say, but I wouldn't want my integers to carry around dictionary pointers with them, nor would I want my strings to do the same (in Java String is final and calls on most methods are therefore non-polymorphic anyways, so is byte[]). That makes for relatively fast and reliable network servers, unlike what you can get in Haskell.
        </li>
      </ul>
      <p>
        Andreas's objection in the thread above concerns the appropriate <a href="RunTime.html">RunTime</a> behavior of the Haskell fragment listed, and shows he's been thinking in Haskell for an awfully long time. ;-) The difference between <a href="LazyEvaluation.html">LazyEvaluation</a> and <a href="StrictEvaluation.html">StrictEvaluation</a> is that the former works from top-down, where functions are definitions that are invoked as needed, while the latter works from bottom-up, where functions are commands that are invoked when encountered. In a Haskell program, execution begins with the reduction of "main", which will likely trigger other reductions as necessary. Type variables are instantiated as needed, and as Andreas points out, "main" is monomorphic and so every expression will eventually have a well-defined type.
      </p>
      <p>
        In a strict language, all evaluation begins with either program literals or values read from IO. These provide the types of variables - and values - used in the rest of the program. This is what Neel was pointing out, and it's also mentioned in Wadler's paper: "However, unrestricted overloading of constants leads to situations where the overloading cannot be resolved without providing extra type information. For instance, the expression one * one is meaningless unless it is used in a context that specifies whether its result is an Int or a Float." In a strict language, that context is usually not available, so you're forced to use monomorphic IO functions (readInt/readFloat/readString) and disambiguate literals (3/3L/3.0). But these restrictions are also present in C/Java. Also, you can't say 3 + 3.0 without specifying some sort of type coercion, which is mentioned in Wadler's paper.
      </p>
      <ul>
        <li>
           you can't get say (i < x) either if <strong>i</strong> is an Int and <strong>x</strong> is a Fractional . And why? Because implicit conversions are hard (or impossible to do ) to do in languages that don't now a priori the types of operands but rely on operator name to infer that. Another blow to <a href="EconomyOfExpression.html">EconomyOfExpression</a>. And that makes you really cry for Fortran.
        </li>
      </ul>
      <p>
        The Google thread does present a legitimate speed argument in that all these dictionary lookups prevent inlining of functions. This isn't an issue in Haskell, where <a href="CallByNeed.html">CallByNeed</a> prevents inlining anyway. But in a strict language where the average function length is one line (as many Haskell programs are), this could be a significant hit. Fortunately, there's already been significant research in this area, because this is the exact same problem that <a href="SmallTalk.html">SmallTalk</a>, C++, and Java face! If you substitute <a href="PolymorphicInlineCaches.html">PolymorphicInlineCaches</a> for Wadler's dictionary lookups, you basically get <a href="SelfLanguage.html">SelfLanguage</a> and <a href="HotSpot.html">HotSpot</a>, both of which get generally acceptable performance. And interestingly enough, <a href="TypeInference.html">TypeInference</a> has been implemented in Self, including dynamic inheritance. <a href="http://research.sun.com/self/papers/type-inference.html">http://research.sun.com/self/papers/type-inference.html</a> -- <a href="JonathanTang.html">JonathanTang</a>
      </p>
      <ul>
        <li>
           You see, here's where the theory gets smacked down by practice. In reality all the algorithms for Self VM required inordinate amount of space and CPU, and things got a lot better and more practical when they moved to Java because Java is less flexible (like an order of magnitude less flexible) and this definitely helps, <a href="HotSpot.html">HotSpot</a> got implemented. So you'd think <a href="PolymorphicInlineCaches.html">PolymorphicInlineCaches</a> will save the day. Well, they don't. Because they are typically not being done. Or so they are according to my measurements which I ran up to JDK1.4.1. Taking into account a startup time, and VM pauses to allow the <a href="HotSpot.html">HotSpot</a> to run, a method dispatch based on a base class is approximately 10 times slower than a method dispatch based on an interface type. If <a href="PolymorphicInlineCaches.html">PolymorphicInlineCaches</a> were an actual happening in <a href="HotSpot.html">HotSpot</a> I would not expect such results. Until somebody shows me real code that I can use to measure and prove that <a href="HotSpot.html">HotSpot</a> does what it is alleged in theoretical papers, I do not believe in <a href="PolymorphicInlineCaches.html">PolymorphicInlineCaches</a>. -- <a href="CostinCozianu.html">CostinCozianu</a>
        </li>
      </ul>
      <hr/>
      <p>
        <em>Even if the technical details about the </em><a href="SufficientlySmartCompiler.html">SufficientlySmartCompiler</a> and implementing type classes in a strict language (and even a few more) are all ironed out, one would have to wonder if the resulting type system would not pose too much of an unnecessary conceptual burden, to the extent to which a mere software engineer would rather throw his hands up in the air and shout: "I'd rather spend a few keystrokes annotating identifiers with type names rather than having to figure out what this compiler tries to do with my types.".<em> -- </em><a href="CostinCozianu.html">CostinCozianu</a>
      </p>
      <p>
        Isn't that the same argument that <a href="DynamicTyping.html">DynamicTyping</a> enthusiasts levy against <a href="ManifestTyping.html">ManifestTyping</a>?
      </p>
      <ul>
        <li>
           Don't think so. But the truth is that some type inferencing algorithm is way overboard for the efficient understanding and tractability by the programmer, especially in the presence of parametric polymorphism and type classes (i.e. not even <strong>real</strong> polymorphism yet, since <a href="DynamicTyping.html">DynamicTyping</a> advocates would laugh their butts off when you can't store ints and floats in a list because the type class Num is not actually a real type. When and if you solve this other problem, I guess a good PhD test could be "can you write a Haskell program that will type check the first time?". Which would not be bad in and of itself, except that it's cracking a nut with a sledgehammer.
        </li>
      </ul>
      <p>
        Besides, the real headache with <a href="ManifestTyping.html">ManifestTyping</a> is not typing out the type annotations, it's maintaining them. Every time the types change, you have to track down every variable that might contain the changed value and modify its type declaration. <a href="OnceAndOnlyOnce.html">OnceAndOnlyOnce</a>? -- <a href="JonathanTang.html">JonathanTang</a>
      </p>
      <ul>
        <li>
           So if you are ready to admit that the real headache is not typing out the type annotations - which can only be seen as <strong>the</strong> sensible conclusion, we can explore whether there's any substance in the allegation of the <a href="DynamicTyping.html">DynamicTyping</a> camp that "every time a type changes, the deluge comes". I can tell you from my experience that having programmed <a href="ManifestTyping.html">ManifestTyping</a> mostly for 10 years, I failed to feel the pain. <a href="ManifestTyping.html">ManifestTyping</a> makes automatic refactoring much easier, and it also helps with manual refactoring since compiler errors are not the intractable "can't unify X with Y", but rather precise and helpful - a rare occurrence with languages based on <a href="TypeInference.html">TypeInference</a>.
        </li>
      </ul>
      <ul>
        <li>
           <em>In some languages, like C/C++, typedef comes to the rescue. If I suspect that a given type which propagates through the system is likely to change in the future, I give it its own name via typedef. Then, if and when I need to redefine it, I just change the typedef. Adding a layer of indirection comes to the rescue again! Of course, use of typedefs for this purpose doesn't solve ALL problems - if the new type lacks operations that the old type supported, you'll have some </em><a href="ReFactoring.html">ReFactoring</a> to do. But the compiler will tell you where it is exactly, without having to hunt it down. The other gotcha with typedefs in C++ is that they don't mesh well with overloading.<em></em>
        </li>
      </ul>
      <ul>
        <li>
           <em>My main regrets regarding typedefs: 1) Java doesn't have them; 2) There is no template form - I'd love to be able to do</em>
        </li>
      </ul>
      <code>
        template <class T> typedef Foo<T,int> FooOfInt<T>;<br/>
      </code>
      <ul>
        <li>
           <em>3) typecopy would be nice.</em>
        </li>
      </ul>
      <p>
        <em>Regarding point 2 above, it has been noted as "mistakenly rejected early on" by </em><a href="BjarneStroustrup.html">BjarneStroustrup</a>, and will likely be included in C++0x. See <a href="http://www.research.att.com/~bs/C++0x_keynote.pdf">http://www.research.att.com/~bs/C++0x_keynote.pdf</a> for more information. -- <a href="MichaelSparks.html">MichaelSparks</a><em></em>
      </p>
      <hr/>
      <p>
        MainifestTyping <strong>vs</strong> <a href="TypeClasses.html">TypeClasses</a>.
      </p>
      <p>
        <a href="TypeClasses.html">TypeClasses</a> seem to get rid of all the problems (although implementation problems) and get rid of <a href="ManifestTyping.html">ManifestTyping</a>.
      </p>
      <p>
        To begin with, <a href="TypeClasses.html">TypeClasses</a> solve some part of the name clashes problem, they do not resolve it completely. For example the name "length" is reserved for lists (aka the type [a]). Now one may want to introduce it's own kinds of lists, say a doubly linked list, or a list backed by an array.Of course the newly introduced types will also need a "length" operator, but since nobody at the <a href="DesignPhase.html">DesignPhase</a> of Haskell foresaw the need for an interface (aka type class) that defines the length type, then the new guy who writes the doubly linked list will not have an interface to adhere to and his newly defined name will class with the other defined name. Of course, <strong>modules</strong> to the rescue, i.e. one will be addressed as Prelude.length, and another one will be addressed by DoubleList.length. So we're back to square one (ML). Another instance is where different type classes define the same names for operators, to resolve the potential client of both will disambiguate by using module name.
      </p>
      <p>
        Sure Java programmers use package names to disambiguate type names, but as we observed before type names in <a href="ManifestTyping.html">ManifestTyping</a> appear <a href="OnceAndOnlyOnce.html">OnceAndOnlyOnce</a> in the manifest, that is, while operator names appear more often.
      </p>
      <p>
        <em>No, we're still a step ahead.  Witness:</em>
      </p>
      <code>
        import Prelude hiding (length)<br/>
        import qualified Prelude<br/>
      </code>
      <code>
        class Sequence a where length :: a -> Int<br/>
        instance Sequence [a] where length = Prelude.length<br/>
        -- your instances here<br/>
      </code>
      <p>
        <em>Of course this will be hidden in a module, should you really decide there's a need for an overloaded 'length'.</em>
      </p>
      <hr/>
      <p>
        <strong>More about type classes.</strong>
      </p>
      <p>
        The assertion was made above that type classes and Haskell type system solve all the problems with type inference without suffering the drawbacks of ML. Actually, Haskell's type system is quite a beast, and it's inherent complexity in addressing simple things is sufficient of a drawback. However, after a brief excursion into Haskell, here's the problem with <a href="TypeClasses.html">TypeClasses</a>: they are not first class in the type system. They are very different beasts.
      </p>
      <p>
        For example under Haskell there's no way to create a list with the following content: [1,"string"] although both elements implement the "Show" interface (speaking in the language of Java mortals), i.e. their types are instances of "Show" and provide the function "show : a -> [Char]" (roughly the equivalent of Java's toString()).
      </p>
      <p>
        <em>As always, Haskell continues to evolve. GHC 6.6 will support this (or the 6.5 development snapshots, if you are feeling adventurous), as long as you help it along a bit by declaring the type of the list [forall a . Show a => a]. A bigger problem is that given a list with a type like this, *all* you can do is call methods of class Show (and superclasses). A list of things you can do nothing with but convert to strings is not much more useful that just having a list of strings in the first place. There is a class Typeable you could add to partially get around the restriction, but it's still pretty messy</em>
      </p>
      <p>
        Furthermore the polymorphism with type classes does not quite really work, while the identity function behaves as expected in:
      </p>
      <code>
        let id= \x -> x in (id 1, id "string")<br/>
      </code>
      <p>
        is well typed and gives the result (1,"string"), when we try to substitute id with a function that operates on Show:
      </p>
      <code>
        let f = \x -> show x in (f 1, f "string")<br/>
      </code>
      <p>
        the unsuspecting Java programmer in me would expect the expression to be well typed, and to return a tuple of two strings. However, Haskell balks at me and says ERROR: it cannot infer type.
      </p>
      <p>
        I check again the type of the f function:
      </p>
      <code>
        :t \x -> show x<br/>
      </code>
      <p>
        it is well typed and gives the type "Show a => a->[Char]" which to me reads like takes a value of a type deriving from Show and returns a string. Now the way Haskell operates is that he doesn't say f take a value of <strong>any</strong> type deriving from Show, <strong>but</strong> it takes a value of <strong>exactly one</strong> type deriving from Show, which type we do not know at the point where the function is declared but will be determined later through <a href="TypeInference.html">TypeInference</a>.
      </p>
      <p>
        <em>Your reading is quite correct. A type like Show a => a -> String does mean *any* type supporting Show - any lower case identifier in a Haskell type signature is a type variable, and a type is polymorphic in all the type variables. It only breaks down here because you hit a rather ugly corner case in the language, called the (dreaded) monomorphism restriction, where the compiler *does* try to reduce the variable a down to one particular type. Fixed example follows yours. All the gory details here:</em> <a href="http://www.haskell.org/hawiki/MonomorphismRestriction">http://www.haskell.org/hawiki/MonomorphismRestriction</a>
      </p>
      <p>
        So for example 
      </p>
      <code>
        let f= \x -> show x ++ show x<br/>
        in let a= f 1  -- Point A: here the type inferencer assigned Num a to the unknown type<br/>
        in let b = f 2 -- Point B: here the type of f is already fixed and set in stone<br/>
        in a ++ b<br/>
      </code>
      <p>
        is well typed and returns 1122, but if I want to say to replace point B with
      </p>
      <code>
        let b = f "string"<br/>
      </code>
      <p>
        then the type inference breaks because string (aka [Char] ) does not match the numeric type already inferred at point A. 
      </p>
      <p>
        <em>The monomorphism restriction only applies to declarations involving type classes (why id worked above), without an explicit type signature, and without parameters on the left hand side (and is disabled by the -fno-monomorphism-restriction flag, if you're using GHC). With any of these fixes, type inference works quite a lot better:</em>
      </p>
      <code>
        let f x = show x ++ show x<br/>
        -- or f :: Show a => a -> String<br/>
        --    f = \x -> show x ++ show x<br/>
        a = f "hi" -- Type checker makes sure there is a Show instance for String <br/>
        b = f 1 -- Some magic decides 1 is an Integer, type checker checks that there is a Show instance for String.<br/>
        in a ++ b<br/>
      </code>
      <p>
        Now the solutions to this dilemma are quite a number in Haskell, but all sacrifice <a href="EconomyOfExpression.html">EconomyOfExpression</a> one way or the other. For example one can use existential types to create a "wrapper" type that will provide a box with the actual value encapsulated inside. This is unnatural (the naive Java programmer in me asks why the hell should I create extra objects and extra types just to please the type inference engine - it's clearly an exercise in <a href="HelpingTheCompiler.html">HelpingTheCompiler</a> and it doesn't even have positive effects with regards to <a href="EconomyOfExecution.html">EconomyOfExecution</a>). Other workarounds involve the usage of closures or array or records containing closures, again we are about unnecessary entities that are nowhere near as elegant as your stock interfaces in languages with <a href="ManifestTyping.html">ManifestTyping</a> (Java, C#). The explanations seem pretty logical <a href="TypeClasses.html">TypeClasses</a> were designed to solve the overloading problem (aka ad-hoc polymorphism), while the barbarians at the gates (OO programmers) seek to apply subtype polymorphism in their designs.
      </p>
      <p>
        See <a href="http://www.haskell.org/hawiki?ExistentialTypes">http://www.haskell.org/hawiki?ExistentialTypes</a>
      </p>
      <p>
        Since Haskell for me is a rarely exercised tongue, I eagerly wait corrections and criticisms. -- <a href="CostinCozianu.html">CostinCozianu</a>
      </p>
      <p>
        <em>You're correct, this is unnatural.  These heterogenous lists are also largely unneeded.  Why would you create a "list of all things showable"?  Just show them already and create a list of strings.  The standard example is actually the second most useless example, with the most useless being the "list of everything".</em>
      </p>
      <p>
        <em>I'm still waiting for a compelling use case for existential types.  All uses I've come across are better implemented as a record of functions.  This again feels natural.</em>
      </p>
      <hr/>
      <p>
        An anonymous donor claims that there is no problem with OCAML:
      </p>
      <p>
        <em>But </em><a href="ObjectiveCaml.html">ObjectiveCaml</a> will let you notate the type of the argument, so this argument doesn't really hold water.<em></em>
      </p>
      <code>
        let f1 (s: string) = length s;;<br/>
        let f2 (a: 'a array) = length s;;<br/>
      </code>
      <p>
        On the contrary, here's the output with the latest OCAML interpreter:
      </p>
      <code>
        let f (x:string) = length x;;<br/>
        Characters 19-25:<br/>
        let f (x:string) = length x;;<br/>
        ^^^^^^<br/>
        Unbound value length<br/>
      </code>
      <p>
        Whereas 
      </p>
      <code>
        #let f (x:string) = String.length x;;<br/>
        val f : string -> int = <fun><br/>
      </code>
      <p>
        Now you probably refer to the <em>open Module</em> directive, but that is not a resolution to the overloading problem :
      </p>
      <code>
        #open Array;;<br/>
        #let f x = length x;;<br/>
        val f : 'a array -> int = <fun><br/>
        # f2 (x: 'a array) = length x<br/>
        val f : 'a array -> int = <fun><br/>
        # open String;;<br/>
        # let f3 y = length y;;<br/>
        val f3 : string -> int = <fun><br/>
        # (* all looks nice but *)<br/>
        # let f4 (x: 'a array) = length x;;<br/>
        Characters 30-31:<br/>
        let f4 (x: 'a array) = length x;;<br/>
        ^<br/>
        This expression has type 'a array but is here used with type string <br/>
      </code>
      <p>
        As you can see in the name resolution algorithms the type declaration simply does not matter, the only thing that matters is the last open directive, in the case above open String. The overloading problem is very manifest in the names of standard functions for printing values:
      </p>
      <code>
        print_string : string -> unit<br/>
        print_int : int -> unit<br/>
        print_float : int -> unit<br/>
      </code>
      <p>
        Whereas in Java or other OO languages there's just one name "print" and several overloaded function. Repeating the type name in the name of the function is redundant and sore to the eye, and is there just to make the <a href="TypeInference.html">TypeInference</a> happy. It's an example of what needs to be sacrificed in order to make <a href="TypeInference.html">TypeInference</a> work.
      </p>
      <p>
        <em>Agreed.  I'm quite happy with </em>deduced<em>, rather than </em>inferred<em>, types.  If I use manifest typing on my data structures, then the types in the usage of instances of those data structures are typically enough to figure out the rest without all the mess brought in by unification. -- </em><a href="ScottMcMurray.html">ScottMcMurray</a><em></em>
      </p>
      <p>
        Dude, deduction is a form of inference. Most <a href="TypeInference.html">TypeInference</a> uses deduction. And the above problems with OCaml are problems of OCaml, not <a href="TypeInference.html">TypeInference</a> in general. Haskell, for example readily allows inference involving typeclasses, and uses it (in abundance) for such things as monads and 'show' (its own form of 'print X' for almost any X you might care to name).
      </p>
      <p>
        <em>I use </em>deduction<em> when it's context independant, like auto in C++0x.  Sure, it's a subset, but I'd rather reserve the name </em>inference<em> for things like Hindley-Milner unification-based approaches where it's not trivial to implement. -- </em><a href="ScottMcMurray.html">ScottMcMurray</a><em></em>
      </p>
      <hr/>
      <p>
        It seems that the message of this page is that manifest typing is better than type inference, because, at the end of the day, it allows for greater <a href="EconomyOfExpression.html">EconomyOfExpression</a>, mostly because of ad-hoc polymorphic functions. So where does this leave dynamic typing, or the combination of dynamic typing and manifest typing (as seen in <a href="CommonLispObjectSystem.html">CommonLispObjectSystem</a>)?
      </p>
      <p>
        <em>Au contraire, mon frere.  If anything, the message is that overloading is better than no overloading.  Duh!</em>
      </p>
      <p>
        I think you're in <a href="ViolentAgreement.html">ViolentAgreement</a>.  If that's the message, then the big question is "Why don't people miss overloading in dynamic languages?"
      </p>
      <p>
        <em>They don't miss it because they have overloading, too. It's just dynamic.</em>
      </p>
      <p>
        Ah. Guess I'm too used to perl.
      </p>
      <hr/>
      <p>
        Something I found to add to the "IDE Tricks" category:  Resharper (for C# in VS) offers type-sensitive code completion in variable initialization/assignment, return statements, function call argument lists, etc.
      </p>
      <hr/>
      <p>
        <a href="OctoberZeroFive.html">OctoberZeroFive</a>
      </p>
      <hr/>
      <p>
        <a href="CategoryLanguageTyping.html">CategoryLanguageTyping</a>
      </p>
    </div>
  </body>
</html>