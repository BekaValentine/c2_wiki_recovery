<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Monty Hall Problem
      </h1>
      <p>
        You are a game show contestant, Monty is the host. Monty presents you with three boxes, one of which contains a FABULOUS PRIZE!!!!. If you choose the correct box, you win the prize.
      </p>
      <p>
        You choose a box. Monty, who knows which box contains the prize, opens one of the unchosen boxes that does not contain the prize. Monty then offers you the opportunity to change your selection to the other unopened box.
      </p>
      <p>
        In order to maximize your chance of winning the prize, should you change your selection?
      </p>
      <p>
        See the rec.puzzles FAQ <a href="http://www.faqs.org/faqs/puzzles/faq/">http://www.faqs.org/faqs/puzzles/faq/</a> for the short description of the correct solution. See <a href="MontyHallSolution.html">MontyHallSolution</a> and the remainder of this page for additional attempts to explain or refute that solution.
      </p>
      <hr/>
      <p>
        This is an example of one of the categories of the <a href="InevitableIllusions.html">InevitableIllusions</a>.
      </p>
      <p>
        <em>Harder than working out how this works is explaining how it works</em>
      </p>
      <hr/>
      <p>
        Part of the psychology of this, I suspect, is that people don't want to choose one door, switch, and then be thought an idiot for switching away from the right door. Perhaps the thought/feeling is that not switching and losing is somehow unlucky, while switching and losing is foolish.
      </p>
      <p>
        <a href="AnAcceptableWayOfFailing.html">AnAcceptableWayOfFailing</a>?
      </p>
      <hr/>
      <p>
        <em>The length of this page does nothing to restore my faith in the average coders' abilities in introductory mathematics. It would be funny if it weren't so disturbing.</em>
      </p>
      <p>
        Perhaps we should talk about <a href="ProgrammerMathSkills.html">ProgrammerMathSkills</a>. <em>(...or lack thereof. ;-)</em>
      </p>
      <p>
        Wow! How about CategoryInvoluntaryHumor ?
      </p>
      <p>
        How about a quantum mechanical explanation based on <a href="SchroedingersCat.html">SchroedingersCat</a>:
        One car is simultaneously behind three separate doors. According to its wave equation, there is one third of a car behind each door.
        You select a particular third of a car by claiming (temporary) ownership of it. Monty then performs a quantum transition that collapses the other two thirds of a car into a smaller space. You are invited to go get two thirds of a car and drive away.
      </p>
      <hr/>
      <p>
        I've read the correct solution to this a dozen times and still don't get it, which has lead me to conclude bad things about myself. -- TheFool
      </p>
      <p>
        <em>Don't feel bad. It doesn't help that so many writers confound the answer with a lot of big tables and mathematical notation, along with implications that those who don't get it are lazy, undereducated, or irrational. It really is pretty simple, but counterintuitive. You just have to approach it in different ways and wait for the "Ah-ha" to hit you. I personally found </em><a href="MontyHallSimulation.html">MontyHallSimulation</a> to be an effective way of understanding it. -- AnotherFool<em></em>
      </p>
      <p>
        A suggestion: <strong>try empiricism.</strong> Grab a buddy and play the game. Try each of the two different strategies (stay with your first choice / switch) a few dozen times. Keep track of your results. Once you've got some empirical data in hand, switch roles with your buddy and play another few dozen rounds. Then try to figure out why your results aren't 50/50. (If no buddy's handy, you can use a <a href="MontyHallSimulation.html">MontyHallSimulation</a>.)
      </p>
      <p>
        It amazes me that so many people are willing to defend the position "switching doesn't matter" when they've never played the game. I've found that getting people who don't understand the solution to <strong>actually play the game</strong> triggers the necessary <a href="AhHa.html">AhHa</a>.
      </p>
      <p>
        <em>Does this mean that you have tried the empirical solution yourself? Did you record data? Are you willing to publish? -- a curious </em><a href="AnonymousDonor.html">AnonymousDonor</a><em></em>
      </p>
      <p>
        Yes, I have, many times. Mostly with a <a href="MontyHallSimulation.html">MontyHallSimulation</a>, but sometimes with other people. My goal was to convince them (or myself) that switching is better, so I didn't bother to keep formal records. Here's an idea: why doesn't everyone try it and record their results below? Then you wouldn't have to trust my word.
      </p>
      <hr/>
      <p>
        Of course you always change your selection. To make the puzzle more intuitive, imagine there are a million boxes instead of just three, but still only one prize. You pick a box. Monty opens 999998 boxes, none of which contain the prize. Should you switch to the one box he didn't open, or should you go with your initial, one-in-a-million guess?
      </p>
      <p>
        [Imagine you picked box 1 (out of a million).  Monty tells you the prize is either in your choice, the very first box, or box number 453,824.  The specific number makes it abundantly clear that your choice is random and his is very revealing.]
      </p>
      <hr/>
      <p>
        Of course you never change your selection. By revealing to you that the other 999998 boxes did not contain the prize, Monty increases the chance you are correct from one-in-a-million to one-in-two!
      </p>
      <p>
        It doesn't matter either way. Whether you change your choice or not, the chances are the same that you are correct. 
      </p>
      <p>
        -The above view is the classic incorrect reasoning for this puzzle. You already knew there were 999998 empty boxes in that set, knowing which ones they are has no effect on the probability of the prize being in that set of boxes. 
      </p>
      <hr/>
      <p>
        Problem: If room R is chosen originally from a set of N rooms and room R' is revealed to you (such that R' is a "goat" room), should you choose one of the other N-2 rooms?
      </p>
      <p>
        If N is < 3, this problem doesn't make sense: 0 rooms: you can't choose anything, 1 room: you always win, 2 rooms: if Monty shows you the other room then you've already picked the winning room. So, N >= 3.
      </p>
      <p>
        Given a set of N rooms where it is given that exactly one of N rooms possesses the property "car" (or is set to true, if you wish) and the other N-1 rooms possess the property "goat" (or is set to false, if you wish), the probability of a room possessing the car, Pc(N) = 1/N. Thus, the expectation of choosing the "car" room, Ec(N) = 1 * 1/N = 1/N, and the expectation of choosing a goat room, Eg(N) = (N-1) * 1/N = (N-1)/N.
      </p>
      <p>
        Thus for three rooms, Ec(3) = 1/3 and Eg(3) = 2/3.
      </p>
      <p>
        But if R' is revealed to be a "goat" room you now know that the original expectation of one the rooms you didn't choose housing the car, Eg(N), is now broken up amongst the N-2 rooms, giving you the probability of the other room possessing a car => Pc'(N) = Eg(N) / (N-2) = (N-1)/N(N-2).
      </p>
      <p>
        Thus, for a three room game, Pc'(3) = 2/3.
      </p>
      <p>
        Note that Pc'(N) > Pc(N) always as Pc'(N) = (N-1)/(N-2) * Ec(N) = (N-1)/(N-2) * Pc(N) as Ec(N) = 1 * Pc(N), and N-1 > N-2, so (N-1)/(N-2) > 1.
      </p>
      <p>
        The main idea here revolves around expectation. Nothing can change your original expectation to win or lose if you just played out the game ignoring all additional information. I.e. if Monty reveals a door and you close your eyes and keep playing, it doesn't change the fact that you will win 1/3 of the time. You don't suddenly win 1/2 the time. 
      </p>
      <p>
        Thus, the 2/3 expectation that you will lose must mean that the car is smeared across the other rooms somewhere. If you remove a room, the car has less places to be smeared across and thus increases the other rooms' likelihoods of having the car.
      </p>
      <p>
        [Pc'(4) = 3/8 = 37.5%. Check it out from the program below:
      </p>
      <p>
        Rooms (3-32767): 4
        Rounds (0-2147483647): 100000
        After 100000 rounds:
      </p>
      <p>
        Original picks won:    24732 times (24.732000%)
        Swapped picks won:     37603 times (37.603000%)
      </p>
      <p>
        Pc'(5) = 4/15 = 26.666...%. Check it out:
      </p>
      <p>
        Rooms (3-32767): 5
        Rounds (0-2147483647): 100000
        After 100000 rounds:
      </p>
      <p>
        Original picks won:    20010 times (20.010000%)
        Swapped picks won:     26713 times (26.713000%)
        ]
      </p>
      <p>
        Source code available at <a href="http://sunir.org/c2/MontyHallProblem/montyhal.c">http://sunir.org/c2/MontyHallProblem/montyhal.c</a>
      </p>
      <p>
        -- <a href="SunirShah.html">SunirShah</a>
      </p>
      <hr/>
      <p>
        Bold is which door has the prize. <em>He will not show the door that has the prize </em>, which is the fact that increases the odds, so this possibility has been left out. Plainly, against my own thoughts, it does work out to a 1-in-2 chance of being right.
      </p>
      <code>
        Right   Wrong  <br/>
        You pick 1. He shows 2. You pick 3.   <strong>1</strong>  2  3            x<br/>
        You pick 1. He shows 3. You pick 2.   <strong>1</strong>  2  3            x<br/>
        You pick 2. He shows 3. You pick 1.   <strong>1</strong>  2  3    x<br/>
        You pick 3. He shows 2. You pick 1.   <strong>1</strong>  2  3    x<br/>
      </code>
      <code>
        You pick 1. He shows 3. You pick 2.   1  <strong>2</strong>  3    x<br/>
        You pick 2. He shows 1. You pick 3.   1  <strong>2</strong>  3            x<br/>
        You pick 2. He shows 3. You pick 1.   1  <strong>2</strong>  3            x<br/>
        You pick 3. He shows 1. You pick 2.   1  <strong>2</strong>  3    x<br/>
      </code>
      <code>
        You pick 1. He shows 2. You pick 3.   1  2  <strong>3</strong>    x       <br/>
        You pick 2. He shows 1. You pick 3.   1  2  <strong>3</strong>    x <br/>
        You pick 3. He shows 1. You pick 2.   1  2  <strong>3</strong>            x<br/>
        You pick 3. He shows 2. You pick 1.   1  2  <strong>3</strong>            x<br/>
      </code>
      <p>
        Viewing it this way cleared it up for me absolutely - I don't know why it is not expressed elsewhere in table form. -- RodneyRyan
      </p>
      <hr/>
      <p>
        Sadly, the above table is improperly constructed. There are three options for you to pick, and three places for the prize to be. 3 x 3 = 9. You are treating what he shows as an input, which it is not. The inputs are "your pick" and "location of prize". What is shown is a function of those inputs. 
      </p>
      <p>
        pick = 1 location = 1  You change from good to bad. = lose
      </p>
      <p>
        pick = 1 location = 2  You change from bad to good. = win
      </p>
      <p>
        pick = 1 location = 3  You change from bad to good. = win
      </p>
      <p>
        pick = 2 location = 1  You change from bad to good. = win
      </p>
      <p>
        pick = 2 location = 2  You change from good to bad. = lose
      </p>
      <p>
        pick = 2 location = 3  You change from bad to good. = win
      </p>
      <p>
        pick = 3 location = 1  You change from bad to good. = win
      </p>
      <p>
        pick = 3 location = 2  You change from bad to good. = win
      </p>
      <p>
        pick = 3 location = 3  You change from good to bad. = lose
      </p>
      <ol>
        <li>
          /9 lose, 6/9 win. = 1/3 lose 2/3 win. Hope this table re-clears things up for you absolutely. 
        </li>
      </ol>
      <p>
        <em>No. I do not understand your point. Can you be more specific? In the table above yours I simply listed all the possible sequences of events and tallied the outcome of each. I do not see where I made an error.</em>
      </p>
      <p>
        OK. The first table was acceptably constructed, but the cases are listed without their corresponding probabilities, which are not equal. Lines 3, 4, 5, 8, 9, and 10 have probability 1/9. Lines 1 and 2 have probabilities which <em>total</em> 1/9; likewise, lines 6 and 7 have probabilities which total 1/9, and lines 11 and 12 have probabilities which total 1/9. I know this is also stated below, but read it here, think about it, and let it sink in. The penny should soon drop. -- <a href="VickiKerr.html">VickiKerr</a>
      </p>
      <hr/>
      <code>
        Strategy: <strong>Stick</strong> with First Choice<br/>
        <strong>First Choice</strong><br/>
        <strong>Prize</strong>	1	2	3<br/>
      </code>
      <ol>
        <li>
          	x
        </li>
        <li>
          		x
        </li>
        <li>
          			x
        </li>
      </ol>
      <p>
        Read it like this: If the Prize is at 1, and my First Choice is 1, and I stick with my First Choice, then I am correct. If the Prize is at 1, and my First Choice is 2, and I stick with my First Choice, then I am wrong.
      </p>
      <p>
        Add it up and you get 3/9 = 1/3 chance of being right with this strategy.
      </p>
      <code>
        Strategy: <strong>Switch</strong> from First Choice<br/>
        <strong>First Choice</strong><br/>
        <strong>Prize</strong>	1	2	3<br/>
      </code>
      <ol>
        <li>
          		x	x
        </li>
        <li>
          	x		x
        </li>
        <li>
          	x	x
        </li>
      </ol>
      <p>
        Read it like this: If the Prize is at 1, and my First Choice is 1, and I switch from my First Choice, then I am wrong. If the Prize is at 1, and my First Choice is 2, and I switch from my First Choice (i.e. from 2 to 1, since switching from 2 to 3 is impossible, since Monty already showed me 3), then I am correct.
      </p>
      <p>
        Add it up and you get 6/9 = 2/3 chance of being right with this strategy.
      </p>
      <p>
        <em>Even less helpful</em> [What about with the annotations?]
      </p>
      <p>
        <em>Explaining theory is not as clear as listing every possible sequence of actual events, totalling the outcome and drawing conclusions. That is why I made the You Pick, He Shows, You Pick table above. I still see it as correct, that is, it lists every possible sequence with the appropriate outcome and presents a tally of 1-in-2 chance of being correct. If I have left out or mis-stated sequences, please correct the table, which I reproduce here:</em>
      </p>
      <code>
        Right   Wrong  <br/>
        You pick 1. He shows 2. You pick 3.   <strong>1</strong>  2  3            x<br/>
        You pick 1. He shows 3. You pick 2.   <strong>1</strong>  2  3            x<br/>
        You pick 2. He shows 3. You pick 1.   <strong>1</strong>  2  3    x<br/>
        You pick 3. He shows 2. You pick 1.   <strong>1</strong>  2  3    x<br/>
      </code>
      <code>
        You pick 1. He shows 3. You pick 2.   1  <strong>2</strong>  3    x<br/>
        You pick 2. He shows 1. You pick 3.   1  <strong>2</strong>  3            x<br/>
        You pick 2. He shows 3. You pick 1.   1  <strong>2</strong>  3            x<br/>
        You pick 3. He shows 1. You pick 2.   1  <strong>2</strong>  3    x<br/>
      </code>
      <code>
        You pick 1. He shows 2. You pick 3.   1  2  <strong>3</strong>    x       <br/>
        You pick 2. He shows 1. You pick 3.   1  2  <strong>3</strong>    x <br/>
        You pick 3. He shows 1. You pick 2.   1  2  <strong>3</strong>            x<br/>
        You pick 3. He shows 2. You pick 1.   1  2  <strong>3</strong>            x<br/>
      </code>
      <hr/>
      <p>
        What the table is missing is the associated probabilities of the events:
      </p>
      <code>
        Right   Wrong   Probability<br/>
      </code>
      <ol>
        <li>
          )  You pick 1. He shows 2. You pick 3.   <strong>1</strong>  2  3            x     .055
        </li>
        <li>
          )  You pick 1. He shows 3. You pick 2.   <strong>1</strong>  2  3            x     .055
        </li>
        <li>
          )  You pick 2. He shows 3. You pick 1.   <strong>1</strong>  2  3    x             .111
        </li>
        <li>
          )  You pick 3. He shows 2. You pick 1.   <strong>1</strong>  2  3    x             .111
        </li>
      </ol>
      <ol>
        <li>
          )  You pick 1. He shows 3. You pick 2.   1  <strong>2</strong>  3    x             .111
        </li>
        <li>
          )  You pick 2. He shows 1. You pick 3.   1  <strong>2</strong>  3            x     .055
        </li>
        <li>
          )  You pick 2. He shows 3. You pick 1.   1  <strong>2</strong>  3            x     .055
        </li>
        <li>
          )  You pick 3. He shows 1. You pick 2.   1  <strong>2</strong>  3    x             .111
        </li>
      </ol>
      <ol>
        <li>
          )  You pick 1. He shows 2. You pick 3.   1  2  <strong>3</strong>    x             .111
        </li>
        <li>
          ) You pick 2. He shows 1. You pick 3.   1  2  <strong>3</strong>    x             .111
        </li>
        <li>
          ) You pick 3. He shows 1. You pick 2.   1  2  <strong>3</strong>            x     .055
        </li>
        <li>
          ) You pick 3. He shows 2. You pick 1.   1  2  <strong>3</strong>            x     .055
        </li>
      </ol>
      <p>
        If you originally chose the correct location, then Monty has two doors to choose from, hence the 50%. If you picked one of the incorrect locations, Monty's only got 1 door to choose from, hence the 100%.
      </p>
      <p>
        <em>Again it is unclear. You say "If you originally chose the correct location, then Monty has two doors to choose from, hence the 50%." 50% of </em>'what<em>'? If you originally chose the correct location you will always be wrong because you will always change your choice to an incorrect location after he picks another door - what is this 50% of ?</em>
      </p>
      <p>
        <strong>Exactly.  Your original choice is correct 33.3% of the time, and wrong 66.7%.  If your original choice is correct, the "always switch" strategy always fails.</strong>
      </p>
      <p>
        <strong>But if your original choice is wrong, "always switch" always works. Monty takes one wrong choice away from you, and "always switch" takes you away from the other wrong choice.</strong>
      </p>
      <p>
        <strong>So, unless you choose right the first time (33.3% chance), "always switch works the rest of the time (66.7% chance). -- </strong><a href="RobMandeville.html">RobMandeville</a><strong></strong>
      </p>
      <ol>
        <li>
          % of the doors he can show you. Draw a decision tree if this is unclear.
        </li>
      </ol>
      <p>
        <em>My view is based on each of the 12 sequences listed in the table above as all being equal - that is, the probability value of each statement is .083. If this is not the case, and this is what is causing my misunderstanding, please fill in the actual values in the new labeled </em>'Probability<strong>. The values must add up to 1. If the values differ please </strong>explain why<em>'.</em>
      </p>
      <p>
        The 12 sequences are not all  equal.  Those where switching is right are .111... Those where staying is right are .0555... (Monty doesn't open both doors when you guess right initially).
      </p>
      <p>
        Hmm... try this:
      </p>
      <code>
        correct door     your first pick    if you stay   if you change   prob Monty<br/>
      </code>
      <ol>
        <li>
                            1             right          wrong        1/9  2 or 3
        </li>
        <li>
                            2             wrong          right        1/9  3
        </li>
        <li>
                            3             wrong          right        1/9  2
        </li>
      </ol>
      <ol>
        <li>
                            1             wrong          right        1/9  3
        </li>
        <li>
                            2             right          wrong        1/9  1 or 3
        </li>
        <li>
                            3             wrong          right        1/9  1
        </li>
      </ol>
      <ol>
        <li>
                            1             wrong          right        1/9  2
        </li>
        <li>
                            2             wrong          right        1/9  1
        </li>
        <li>
                            3             right          wrong        1/9  1 or 3
        </li>
      </ol>
      <p>
        I think this breakdown shows that if you stay you have a 1/3 chance of being right, but you have a 2/3 chance if you use the additional information Monty gives you. -- <a href="AndyPierce.html">AndyPierce</a> <em>Does showing the door Monty shows make this table clearer?</em>
      </p>
      <p>
        <em>No, and neither of your explanations make sense. They both seem to hinge on the difference in switching or not, but according to the problem itself after Monty opens the door </em>'you always switch<strong>. Therefore, whether you stay or not, or switch or not, has no relevance to the problem. As I have asked, </strong>please label the column of Probability in the table with appropriate values<strong> to explain why the chances of any one of the 12 sequences occurring is </strong>not the same for all statements<em>'.</em>
      </p>
      <p>
        Okay, I filled in the probabilities in your table. My lame browser did not let me see to line them up, someone feel free to fix that. 
      </p>
      <p>
        <em>Thanks! Now, the differences in probabilities has to do with the chance of your first guess being correct, right?</em>
      </p>
      <p>
        Yes - specifically, the sum of all the outcomes after you pick your door must equal the probability that you picked your door (conservation at work). But I've never managed to teach an unbeliever using that approach.
      </p>
      <p>
        <em>Well it worked for me - I see now what the logic is. Thanks a lot for bearing with me! I finally understand it. This is how I would explain it:</em>
      </p>
      <p>
        <strong>If you initially pick the door that has the prize (1 out of 3), you will switch and always be wrong. If you initially pick a door that does not have the prize (2 out of 3), Monty will open a door that also does not have the prize, you will switch and always be right. Therefore your chance of picking the correct door is (2 out of 3).</strong>
      </p>
      <p>
        <em>Thanks again to all for your explanations !</em> -- RodneyRyan
      </p>
      <hr/>
      <p>
        BayesTheorem, anyone?
      </p>
      <hr/>
      <p>
        I think the reason that people so often get this wrong is that they are hoist on their own petard (please correct the cliché). The victim, eager to prove he's no JoeSixPack, thinks as follows: "Any dummy knows the car can't suddenly switch places, switching doors isn't going to make the car jump from one room to the other. That's what I learned in college." And of course, if were a matter of the car switching rooms spontaneously (possible according to quantum theory but very unlikely ;-)) you would be correct to stop your thinking there. But the victim, eager to prove (s)he's not an ignorant boob, jumps on the notion that the "probabilities can't change," skips the rest of the required reasoning and blurts out the (incorrect) answer.
      </p>
      <p>
        I had trouble believing the correct answer myself until running a MonteCarlo simulation. 10000 trials with the always-stay strategy yielded 3322 wins. The same number of trials with the always-switch strategy yielded 6652 wins, which is close enough to the theoretical result for government work.
      </p>
      <p>
        -- <a href="DavidBrantley.html">DavidBrantley</a>
      </p>
      <p>
        I liked the explanation on rec.puzzles, which is the mate of the one in bold above. They say: The odds of you guessing WRONG in your first choice is 2/3. If you stay with your first choice, you stay WRONG with that probability. Ergo, when you switch, you move to only a 1/3 chance of being WRONG... 2/3 of being right. -- <a href="AlistairCockburn.html">AlistairCockburn</a>
      </p>
      <hr/>
      <p>
        Known to bridge players as the LawOfRestrictedChoice.
      </p>
      <hr/>
      <p>
        Your original choice has a chance of 1/3 to win the prize. This doesn't change no matter what the moderator will do. Consequently, the chance that the prize is hidden behind one of the two remaining doors is 2/3.
      </p>
      <p>
        So, now, the moderator opens one of the goat doors, but not yours. Your original choice still has a chance of 1/3 to be correct, but the two thirds for the other two doors now only apply to one door. That's why switching doors is smart.
      </p>
      <p>
        A little ASCII art  [:)] 
      </p>
      <p>
        After your original choice:
      </p>
      <code>
        +------+  +------+ +------+<br/>
        |  ?   |  |  ?   | |  ?   |<br/>
        +------+  +------+ +------+<br/>
        your choice<br/>
      </code>
      <code>
        \-------+--------/ chance to win:<br/>
        |             1/3<br/>
        chance to win: 2/3<br/>
      </code>
      <code>
        +------+  +------+ +------+<br/>
        | goat |  |  ?   | |  ?   |<br/>
        +------+  +------+ +------+<br/>
        chance to  chance to<br/>
        win: 2/3   win: 1/3<br/>
      </code>
      <p>
        <em>I'd pick the goat and win </em>100%<em> of the time!</em>
      </p>
      <hr/>
      <p>
        Label the box you picked as A, Monty picked as B, the other as C.
        The game is equivalent to the following:
      </p>
      <p>
        You have two choices: do not switch and get all the prize in A; or switch and get all the prize in (B and C). Switching is twice as good as not switching. Monty tells you that all the prize in (B and C) is concentrated in C alone. So switching to C is equivalent and still gets you all the prize in (B and C).
      </p>
      <p>
        Still have problems?
      </p>
      <p>
        Do a simulation and verify that in the long run:
      </p>
      <code>
        (1) The total number of prizes in B and C equals that in C alone. <br/>
        (2) The total number of prizes in B and C is about twice that in A.<br/>
      </code>
      <p>
        And conclude that
      </p>
      <code>
        (3) The total number of prizes in C is about twice that in A.<br/>
      </code>
      <hr/>
      <p>
        This reminds me of the <a href="TwoEnvelopeProblem.html">TwoEnvelopeProblem</a>.
      </p>
      <hr/>
      <p>
        I understand the 2/3 vs 1/3 explanation, I believe, and I'll accept that tables and MontyHallSimulations prove it correct. But I don't understand why the problem isn't equivalent to this problem:
      </p>
      <p>
        <em>You have one box; Monty has another box. One of those two boxes contains a prize; the other is empty. Should you exchange boxes?</em>
      </p>
      <p>
        It seems to me that the initial 1-of-3 choice in the original problem is irrelevant. The revelation of one empty box simply changes the available choices to two, without providing any other information. Can someone explain this?
      </p>
      <p>
        <em>Both before and after the change, Monty's unopened boxes contain the prize with probability 2/3. The "simple change" implies those probabilities are the same after the change, but now "Monty's unopened boxes" becomes "Monty's unopened box". In your alternative scenario, much the same applies, but the initial probabilities are different (both 1/2).</em>
      </p>
      <hr/>
      <p>
        If you think the answer to the <a href="MontyHallProblem.html">MontyHallProblem</a> is that it doesn't make a difference, you are confusing it with <a href="NotTheMontyHallProblem.html">NotTheMontyHallProblem</a>. -- <a href="AndrewMcGuinness.html">AndrewMcGuinness</a>
      </p>
      <hr/>
      <p>
        I think the confusion arises because even though the probability that Monty opens one door is 1/2, the choice is not random. Once, I had a co-worker (with limited skills in programming and math) actually scream at me when I discussed this because HIS PROBABILITY PROFESSOR had told him it didn't matter if you switched or not. So much for higher education in this country. Though I believed the doesn't matter scenario till I ran a simulation, saw the 2/3 result for switching, and sat down to work out the conditional probabilities. -- <a href="RobertField.html">RobertField</a>
      </p>
      <hr/>
      <p>
        I had the good fortune to discuss this at length via email with one of the folks here.  Here's another way of looking at it. Suppose that there is a lottery in which there are a million tickets and a million dollar prize. Winners are chosen by drawing a matching ticket from a really big hat. You have one ticket. Monty eliminates all the other tickets but one.  Somehow we know that all the tickets he eliminated were not winning tickets. Now would you accept the ticket Monty offers?  The answer should be yes. It should be obvious that between your ticket in one hand and all the other tickets in the other hand, that you are more likely to win when you hold all the tickets. -- <a href="MattSimpson.html">MattSimpson</a>
      </p>
      <p>
        <em>Unless Monty's elimination process was random, avoiding the winning ticket merely by chance.</em>
      </p>
      <hr/>
      <p>
        Ok, my attempt to explain the <a href="MontyHallProblem.html">MontyHallProblem</a>: 
      </p>
      <p>
        When you pick a box, you have a 1/3 chance of being a prize. After Monty eliminates an empty box, the other box has a 1/2 chance of being a prize. Therefore, it pays to switch. -- <a href="SeanOleary.html">SeanOleary</a>
      </p>
      <p>
        [<em>No. With 1/3 chance, you pick the box with the prize, and Monty chooses one of the other boxes at random. With 2/3 chance, the prize is in one of the boxes you didn't pick, and Monty </em>'must<strong> choose the empty box to open and show you, leaving the other box, which must have the prize. So, if you always change boxes, 1/3 of the time you lose, 2/3 of the time you win. So it is favorable to always switch. -- </strong><a href="RobertField.html">RobertField</a><em>] (Robert, isn't that what's said lower down in the para beginning "Of course"?)</em>
      </p>
      <p>
        <em>And how did you know that "the other box has a 1/2 chance" was correct?</em> 
      </p>
      <p>
        Monty has better information. For him, it's always a 50/50 split. He always eliminates an empty box. 
      </p>
      <p>
        <em>But the probabilities have to sum to 1.</em>
      </p>
      <p>
        Probabilities have to sum to 1 in the same scenario. They're two different scenarios here. My scenario, where each box has a 1/3 chance of winning (3 * 1/3 = 1) and Monty's scenario, where there are only 2 boxes, each with a 1/2 chance of winning (2 * 1/2 = 1). Monty has better odds because he has better information.
      </p>
      <p>
        <em>But then your logic breaks down, since your choice is based on comparing probabilities arising in different scenarios. Anyway, Monty may be choosing to open either of two empty boxes - in which case, he can give each a 50/50 chance of being selected. However, in the other cases, Monty doesn't have a choice of empty box to reveal, and so a 1/2 chance doesn't arise.</em>
      </p>
      <p>
        Let's change the game to roulette, in order to show that comparing probabilities is valid. For the moment, let's forget about <strong>0</strong> and <strong>00</strong>. I place a bet on the first dozen (one chance in three). I'm blindfolded and Monty spins the wheel. Then Monty says I'll get the same payoff if I change my bet to black or red (one chance in two). Should I switch to get the better odds?
      </p>
      <p>
        <em>Of course, but that's very different. In the previous scenario, the original choice has probability 1/3 of having the prize, so the probability of the prize being in the remaining box(es) is 2/3. Bringing in 1/2 for comparison purposes is simply incorrect.</em>
      </p>
      <hr/>
      <p>
        I call these discussions that are not on target <a href="WinoArguments.html">WinoArguments</a>, after the endless circular discussions by drunks in bars.
      </p>
      <p>
        Hic! 'sright, but we're learning Sean to do maff proper... Hic!
      </p>
      <hr/>
      <p>
        All right, after being anonymously berated for not knowing my maths, I decided to write my own simulator. Here's my revised take:
      </p>
      <p>
        I choose one of three boxes and have a 1/3 chance of picking the correct box. That means the other two boxes have a 2/3 chance of being the correct box. Of those two boxes, Monty can always show me an empty box. Therefore the remaining box has a 2/3 chance of being the correct box.
      </p>
      <p>
        Thanks for your attempts to edumacate [sic] me. The best advice was to try it out myself. (Now would someone else clean up this thread? I don't mind my mistake being preserved for posterity, but comparing me to a wino, tsk tsk. :-) -- <a href="SeanOleary.html">SeanOleary</a>
      </p>
      <hr/>
      <p>
        You don't need to switch to get 50/50 odds:
      </p>
      <p>
        Seems to me that each box of the three boxes have 50% chance to win. This is due to the removal of a wrong box. If Monty discloses an <em>unpicked</em> box, and then proposes a chance to switch, he has just removed one <em>unpicked</em> box from the standing, leaving just the remaining two boxes (yours and the other unpicked box). You have 50% no matter what. Correct or not, the odds are now 50% and no switch is required to raise your odds from 1/3 to 1/2 (Monty did this by removing one box from the mix).
      </p>
      <p>
        Pick the correct box, Monty removes a wrong box, and you now have 50/50 odds. (switch and lose: stay and win)
        Pick a wrong box, and Monty removes the other wrong box, and you now have 50/50 odds. (switch and win: stay and lose)
        Switch or not, you have the same odds.
      </p>
      <p>
        <em>Did you read this page carefully?  You are incorrect, in one of the usual ways.  Granted, this page is a mess of explanations and confusion, but re-factoring it has failed before.</em>
      </p>
      <p>
        I see now looking at it this way. I reserve one box and Monty reserves one box and we discard ALL the rest (Monty must pick the winning box if I hadn't). Now we have gotten down to two boxes with imbalanced odds: my choice is 1/n while his is n-1/n. If we started with 100 boxes, my pick would be 1/100 while his has a 99/100 chance of being correct (his box can only loose if I reserved the winning box.) Goal then is to first pick a loosing box, then switch after he narrowed it down. Experiment: Try with a deck of cards. Try to find an Ace of spaces. Pick one card. Monty eliminates all but one. Now we have 1/52 and 51/52 odds for the two cards. Pick. Chances are it's Monty's card.
      </p>
      <hr/>
      <p>
        Not that I really expect it to help, but I wrote up a different presentation of the problem, which may help guide someone to new understanding: <a href="http://www.whiterose.org/cluey/archives/003576.html">http://www.whiterose.org/cluey/archives/003576.html</a>
      </p>
      <hr/>
      <p>
        I'm kind of shocked. Everyone here has really complex arguments. I think I have an argument that is easier to follow, because all it uses is the LawOfTotalProbability. I hope it's right. :) Let me demonstrate:
      </p>
      <p>
        When we start off, we have to choose a door. The probability that we're right is 1/3, and the probability that we're wrong is 2/3. We'll choose door 1. 
      </p>
      <ul>
        <li>
           P(Door1) = 1/3
        </li>
        <li>
           P(Door2) + P(Door3) = 2/3
        </li>
        <li>
           P(Total)   = 1
        </li>
      </ul>
      <p>
        Now, Monty comes along and says, "Well, if you look behind door #3 you see a goat? Do you want to keep your door, or change it?"  Now, what just happened? Monty <em>told</em> us something. 
      </p>
      <ul>
        <li>
           P(Door1) = 1/3
        </li>
        <li>
           P(Door2) + P(Door3) = 2/3
        </li>
        <li>
           P(Door3) = 0 (Monty told us)
        </li>
        <li>
           P(Total) = 1
        </li>
      </ul>
      <p>
        Wait, but we know that P(Door3) = 0. The law of total Probability says that we have to have a total of 1. We know that Door3 can't be it, because Monty told us that P(Door3) = 0. So, to make P(Door2)+P(Door3) = 2/3 and satisfy our law of total probability, we must say that P(Door2) = 2/3. 
      </p>
      <p>
        So, P(Door1) is 1/3.  P(Door3) is 0. P(Door2) is 2/3. P(Total) is 1. 
      </p>
      <p>
        What do you think? The reason that it's not a 50/50 chance is because these trials are not separate, they're linked. If they were totally separate, and no information was shared (choose one of these three doors for no apparent reason, then come back next week and choose one of two doors for a prize), then it would be a 50/50 chance. There would be no link via the LawOfTotalProbability. -- <a href="DaveFayram.html">DaveFayram</a>
      </p>
      <p>
        <em>You're quite right.  It is shocking.  (And your exposition is 100% correct.)  However, I prefer </em><a href="AlistairCockburn.html">AlistairCockburn</a>'s explanation, which is the same as yours, but shorter.  To paraphrase:  the probability you chose the wrong door initially is 2/3, so the probability of being right if you switch is also 2/3.  Note from this the four-door variant:<em> </em>
      </p>
      <ul>
        <li>
          You choose a door
        </li>
        <li>
          Monty opens one of the remaining three doors, revealing no prize
        </li>
        <li>
          Monty gives you the chance to choose one of the remaining doors
        </li>
        <li>
          You think you have a 50% better chance that way, so you accept Monty's offer
        </li>
        <li>
          This page becomes <a href="TooBigToEdit.html">TooBigToEdit</a>...
        </li>
      </ul>
      <hr/>
      <p>
        I've often wondered if the difficulty people have in accepting the solution would be diminished if it were posed in terms of Monty's choices, not the contestant's.
      </p>
      <p>
        Consider it this way: after the contestant has made a choice, what is the probability that Monty can leave a door closed that has the prize behind it? 
      </p>
      <p>
        The contestant had a 1/3 chance of getting it right thus leaving Monty with a 2/3 chance of leaving a door closed with a prize behind it.  So after Monty has made his choice, there is a 2/3 probability that the door he left closed has the prize behind it. 
      </p>
      <p>
        Is that any easier as an explanation?
      </p>
      <p>
        -- <a href="ChanningWalton.html">ChanningWalton</a>
      </p>
      <hr/>
      <p>
        Many smart people have been unable to see the right answer, even when it is explained to them many ways (Personally, I find the empirical approach, played as a betting game with REAL MONEY, to be the quickest way to get someone to understand it.  A simulation doesn't concentrate your mind as well as losing money does.)  The lesson I take from people's inability to understand this is that there are likely to be MANY other substantial mistakes in quantitative judgment that even smart people make all the time.  If you can identify these fallacies, you can probably use them to make a lot money, at least for a while.  
      </p>
      <p>
        -- <a href="PeteProkopowicz.html">PeteProkopowicz</a>
      </p>
      <hr/>
      <p>
        I've run it empirically and I accept the results, but I still find the theory unsatisfying. Moreso because people make so many convoluted other examples in attempt to clarify. Some of the more common things I have problem with is a claim that Monty knowing where the prize is makes a difference, which it does not. Only the actions taken and the information revealed make a difference. -- ChrisMellon
      </p>
      <p>
        Monty's knowledge of where the prize is <em>does</em> matter. After your initial choice, the door he opens never contains the prize. This can only be accomplished if he knows where the prize is.
      </p>
      <p>
        No, it doesn't. What matters is that the door opened will not contain the prize, nor will it be the door you picked. *Why* that is the case does not matter. A gust of wind blowing a random door open will reveal exactly the same information, so long as it opens the same door that someone with knowledge would have picked. 
      </p>
      <p>
        Of course it does - Monty ALWAYS opens a door without a prize! A random door opening will miss sometimes.
      </p>
      <p>
        <em>No. It's a constraint of the simulation that the opened door will always be empty, and will not be the door you picked. Whether that happens by random chance or because Monty knows where the prize is doesn't matter. What matters is that the door opened is not your door, and does not have a prize. Period.</em>
      </p>
      <p>
        Let's try something - let's play the game withh 100 doors. Choose 1, then Monty opens 98 of the doors, revealing them empty - now do yuo change doors? I sure would.... <a href="NissimHadar.html">NissimHadar</a>
      </p>
      <p>
        <em>Missing the point... let's play the game with 100 doors. Choose one door. A crazed felon runs into the studio, screaming, then opens one door and dashes through it. That door doesn't have a prize. Monty is freaked out and can't remember which door you picked, so he lets you pick again. You remember the door you picked before, so do you choose that door (which is not the one the felon opened), or one of the other 98 doors?</em>
      </p>
      <p>
        <a href="AhHa.html">AhHa</a>, I see. To paraphrase, is your point that the contestant, despite having no knowledge of why Monty chose that particular door to open, still has enough information to choose the better option (switch)? In that sense, the constraint that Monty always chooses a prizeless door to open is unnecessary to understanding the solution to the problem.
      </p>
      <hr/>
      <p>
        Let's simplify this to basics.  Which is the better option, to choose Door Number 1 or to choose Door Number 2 and Door Number 3?  This is the underlying choice in this game.  When you initially choose Door Number 1, there is a 1 in 3 chance you are correct.  You already know that there is a 100% chance that there is no prize behind either Door Number 2 or behind Door Number 3.  Revealing one of them to be empty and then offering the other is equivalent to immediately offering the choice of both.
      </p>
      <hr/>
      <p>
        Come on, guys. This is basic conditional probability.
      </p>
      <ul>
        <li>
          Probability of picking winning box at first: 1/3
        </li>
        <li>
          Probability of picking losing box at first: 2/3
        </li>
      </ul>
      <ul>
        <li>
          Probability of winning with a swap GIVEN that you have the winning box: 0
        </li>
        <li>
          Probability of winning without swap GIVEN that you have the winning box: 1
        </li>
        <li>
          Probability of winning with a swap GIVEN that you have the losing box: 1
        </li>
        <li>
          Probability of winning without swap GIVEN that you have the losing box: 0
        </li>
      </ul>
      <p>
        So, if you swap, the probability of winning is (1/3 * 0) + (2/3 * 1) which is obviously 2/3.
      </p>
      <p>
        And if you don't, the probability of winning is (1/3 * 1) + (2/3 * 0) which is obviously 1/3.
      </p>
      <p>
        Therefore, it is always better to swap. Intuitively, you are more likely to have picked a losing box on your first pick.
      </p>
      <hr/>
      <p>
        See <a href="MontyHallSimulation.html">MontyHallSimulation</a>
      </p>
      <hr/>
    </div>
  </body>
</html>