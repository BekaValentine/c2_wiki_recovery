<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        What Is Intent
      </h1>
      <p>
        All these debates about definitions involving "intent" raises the big question: what is a good definition of "intent"? And please do not use synonyms such as "purpose" and "goal".
      </p>
      <p>
        Definition Candidate 1: <em>"Intent" is the set of dynamic states and/or static structures in a system that are necessary to achieving an identifiable outcome.</em>  (Other def's given later.)
      </p>
      <p>
        So <em>anything</em> that changes has intent if we have enough info to do prediction? That certainly deviates from the colloquial meaning. Peeling paint does not have "intent" to most normal people.  If you want to invent a working technical term, that's fine by me, but if it has no match to common usage, then call it something different, like "state-based prediction" or the like.
      </p>
      <p>
        <em>I created the above definition by examining a number of legal, literary, social, psychological, and general dictionary definitions for "intent", then abstracted them until they converged, thus representing their common essence.  Therefore, it is directly based on common usage.  I'm not sure paint can be considered a system, but its interaction with a given environment may be, in which case the definition applies.  Anyway, now it's your turn.  What is "intent"?</em> 
      </p>
      <p>
        Oh great, now we are stuck on the definition of "system". Thanks a lot :-)
      </p>
      <hr/>
      <p>
        <em>Unfortunately, it's (a) rather difficult to create a definition that consists entirely of the words "a", "and", & "the", and (b) there'll always be some wag who'll debate the meaning of those, too.  Now then:  Where's your definition?</em>
      </p>
      <p>
        It looks like you took the <strong>lowest common</strong> features, which does not necessary mean an accurate reflection of usage. See <a href="TermUsageVersusRigor.html">TermUsageVersusRigor</a>.
      </p>
      <p>
        I'm still working on a candidate def of "intent". However, it usually involves a plan, or mental simulation and a schedule or queue to carry the plan out. This is the <strong>difference between instinct and intent</strong>. Instinct is just a pre-set reaction. Intent involves some kind of simulation with the potential to turn that simulation into a response. I don't see anything in your def that separates out instinct.
      </p>
      <ul>
        <li>
           Addendum: See "Simulation and Instinct" below.
        </li>
      </ul>
      <ul>
        <li>
           Addendum: Candidate definition 2: "The response to the occurrence of a simulation of the world or domain by a system or biological unit. This response varies based on the outcome of the simulation such that aspects of the response can be found that mirror the simulation." -t
        </li>
      </ul>
      <p>
        <em>Given that a brain is a system of neurons, what is a "mental simulation" or "plan" but set of dynamic states (neural activations) and/or static structures (neural connections)?  I do not distinguish instinctive from non-instinctive behaviour.  Many seemingly conscious behaviours appear to be instinctive, or at least automatic.  A decision to choose action A vs B, for example, has been shown through research to manifest as distinct brain activity prior to conscious awareness of the decision.  I would also argue that the intent of the autonomous nervous system is to maintain bodily functions, and the intent of reflexes are to react appropriately to stimuli in circumstances where higher brain function would be too slow.</em>
      </p>
      <p>
        Most definitions are shaped by common perceptions, not scientific truth. By common perception, I reckon that most people make a distinction between instinct and intent. I agree that the distinction between modeling-first and instinct (hard-wired) may be fuzzy, but perhaps there is a continuum between instinct and intent. 
      </p>
      <p>
        <em>I assumed, perhaps erroneously, that the goal was to achieve a rigorous working definition -- one reflective of scientific truth -- as a basis for further discussion on the pages where the assumed (and informal) definition of "intent" has become contentious.  If you're merely looking for a casual definition, I'm sure any dictionary will suffice.</em>
      </p>
      <p>
        Similar to what I mentioned above, perhaps you should abandon the usage of the text "intent", since it deviates from common usage. Call it "fliffnarfer" or something, just not "intent". It will otherwise risk excessive confusion. My pencil sharpener itself does not have "intent" to most people. I would note that the legal system makes a fairly heavy distinction between intentional and accidental. If you drive poorly and kill someone as a result, its a lower sentence than if you purposely plan to flatten somebody using your car. ("Planning" generally implies a mental model/simulation of the process.)
      </p>
      <p>
        As far as "the goal was to achieve a rigorous working definition", you seemed to achieve that by making it useless, or at least differ too far from common usage. You merely described cause-and-effect, which even the simplest things known have some degree of. Rocks "have intent" by your def. [Paragraph added later.]
      </p>
      <p>
        <em>Actually, I've never used "intent" on this Wiki except in an informal sense (I'm Correspondent #1, not Correspondent #2), but you asked for a definition so I gave you one.  Within such a definition, I see little opportunity for confusion.  I still maintain that you are confusing "intent" with "conscious will".</em>
      </p>
      <p>
        It's not me that's confused, it's the people who make definitions via usage. Again I ask, what's the difference between your version of "intent" and "instinct"?
      </p>
      <p>
        <em>I answered that, above.  To wit: "I do not distinguish instinctive from non-instinctive behaviour."</em>
      </p>
      <p>
        So all behavior of anything is "intent" as long as the outcome is "identifiable" and part of a "system"? 
      </p>
      <p>
        <em>No, behaviour is not intent.  It would be more accurate to say that "intent" is the states and structures of a system that result in behaviour.</em>
      </p>
      <ul>
        <li>
           Understood. I loaded the wrong end of the gun.
        </li>
        <li>
           <em>What is the intent of the end of a gun?</em>
        </li>
      </ul>
      <p>
        Also, do you agree that to most people there is a difference between "intent" and "instinct"?
      </p>
      <p>
        <em>Perhaps, but I believe this to be a product of a naive understanding of instinctive and non-instinctive behaviour, rather than a misunderstanding of the meaning of intent.  I believe most people incorrectly regard non-instinctive behaviour as "special".</em>
      </p>
      <p>
        I don't agree it is necessarily "naive". Planning, such as a mental model, is certainly a feature of human intelligence even if instinct is often mistaken for planning. In other words, the common mistaking of one for the other does not change the fact that planning exists.
      </p>
      <hr/>
      <p>
        So by definition candidate #1, a rock sitting on the top of a melting iceberg has "intent" because the outcome is identifiable? That is, the rock has "intent" to move toward ground-level.
      </p>
      <code>
        ~  <-- heat from weather<br/>
        O  <-- rock<br/>
        A  <-- iceberg<br/>
      </code>
      <p>
        <em>No, according to definition candidate #1 the whole </em>'set<strong> of states (rock + iceberge) might embody a very narrow intent. The rock alone would possess only intent that could be recognized as identifiable outcomes to be achieved by the rock alone (i.e. without the iceberg in the picture).  Consider </strong>ChineseRoom.<em></em>
      </p>
      <p>
        For clarification, I meant the "situation" of the rock sitting on the iceberg with warmth, not just the rock itself. Or perhaps the "system" of heat + rock + iceberg.
      </p>
      <p>
        As far as ChineseRoom, I don't see it applicable. The issue is not whether "understanding" is taking place.
      </p>
      <p>
        <em>The lessons of a thought experiment are wasted upon those, such as yourself, who do not automatically apply the same experiment to other possibilities when it is suggested to them.</em> 
      </p>
      <ul>
        <li>
           If you don't want to answer, just say so instead of turning it into an insult or rudeness. ChineseRoom appears related to the question of the definition of "understanding", which is not necessarily the same as "intent" (although if answered, could provide a blue-print for defining "intent" clearly.)
        </li>
      </ul>
      <p>
        But anyhow #1 appears to be so wide as to not exclude enough to be useful. If one knows enough about ANY set of objects and their environment, they have "intent". It's almost a synonym for "predictability". Further, it's still hinging on properties of the observers, not the objects themselves.
      </p>
      <p>
        <em>I would not support definition candidate #1 myself, because it describes an idea closer to a 'plan' or 'implementation' rather than an 'intent'. Plans and implementations and actions have both intended consequents and unintended consequents. That said, it doesn't really hinge on observers themselves, but rather on what is observable.</em> 
      </p>
      <ul>
        <li>
           <strong>Please use some kind of unique page handle, people.</strong> I don't care if its a real name or not.
        </li>
      </ul>
      <p>
        <em>I'd associate with 'intent' those consequents for which the plan/implementation (dynamic or static structure necessary to achieve an identifiable outcome) was obtained or built </em>'regardless of how<em>' the plan/implementation came into being. That the 'how' is an instinct or reflex doesn't matter to me. Bears intend to sleep during the winter to conserve energy while food is difficult to obtain; they don't intend to sleep during the winter to make themselves more vulnerable, or we wouldn't observe them shacking up in caves. A CPU is intended to rapidly execute machine code according to a fixed set of rules; they aren't intended to make good ovens for cooking omelets. A program might be intended to print out the Nth fibonacci number, given N. The human nervous system intends to flinch upon detecting a cause of potential eye damage.  Thus 'intent' is temporal in nature, existing intent is part of an object's past, and immediate-future intent is part of an object's present.</em> 
      </p>
      <ul>
        <li>
           Please clarify the first sentence. It seems to be missing something. As far as the bear example, bears don't hibernate for a purpose/plan known to them. It's purely instinct. Are you saying that natural selection has "intent"? 
        </li>
        <li>
           <em>As I have been using the word 'intent' (on this page and all others), instinct is usually intentional - it involves taking action with a purpose or a goal.  You seem to think "intent" = "conscious intent"; but if I wanted to say "conscious intent" I'd use the word "conscious" and not think it redundant.  I am not saying that natural selection (a theory of survival) has intent.  But the idea that species have developed mechanisms intended to support the survival of individuals and groups within it is perfectly within reason AND within the normal person's use of the word 'intent'.  Saying that "A cat's claws are not intentional" is, to me, the same as saying "A cat's claws are accidental or purely coincidental."  And I'd disagree with the latter.</em>
        </li>
        <li>
           Natural selection is a statistical relationship. Their may also be a statistical relationship to the placement of rocks at the bottom of the ocean due to melting iceberg patterns. Typically we call these "patterns" in nature. Certain combinations of situations tend to cause certain outcomes. Natural selection is no different. It's merely cause-and-effect. What's missing is definition elements to distinguish between intent-related cause-and-effect and non-intent-related cause-and-effect. Unless your position is that <em>all</em> C&E is "intent", which would be rather odd, because air molecules bumping each other around would then be "intent". -t
        </li>
      </ul>
      <p>
        <em>Of course, </em>'detecting<strong> intent is the job of an observer. But an observer can fail to detect it, which makes intent objective (truly subjective things simply don't exist if you don't 'detect' them). In all cases, intent is detected using the simple test of probability over a large set of observations... the exact same way we detect baseballs, rockets, suns, oceans, beaches, and everything else we call 'objective'. E.g. the probability of a CPU being intended as an omelet cooking surface is quite slim given the observation of the crooks and crannies where omelet-gunk can get lost into, all of which make it a bad cooking surface. And the probability of a CPU </strong>not<strong> being intended to execute machine code is </strong>astronomically<em>' small, as the creation of something with a CPU's structure and capabilities is unheard of and even unimaginable in nature.</em>
      </p>
      <p>
        <em>In any case, any definition of 'intent' that does not touch on the issue of what is NOT intentional will be incomplete, including candidate #1.</em>
      </p>
      <p>
        <a href="PageAnchor.html">PageAnchor</a>: Jury
      </p>
      <p>
        But we have no way to apply consistent rigor to such. It's like a court case for murder: its a subjective jury process with bits and pieces of logic tossed in. We can define "foo" as "whatever the jury says foo is". But its a <a href="UselessTruth.html">UselessTruth</a> at best, at least in cases where clarity and rigor are required. It's not dissect-able. It's not automatable. It won't settle disputes.
      </p>
      <hr/>
      <p>
        <strong>Compare to "Beauty"</strong>
      </p>
      <p>
        "Beauty" can also be approximately determined by a "test of probability over a large set of observations". Algorithms even exist that reasonably predict peoples' survey scores on facial photographs, something that can't yet be done with "intent".
      </p>
      <p>
        But behavior prediction is a weak form of modeling. It is fraught with errors, and may not tell us much about the underlying mechanism. Multiple regression may be fairly accurate, but that does not necessarily mean the underlying mechanism of the thing being predicted is actually driven by multiple regression's result formula. Thus, "intent" determined by a jury is of limited use. 
      </p>
      <p>
        It behooves me why you want to hold on so tightly to such a weak tool. It's a kind of faith only a creationist would love.
      </p>
      <p>
        --top
      </p>
      <hr/>
      <p>
        Re: "In all cases, intent is detected using the simple test of probability over a large set of observations... the exact same way we detect baseballs, rockets, suns, oceans, beaches, and everything else we call 'objective'. E.g. the probability of a CPU being intended as an omelet cooking surface is quite slim given the observation of the crooks and crannies where omelet-gunk can get lost into..."
      </p>
      <p>
        A baseball-detector could be built that has <strong>little or nothing to do with the actions of the manufacturer, observer, or user</strong>. That is because it would most likely be based on the characteristics of a baseball: shape, color, weight, threading pattern, etc. However, your CPU analogy looks at how people actually use it or what they "had in mind" while building it, and is thus not comparable.
      </p>
      <p>
        <em>The definition of a baseball also has to do with what people "had in mind" while building it (its use in baseball). But the definition of a baseball is not the same as the baseball-detector, which makes a probabilistic estimate about the presence or absence of a baseball on the basis of observable characteristics. In this same sense, an intent-detector does not require access to what people "had in mind" while building an object, and may rely upon immediately observable characteristics.</em>
      </p>
      <ul>
        <li>
           <a href="PageAnchor.html">PageAnchor</a> baseball_1 :
        </li>
        <li>
           A definition can be based on the same tests that a detector uses. Ties to what the factory "had in mind" are unnecessary. If a planet with lots of rubber produced a fruit which looked and behaved just like an Earth baseball, by most accounts (common usage), it's still a "baseball" even if the fruit tree had no "plan" to make them shaped like Earth stuff. It's a lucky coincidence. Thus, planning is moot to qualify as a baseball. [Paragraph expanded after replies below were made.]
        </li>
        <li>
           <em>A definition is tied to the usage in a language. Playing </em><a href="HumptyDumpty.html">HumptyDumpty</a> and changing the definition at whim is not allowed - it means you're now speaking a different language (that is exactly the same as English <em>except</em> for a few changes). Working definitions of 'baseball' or 'intent' can be created, but are ultimately 'working definitions' and not English definitions.<em></em>
        </li>
        <li>
           English is vague. Often there is nothing to "change" because the range of possible interpretations are so wide open.
        </li>
        <li>
           <em>English is vague, I agree.  The latter half of your statement certainly needs clarification. Are you condoning equivocation by asserting definitions are still in use 'unchanged' after you've implemented a particular 'interpretation'?</em>
        </li>
        <li>
           What did I do that is allegedly misleading or deviate from standard usage? Our models, even unfinished ones, still need to be tested against usage, and yours fails. There <strong>must</strong> be something similar to "planning" in a definition of "intent" to qualify, but yours totally lacks it. -t
        </li>
      </ul>
      <p>
        If catastrophe turned the world into a Mad Max dystopia (movie), then people may indeed start using CPU's as cooking devices on a mass scale. By your reckoning, the nature of the CPU has now changed despite having the same physical characteristics. 
      </p>
      <p>
        <em>If you created another device (e.g. a CPU placed under an iron pan surface) then the intent of that whole device is different from the intent of the CPU on its own... and so are its physical characteristics.</em>
      </p>
      <ul>
        <li>
           Let's not complicate the example without purpose. The CPU portion of such a thing is still the CPU.
        </li>
        <li>
           <em>The CPU portion of such a thing is not the whole thing. That is, it is a replaceable component whereby the replacement only needs to output heat. By observing the construction and usage of such a device, it would be readily deducible that the 'intent' of using the CPU in such a device is to produce the heat, rather than use as a CPU.</em>
        </li>
        <li>
           You are changing to scope. I am focusing on the chip for this discussion.
        </li>
        <li>
           <em>You mentioned a context for use of the CPU, such as its use as a cooking device. I'm curious how you expect to use or identify the use of a CPU as a cooking device if there is nothing else in the universe because you're "focusing on the chip".</em>
        </li>
        <li>
           Please restate. I am focusing on determining properties of "the chip", not junk surrounding it.
        </li>
        <li>
           <em>You mentioned "using CPUs as cooking devices on a mass scale". You should not recognize or mention a usage context if you are focused on determining properties of "the chip" and specifically excluding the junk surrounding it. The assertion that you are focused on just the chip is inconsistent with your prior context, and should be disregarded as illogical.</em>
        </li>
        <li>
           We may have no way of knowing if the stuff surrounding is new or added later. We can only make jury-like probability guesses at best. I can use a rock as a paper-weight, but that does not mean the "intent" of the process that made the rock was to have it serve as a paper-weight.
        </li>
      </ul>
      <p>
        Definitions based on what the observer thinks are often problematic. We have to <strong>play Sherlock Holmes</strong> with their actions. This is <strong>not acceptable for technical definitions</strong>. 
      </p>
      <p>
        <em>Which isn't a problem here. What the observer thinks does not affect intent.</em>
      </p>
      <ul>
        <li>
           It also applies to makers and users.
        </li>
        <li>
           <em>Makers and users are objectively observable.</em>
        </li>
        <li>
           Yes, but that's not what we are talking about here.
        </li>
        <li>
           <em>Then why did you mention them?</em>
        </li>
      </ul>
      <p>
        We are in the technology business, not crime solving or human activity prediction.
      </p>
      <p>
        <em>Actually, some of us are involved in technology for solving crimes and predicting human activities.  In fact, if you've ever written a GUI, you ARE in the business of predicting human intent... and for preparing vectors to accept it.</em>
      </p>
      <ul>
        <li>
           True, but that's a side issue. Also, predicting behavior does not necessarily need to involve intent. Neural nets can often predict behavior without "knowing" what something is "trying to do".
        </li>
        <li>
           <em>I agree that predicting behavior is different from predicting intent. When you predict intent, it opens doors to the possibility of finding 'better' ways to accomplish it.</em>
        </li>
      </ul>
      <p>
        Another problem is different observers/makers/users have different perspectives. If I use a CPU as an egg warmer, to me it's an egg warmer even if you use it as a CPU in the afternoon while I take a nap. 
      </p>
      <p>
        <em>And the fact that CPUs are very expensive compared to other egg warmers, likely to overheat the egg in one spot, and prone to damage after doing so would all be fine clues that you weren't using the CPU as it is intended. It especially doesn't mean that a "better CPU" will also be a "better egg warmer". In any case, mere differences in usage doesn't affect intent.  Indeed, you can often put devices, habits, plans, programs, and so on to unintended uses. You can pound a nail in with a glass vase, but that doesn't mean glass vases are designed for 'purpose' or 'intent' of hammering in nails.</em>
      </p>
      <p>
        Such determination is a vague guessing game. One is playing Sherlock Holmes. It is not comparable to a baseball attribute detector.
      </p>
      <p>
        <em>Wrong.  It is directly comparable. One is playing "Sherlock Holmes" to design a baseball attribute detector, too.</em>
      </p>
      <ul>
        <li>
           Irrelevant. Assume we find a baseball detector algorithm on the web with no history of its origin.
        </li>
        <li>
           <em>We'd likely still detect the intent of such a program, at least if we experimented with it enough.  The probability of a random program successfully distinguishing baseballs from other balls, rocks, debris, grenades shaped to look like baseballs, etc. is ridiculously low, so we'd have reason to believe that the intent of the program is to detect baseballs. We can detect baseball detectors, too. As with detecting all other objective things in the real world, doing so is probabilistic.</em>
        </li>
        <li>
           <em>Anyhow, "no history of its origin" is just you playing a game of "let's limit perfectly observable information". Playing that game can be fun, but you can't pretend that 'temporal' information should get special treatment.  Consider limiting spatial information. Can you tell whether a building is a home or a meth lab or a cardboard cut-out if you're only allowed to observe it from one position and using nothing but your eyes? It is true that we always work with limited information, but the limits of the information we work with is not the same as the limits of information available.</em>
        </li>
        <li>
           Doing science often involves removing variables one at a time to see the affects. Anyhow, my point is that definitions of everyday things do not require knowing "purpose" of manufacturing, or even the existence of manufacture as an origin, as illustrated by the rubbery planet analogy at <a href="PageAnchor.html">PageAnchor</a> baseball_1.
        </li>
      </ul>
      <p>
        Further, the factory owner's "purpose" is to make a profit. He/she doesn't care whether buyers use the vases for decorations or sex toys, as long as people pay for them. And even "decoration" is an oversimplification. If somebody buys vase X because it reminds them of their childhood, it is a psychological tool, not a "decoration". 
      </p>
      <p>
        <em>There are multiple purposes and multiple intents. The factory owner's "ultimate purpose" is probably not even to make a profit; it is above even that, such as to 'obtain happiness'. This doesn't prevent other intents; indeed, just as goals give rise to sub-goals in the creation of a plan, intent gives rise to intent in the execution of a plan.  'goal' and 'intent' are, after all, near synonyms.</em>
      </p>
      <p>
        It's all relative. Your vague feelings/notion-based reasoning is so imprecise on so many levels.
      </p>
      <p>
        <em>None of it is relative. It is simply layered. And I don't believe I have involved any "vague feelings/notion-based reasoning" - can you support that accusation?</em>
      </p>
      <ul>
        <li>
           And the more layers the more difficult and imprecise our guesses become. 
        </li>
        <li>
           <em>Is that another objective claim that I'm expected to accept without any support?</em>
          <ul>
            <li>
               My Objective Proofs: 0
            </li>
            <li>
               Your Objective Proofs: 0
            </li>
            <li>
               <em>So claims a person that argues </em><a href="ObjectivityIsAnIllusion.html">ObjectivityIsAnIllusion</a>.<em></em>
            </li>
            <li>
               Red herring; you haven't produced shit. 
            </li>
            <li>
               <em>Indeed. It is you who has been producing page after page of the same illegitimate shit. I don't repeat myself on each page. The proofs I've offered are listed in their original locations, such as </em><a href="MostHolyWarsTiedToPsychology.html">MostHolyWarsTiedToPsychology</a>.<em></em>
            </li>
          </ul>
        </li>
      </ul>
      <ul>
        <li>
           Trying to figure out a black box which is trying to figure out a black box which is trying to figure out a black box...etc...
        </li>
        <li>
           <em>There is a huge difference between incomplete information and abstracted black boxes.</em>
        </li>
      </ul>
      <p>
        And in programs something that is a "variable" to one person may be viewed as a "data structure" by another, and thus not a variable anymore than a database is a variable.
      </p>
      <p>
        <em>You'll need to clarify what you mean here.</em>
      </p>
      <p>
        Moved portions to <a href="LaynesLawDiscussion.html">LaynesLawDiscussion</a>.
      </p>
      <hr/>
      <p>
        I think it important to consider intent in relation to its limited extent and context.  This is an exploration of it in something of a story plus a pseudo-Socratic dialog.
      </p>
      <p>
        <strong>The Story</strong>
      </p>
      <p>
        A man decides he wants an egg-salad sandwich.  He goes to his refrigerator to grab the ingredients, but discovers he is short on eggs, mayonnaise, and pickles.  So he decides he needs to go to his local grocer and buy some.    He puts on a shirt, grabs his keys, and heads to his vehicle.  At the grocer, he grabs the eggs, mayonnaise, and pickles.  He can't remember how fresh his bread was so he picks up a new loaf, then he sees a hot woman on the cover of the monthly rag and buys it too.  He gets back in his vehicle and returns to his apartment, and discovers it unlocked.  A bit alarmed, he looks around the apartment but discovers nothing obvious is missing or in any greater disarray than usual, then chastises himself for forgetting to lock the door.  Discovering his loaf of bread is still decently fresh, he wraps the fresher one up in a bag and drops it into his freezer.  He flips through the magazine a bit, decides he doesn't really want it, and tosses it to his dusty pile of recyclables.  Then he gets started on his sandwich, boiling some water for the eggs and preparing to make his sandwich.
      </p>
      <p>
        <strong>The Questions</strong>
      </p>
      <p>
        <strong>Q:</strong> Did the man intend to have an egg-salad sandwich?
      </p>
      <p>
        <strong>A:</strong> This one seems to be an obvious 'yes'.  The man went to a considerable effort towards achieving the goal of having an egg-salad sandwich (and maybe even eating it, too).  It is unlikely we would observe his actions if he did not want an egg-salad sandwich.  Besides, the first sentence is clear: "a man decides he wants an egg-salad sandwich", though wanting alone probably isn't enough to justify 'intent' if the man has any ability to delay his own gratification.
      </p>
      <p>
        <strong>Q:</strong> Did the man intend to put on a shirt?  
      </p>
      <p>
        <strong>A:</strong> It is possible the man would not have put on a shirt if he didn't need to head out to the grocer, and the man wouldn't have headed out to the grocer if he weren't short on ingredients.  So, in the overall goal of having an egg-salad sandwich, it would be hard to justify claiming he intended to put on his shirt.  That said, he certainly didn't put the shirt on by accident.  One might say he intended to put on the shirt, but only in the context of his intermediate goal of purchasing ingredients.
      </p>
      <p>
        <strong>Q:</strong> Did the man intend to lock the door?
      </p>
      <p>
        <strong>A:</strong> This seems to be a trick question.  Assuming the man forgot to lock the door (which seems likely, given the evidence), then he neither <em>actively intended</em> to lock the door, nor did he take action to lock the door.  That said, he certainly regretted not locking the door, and he would have taken action to lock the door had he remembered to do so.  In some senses, one might say that he did intend to lock the door and that his failure to do so was the 'accident'.
      </p>
      <p>
        <strong>Q:</strong> Did the man intend to purchase eggs, mayonnaise, and pickles?
      </p>
      <p>
        <strong>A:</strong> I think so, yes.  That is the reason he went to the grocer.
      </p>
      <p>
        <strong>Q:</strong> Did the man intend to purchase the loaf of bread and magazine?
      </p>
      <p>
        <strong>A:</strong> Ugh, what a question.  He clearly didn't need these things, or want them.  He was tempted into buying the rag because of some hot cover girl.  He bought the bread because he forgot whether his loaf was fresh enough.  Still, he clearly bought the bread on purpose, as a just-in-case deal.  And the magazine didn't get paid for by accident... he just regrets buying it.  In some ways, this question is the opposite of the <em>lock the door</em> question, where he forgot to do something he wanted to do.  Here he did something he didn't want to do.  What can I say? He certainly didn't shell out the cash for the bread and the magazine by accident, so in the technical sense he paid for and thus purchased them intentionally.  To remain consistent with the <em>put on a shirt</em> question, we can look at context: his intent to buy the bread and magazine had limited extent.  It may be worth pointing out that an accident (forgetting whether his bread was fresh or not) seems to have been cause for the intentional behavior of purchasing a new loaf.
      </p>
      <p>
        <strong>Q:</strong> Does the man have free will?
      </p>
      <p>
        <strong>A:</strong> I don't know; I can't argue it either way from the story.  He certainly bought that rag as though he were programmed to do so ;-).  If he doesn't, then he is essentially programmed by his environment, his biology, and his history, and the 'plan' he made to get the egg-salad sandwich, even his desire to have one in the first place, weren't in his control.  But what does this mean?  Can a man 'intend' to have an egg-salad sandwich if that desire is programmed by his environment?  Damn you for making me question all my previous answers, <strong>Q</strong>!  :-(  But I suppose that if I accept my above reasoning is good then intent mustn't rely on free will.  Even if the man's thoughts and actions are all programmed by his environment and biology, sort of like <em>instinct</em>, his actions were still represented in his mind and, with the few exceptions noted above, did not occur by accident. 
      </p>
      <p>
        <em>I would rather not introduce "free will" into an already sticky definition topic. Free-will debates can get into the issue of whether the universe is deterministic or not, quantum physics, etc. I instead focused more on "instinct" versus planning. Instinct is "if condition set X, then do Y", while planning involves some kind of model of reality and then using the model to make decisions. There are probably processes in-between because some models can be really simple. Thus, I don't claim a hard boundary. But hopefully this point of view will keep the topic scoped better than getting into quantum probabilities. --top</em>
      </p>
      <p>
        [Yet, analysis of any model-based system will inevitably reveal its behaviour to be based on a collection of "if condition set X, then do Y" rules.  What is "planning" but the execution of these to establish a new system state (i.e., yet more "if condition set X, then do Y" rules) that guides action?]
      </p>
      <p>
        <em>That might be true, but the other way around is not. Instinct generally involves only pre-programming; while intent involves the creation of a new model(s) for new situations. --top</em>
      </p>
      <hr/>
      <p>
        Definition Candidate 2: "Intent is potential action, not realized action, discovered by analyzing or executing a model or simulation of reality."
      </p>
      <p>
        (Still needs some work. I am not happy with it.)
      </p>
      <hr/>
      <p>
        Just to make sure: Do we agree that some animals (e.g. primates, cats, dogs) have intent?
      </p>
      <p>
        I think what additionally is needed is the awareness of this execution or at least of the model. Awareness may be too vague also, so maybe "representation of the execution" suffices.
      </p>
      <p>
        Without this extension affective (in the heat of the moment) actions which nonetheless involves simulation (albeit maybe short-sighted ones) but not - well - dynamic adaptation of the model.
      </p>
      <hr/>
      <p>
        Candidate features of "intent". One or more may apply, depending on definition:
      </p>
      <ul>
        <li>
           Outcome is predictable
        </li>
        <li>
           Model or simulation of reality is created
        </li>
        <li>
           Awareness of activity based on model
        </li>
        <li>
           Reactive/Computational in nature.
        </li>
      </ul>
      <p>
        Another list has been started below. These perhaps can be merged, or their purpose/scope separated.
      </p>
      <hr/>
      <p>
        Is obfuscation of the meaning of intent the intent of this page?
      </p>
      <p>
        <em>Yes. </em><a href="TopMind.html">TopMind</a> created this page with that purpose. Thus his opening sentence: "and please do not use synonyms such as purpose or goal" despite the fact that neither "purpose" nor "goal" are not identical in meaning to "intent".<em></em>
      </p>
      <p>
        {Sorry, but I am not understanding the complaint here. I deny any intentional evil on my part. However, I agree it needs a link back to the topic(s) that started it all. In short, it spawned from a definition of "types", which to me came across as "intent to classify". If you have a good definition of "intent", then <a href="ActInsteadOfComplain.html">ActInsteadOfComplain</a> by giving it here and showing why it's wonderful. -t}
      </p>
      <hr/>
      <p>
        <strong>Simulation and Instinct</strong>
      </p>
      <p>
        Above it was suggested that a possible difference between "intent" and "instinct" involved "simulation". Instinct is generally a trigger(s) based on relatively simple external stimuli. Neurons may be pre-programmed to place a creature in "emergency mode" (adrenaline dumped into blood-stream, widened eyes, etc.) when a loud sound is heard. Such is generally a general rule(s) such as: "If a sudden sound exceeds X decibels, then put body into Alert Mode." It's a reaction based on relatively simple-to-state or simple-to-detect stimuli.
      </p>
      <p>
        Compare this with looking up and seeing a rock on a ledge right above you. When you see the rock above you, your brain makes a little simulation "movie" in which the rock falls down and crushes you. It's a physics simulations more or less. However, maybe if you worked in a coal or mineral mine for many years in which dynamite is often used, this may eventually be <strong>turned into an instinct</strong> in the brain in which if a rock-like shape is spotted (general image pattern recognition AI), then a simpler rule is put into place to speed up reaction: "If a roundish grey or tannish object is spotted above, then put body into Scram Mode". The brain then doesn't need to run a full simulation each time a rock is spotted: <strong>simpler proxy factors are put into place instead</strong> (or at least given processing priority). That's instinct. 
      </p>
      <p>
        The replacement of complex simulation with simpler detection may resemble the following. Let's suppose we identify stimuli factors with letters. "A" may be "angular shape spotted", "B" is "green is spotted", etc. When a mental simulation detects danger, the brain tends to remember which stimuli letters detected a "high" state during the danger. (This is factor tracking not necessarily part of the original simulation.) The repeated reinforcement of the stimuli combo's detected near the time of the danger eventually build up a "rule based" detection system that may resemble "If C, F, H, and Q are all high, then put body into Scram Mode" if translated into pseudo-code. Thus, the physics simulation is replaced by a factors-based rule(s). Neural networks are pretty good at this kind of multi-factor detection.
      </p>
      <p>
        Note that some of these rule sets may be inborn in humans and/or animals, and some are "learned" via repeated stimuli experiences. Also note that the organism may still begin a simulation to fine-tune the response, but the instinct is begun <em>first</em>. Sometimes we jump first, and then as we process the image while panicking, realize it's just a plastic spider instead of the real thing, for example.  Nature provided such shortcuts because the slow tend to get eaten, and simulations are often too slow. Thus, critters who continued to do it the long way stopped being around to reproduce more simulation-only organisms; and reflexes take priority over behavior.
      </p>
      <p>
        Now, there may be grey areas, for with enough factors and inter-connected rules, a crude simulator can be built or emerge. But, we can perhaps form generalizations that are sufficient to delineate the ends of the spectrum:
      </p>
      <p>
        Simulation often involves:
      </p>
      <ul>
        <li>
           <strong>Sequencing</strong>: the timing of events is important to the response
        </li>
      </ul>
      <ul>
        <li>
           <strong>Placement</strong>: the placement of events and features/objects relative to one another is important to the response
        </li>
      </ul>
      <ul>
        <li>
           <strong>Multiple Options</strong>: there are many possible outcomes, and the response reflects this fact
        </li>
      </ul>
      <ul>
        <li>
           <strong>Complexity of Computation</strong>: the computations often involve many resources (such as more neurons) and are relatively slow
        </li>
      </ul>
      <p>
        Determining which is happening is easier if we can dissect the computational mechanisms involved, such as sticking probes into a brain. However, one can also perform experiments to see whether instinct or simulation is happening if there is an element of repeatability. We could see if timing and placement made a difference to response, for example, or merely the presence of a candidate set of factors was sufficient to produce a response. -t
      </p>
      <hr/>
      <p>
        My dog knows <a href="WhatIsIntent.html">WhatIsIntent</a>
      </p>
      <p>
        Today when I kicked the ball I missed and kicked her head. Before you can say bill gates she had determined that the pain I caused was not my intent, therefore my action was not done with intent so she took after mis-directed ball.
      </p>
      <p>
        I refuse to let her read this because she will no longer be able to override the pain. I hate waiting for long for the ball to return.  -- <a href="PeterLynch.html">PeterLynch</a>
      </p>
      <p>
        <em>It could be that dogs are simply more forgiving than humans, regardless of pain-giver's intent. But I'm not sure yet how to test for such. I wish more humans had the dispositions of dogs. Dogs for the most part have had the a-hole bread out of them, unlike humans, who seem to have an extra gene for it. Let's breed them to be smarter and then sterilize humans so that we eventually have Planet of the Dogs.</em>
      </p>
      <p>
        There have been tests or studies done showing that dogs forgive and forget quickly, whereas humans have longer memory. Think about all the dogs that get abused, but don't bite their owners since the owner provides them food. I can't point to any of the studies right now, but I have read them before.
      </p>
      <p>
        <em>Dogs don't forget quickly, at least not the one's I'm familiar with. Perhaps more likely to give you a second chance, yes, but that's not forgetting.</em>
      </p>
      <hr/>
      <p>
        See also: <a href="NeglectingFreeWill.html">NeglectingFreeWill</a>, <a href="DefinitionsThatRelyOnIntent.html">DefinitionsThatRelyOnIntent</a> 
      </p>
      <hr/>
      <p>
        <a href="CategoryDefinition.html">CategoryDefinition</a>
      </p>
    </div>
  </body>
</html>