<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Wiki Spam
      </h1>
      <p>
        <a href="WikiSpam.html">WikiSpam</a> is a wikiwide problem. It won't be solved but wikiwide.
      </p>
      <p>
        These spammers add links to wikis, blogs, bulletin boards, and guestbooks so their Google page rank goes up. We need to all help keep an eye on this at all wikis and help clean it up where we can. <a href="WikiSpam.html">WikiSpam</a> in general is described at <a href="http://en.wikipedia.org/wiki/Blog_spam.">http://en.wikipedia.org/wiki/Blog_spam.</a>
      </p>
      <p>
        See other discussions on:
      </p>
      <ul>
        <li>
           ChongQed has a wiki devoted to the topic of <a href="WikiSpam.html">WikiSpam</a>: <a href="http://wiki.chongqed.org/">http://wiki.chongqed.org/</a>
        </li>
        <li>
           <a href="MeatBall.html">MeatBall</a> <a href="http://www.usemod.com/cgi-bin/mb.pl?WikiSpam">http://www.usemod.com/cgi-bin/mb.pl?WikiSpam</a>
        </li>
        <li>
           <a href="OpenWiki.html">OpenWiki</a> <a href="http://openwiki.com/ow.asp?WikiSpam">http://openwiki.com/ow.asp?WikiSpam</a>
        </li>
        <li>
           s23 <a href="http://wiki.s23.org/wiki.pl?WikiSpam">http://wiki.s23.org/wiki.pl?WikiSpam</a>
        </li>
        <li>
           GruenderWiki <a href="http://www.wikiservice.at/gruender/wiki.cgi?WikiSpam">http://www.wikiservice.at/gruender/wiki.cgi?WikiSpam</a> (German)
        </li>
        <li>
           WiCaFo <a href="http://cafoscari.wiki.taoriver.net/moin.cgi/WikiSpam">http://cafoscari.wiki.taoriver.net/moin.cgi/WikiSpam</a>
        </li>
      </ul>
      <hr/>
      <p>
        <a href="SpammedWikisDatabase.html">SpammedWikisDatabase</a> lists wikis currently getting hammered by spam. If you have a spare moment, please stop by, pick a page or two and delete the junk.
      </p>
      <p>
        ChongQed has examples of <a href="WikiSpam.html">WikiSpam</a> at various wikis along with the spammers' IP addresses, which can be used to ban spammers from your wiki.
      </p>
      <hr/>
      <p>
        <strong>Comments</strong>
      </p>
      <p>
        A difficult-to-judge case is one where a page is an advertisement for a commercial product or service that may seem <a href="OnTopic.html">OnTopic</a>. For example, a page devoted to describing a company that sells software or consulting services may seem relevant or useful at first glance. Such pages should be deleted if they have little information other than "We offer an incredible product/service. Please contact me if you want to buy it.".
      </p>
      <p>
        See <a href="WikiAsCommercialPromotionTool.html">WikiAsCommercialPromotionTool</a>.
      </p>
      <hr/>
      <p>
        An easy-to-judge case is one where a single word is linked to an off-site page. Those off-site pages then contain links to pornography related services. Two actual cases of this were witnessed on the words "Python" and "Wcms" on another wiki.
      </p>
      <p>
        This has also been observed on the <a href="AtomWiki.html">AtomWiki</a>, with the word SEO linking to an external site. Spam of this kind has become common on weblog comment systems and sadly it looks like widespread <a href="WikiSpam.html">WikiSpam</a> may become a big problem in the future.
      </p>
      <p>
        <em>Due to the way </em><a href="WardsWiki.html">WardsWiki</a> handles external links, this type of spam isn't possible here.<em></em>
      </p>
      <hr/>
      <p>
        Please Wiki developers, add
        : <meta name="robots" content="noindex,nofollow"/>
        to the old versions of Wiki pages. When spam is cleaned up, it persists in the version history of pages, so continuing to contribute to Google page rank. If you add this header, Google won't index the old spammy versions. I wrote some more about this technique (and analysis of an attack on my site) here: <a href="http://www.annexia.org/wiki_spam.">http://www.annexia.org/wiki_spam.</a> -- RichardWMJones
      </p>
      <p>
        <em>This has been in place on </em><a href="WardsWiki.html">WardsWiki</a> for a while now.<em></em>
      </p>
      <hr/>
      <p>
        Ah, if only we were in an Asimovian utopia where robots could do no harm. It seems ironic somehow that Wiki can survive humans but can be strangled to death by misguided automatons. Of course, if you really wanted to restrict automated contributions, you could include a miniature <a href="TuringTest.html">TuringTest</a> with each post. This is what Yahoo does when you sign up for an account; you have to read a series of letters and numbers in a distorted image (a <a href="CaptchaTest.html">CaptchaTest</a>). -- <a href="PatrickParker.html">PatrickParker</a>
      </p>
      <p>
        <em></em>HumanVerification is compared to other proposals on <a href="WikiSpamSolutions.html">WikiSpamSolutions</a>.<em></em>
      </p>
      <hr/>
      <p>
        I've had good results on several wikis I administer with a small patch to <a href="UseModWiki.html">UseModWiki</a> which counts the number of external links before and after the edit, and redirects you to a page explaining the spam protection scheme in effect if there are four or more external URLs in the newly edited version of the page. This behaviour can be inhibited if you're logged in, or coming from a specific IP range. Mail me if you want a copy. -- <a href="DonaldGordon.html">DonaldGordon</a>
      </p>
      <p>
        <em>I independently came up with the solution that </em><a href="DonaldGordon.html">DonaldGordon</a> mentions above. I'm using it here:<em> </em>
        <a href="http://www.otug.org/otcgi-bin/wiki.pl">http://www.otug.org/otcgi-bin/wiki.pl</a>
      </p>
      <p>
        <em>This solution of checking the number of new links on every edit works very very well. I'm amazed more wikis don't do this. It seems like it would stop almost all spammers. Has </em><a href="UseMod.html">UseMod</a> added this type of patch? -- <a href="RachelStruthers.html">RachelStruthers</a><em></em>
      </p>
      <p>
        This solution has been given the name <a href="WikiSpamBlocker.html">WikiSpamBlocker</a>, and the code patch (as used for <a href="MeatballWiki.html">MeatballWiki</a>) is given in Meatball: ShotgunSpam. It is compared with other proposals in <a href="WikiSpamSolutions.html">WikiSpamSolutions</a>.
      </p>
      <hr/>
      <p>
        I was thinking that it ought to be possible to create a script that listed pages in order of number of external links. Even if a page is spammed by only a few bytes and each spam is a different size, they <em>must</em> add external links, and I can't think of many normal pages that have that many external links. -- <a href="JamesKeogh.html">JamesKeogh</a>
      </p>
      <hr/>
      <p>
        Extremely frustrating are the sites that don't have a Revisions History - so the would-be gnome can only delete, not restore. Why would someone put up a wiki without the revisions link? I tried appending "?action=diff" to the page's url, but that doesn't work - I guess it's not the right syntax for the wiki engine in use. What a shame. -- TeganDowling
      </p>
      <p>
        <em>That's been discussed extensively, and is not just a spam issue. In particular, keeping a complete history of every page can be stifling and lead to disaster. Note that Google may have cached some earlier versions of a page. If spamming is really troublesome, </em><a href="WikiSpamBlocker.html">WikiSpamBlocker</a> can be used - it has been tried and seems to work.<em></em>
      </p>
      <hr/>
      <p>
        Ward has chosen to use <a href="DelayedIndexing.html">DelayedIndexing</a> to discourage spamming.
      </p>
      <hr/>
      <p>
        <a href="EliotScott.html">EliotScott</a> asks: How does one automagically remove unwanted content, in this case <a href="WikiSpam.html">WikiSpam</a>? What's the secret to identifying it on pages? I'd like to setup my own Wiki Web Site, but I can't have inappropriate language or content either.
      </p>
      <p>
        <em>Thanks,</em> ES
      </p>
      <p>
        <em>It depends which one of the </em><a href="WikiEngines.html">WikiEngines</a> you use. <a href="MoinMoin.html">MoinMoin</a> comes with an anti-spam feature. You just have to turn it on in your config file; see: <a href="http://moinmoin.wikiwikiweb.de/AntiSpamGlobalSolution">http://moinmoin.wikiwikiweb.de/AntiSpamGlobalSolution</a> You can add profanity filters to the LocalBadContent page I think. A much better wiki engine is <a href="MediaWiki.html">MediaWiki</a>, but they have not yet finished adding built-in support for spam blocking; see: <a href="http://mail.wikipedia.org/pipermail/mediawiki-l/2004-December/002666.html.''">http://mail.wikipedia.org/pipermail/mediawiki-l/2004-December/002666.html.''</a>
        It seems, that some spam (or what else is is?) occurs always at 4:00 (see <a href="http://c2.com/mrtg/).">http://c2.com/mrtg/).</a>
      </p>
      <p>
        May be of interest to some, mostly what we knew already though - <a href="http://www.theregister.co.uk/2005/01/31/link_spamer_interview/.">http://www.theregister.co.uk/2005/01/31/link_spamer_interview/.</a>
      </p>
      <hr/>
      <p>
        <strong>Spams left unattended for long periods</strong>
      </p>
      <p>
        <a href="SandBox.html">SandBox</a> cleaned up 22ndFeb Sydney time around 7am, after left untouched for 10 hours or so by the community. Anyone in US has habit of checking wiki in the mornings? Please check for spam as well.
      </p>
      <hr/>
      <p>
        <strong>Spammer upset with antispammers</strong>
      </p>
      <p>
        While that is true for all of the spamming morons, there is one in particular that is spamming other sites with the urls and text from sites that call him as a spammer. He is a nasty spammer too, he has set up some Javascript with an IE exploit so that visitors to his fake search engine end up spamming for him. c2.com is one of his victims, along with chongqed.org, spamhuntress.com, spam.gunters.org, buffoons.blogspot.com, and others. More info on him: <a href="http://wiki.chongqed.org//WikiForum#050515">http://wiki.chongqed.org//WikiForum#050515</a> -- Joe(at)chongqed.org - 2005-05-16 05:15 UTC
      </p>
      <hr/>
      <p>
        <a href="WikiHistory.html">WikiHistory</a> was spammed on Oct 16, 2005 (and <a href="FrontPage.html">FrontPage</a> similarly the previous day). This is the only incident I have seen since the <a href="EditCodeWord.html">EditCodeWord</a> was put in place in March. Quite effective as a spam deterrent, I'd say.
      </p>
      <hr/>
      <p>
        I don't know if it's been mentioned, but a way to combat spam is also to restrict editing to registered users.  A bunch of wikis do that, <a href="WikiStory.html">WikiStory</a> (<a href="http://www.wikistory.com/wiki/WikiStory_Home)">http://www.wikistory.com/wiki/WikiStory_Home)</a> is the first that comes to mind.  People can still be annonymous, since choosing a username does not reduce anonymity.  There would be less editing with this solution, because people might not want to register, for whatever reason, and I haven't visited C2.com before but the wiki appears to not incorporate a user system.  So there are downsides to this approach and instances where it may not be applicable.
      </p>
      <hr/>
      <p>
        See <a href="SpamBlackList.html">SpamBlackList</a>, <a href="WikiSpamSolutions.html">WikiSpamSolutions</a>, <a href="CaptchaTest.html">CaptchaTest</a>
      </p>
      <hr/>
      <p>
        <a href="CategoryWikiSpam.html">CategoryWikiSpam</a> <a href="CategoryProblem.html">CategoryProblem</a>
      </p>
      <hr/>
      <p>
        Thanks moved to <a href="WikiAppreciation.html">WikiAppreciation</a>.
      </p>
    </div>
  </body>
</html>