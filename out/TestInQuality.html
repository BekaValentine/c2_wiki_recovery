<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Test In Quality
      </h1>
      <p>
        Procedure used to "add" quality into a product after it is developed. This fails, of course because testing doesn't really add quality. It only tells you what level of quality you have achieved, which is usually poor if this was your strategy.
      </p>
      <hr/>
      <p>
        You can not inspect quality into the product; it is already there. - <a href="WilliamEdwardsDeming.html">WilliamEdwardsDeming</a>
      </p>
      <hr/>
      <p>
        Before I get really nailed on this, I am referring to System or Functional testing. I DO believe that you CAN <a href="TestInQuality.html">TestInQuality</a> (in a funny way) if you are writing repeatable unit tests before you write code and ensuring that they always pass at 100%.
      </p>
      <p>
        <em>You can test in quality if, when you say </em>'testing<strong>, you really mean </strong>testing and fixing bugs<em>'. This may not be the optimal way of building robust code, but it does work.</em>
      </p>
      <p>
        Not in my experience. The best you get from trying to <a href="TestInQuality.html">TestInQuality</a> is code which doesn't break for any of the tests you have run so far. My experience is that people who like this idea usually don't really understand how the program works and are just winging it. -- <a href="JeffShelby.html">JeffShelby</a>
      </p>
      <p>
        Jeff, in my experience, this is how it always works. If you're using any Microsoft products at all, then you are using products that have <em>had quality tested into them</em>. Take Internet Explore 5.0 for example. It's a <em>lot</em> more robust than Netscape. Let me assure you that it was <em>not</em> anywhere near that stable when it was under development (I was at MS at the time, building an application on top of it). How did it get stable?  Microsoft had dozens, if not hundreds, of testers finding bugs and entering them into the bug database. These bugs were then assigned to the appropriate developers who tracked the bugs down and fixed them. This went on for months before MS decided IE was solid enough to release. My team at MS released two 1.0 products using the same approach. Office 2000 was released using the same approach (the Office 2000 bug database had over 200 000 bug entries in it before Office shipped). My first employer used a similar approach on Aldus/Macromedia <a href="FreeHand.html">FreeHand</a>, a product that has always had a good reputation for quality. My current employer uses the same approach. Heck, even the <a href="OpenSource.html">OpenSource</a> guys use this approach - otherwise, they wouldn't be making the big deal about how "Debugging is parallelizable" (to directly quote Eric S. Raymond).
      </p>
      <p>
        -- <a href="CurtisBartley.html">CurtisBartley</a>
      </p>
      <hr/>
      <p>
        It's not common practice, but it is more effective to <strong>not put the bugs in in the first place</strong> than to rely on some independent process that tries to <strong>track down the bugs you've hidden in your code,</strong> and report them back to you, so you can fix them.
      </p>
      <p>
        "Testing and fixing the problems you find" works. But if you really want a quality product, you'll have to build the quality in, not add it as an afterthought.
      </p>
      <hr/>
      <p>
        See: <a href="ItWorks.html">ItWorks</a>
      </p>
      <p>
        <a href="CategoryQuality.html">CategoryQuality</a>
      </p>
    </div>
  </body>
</html>