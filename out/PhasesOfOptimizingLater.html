<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Phases Of Optimizing Later
      </h1>
      <p>
        My profiling tool tells me:
      </p>
      <ul>
        <li>
           time in this method only
        </li>
        <li>
           time in this method and ones it called
        </li>
        <li>
           objects created in this method only
        </li>
        <li>
           objects created in this method and ones it called.
        </li>
      </ul>
      <p>
        For optimization, I consider time and objects to be equivalent, as they are both equally bad in the general case. So I shall only distinguish between method time and cumulative time, but I mean objects too.
      </p>
      <p>
        When I first profile a slow program, I usually get some methods whose method time is outrageously high. This is where people do stupid things. As the stupidity is limited to one method, I can rewrite that code and fix it.
        Then I look at methods whose method time is high, but only because they are called so many times. By looking up the stack from there, I can sometimes find a place where people are calling other methods too much, instead of caching results. Once I have eliminated those places, I get to the stage people have been calling <a href="UniformlySlowCode.html">UniformlySlowCode</a> - the code is slow, but there are no blatant hot spots.
      </p>
      <p>
        At this stage, I look at the cumulative times. Some methods are expected to have high cumulative times, e.g. main. Some methods should not, and it is only by knowing the code intimately and having a suspicious nature that you can detect these. After you look at the code, and think about it, you sometimes realize that the person who wrote it was an idiot and did it all wrong, but they were such a smart idiot that to fix it you are going to have to change large chunks of the program. To do that requires architectural change. 
      </p>
      <p>
        At this stage you mercilessly apply <a href="OnceAndOnlyOnce.html">OnceAndOnlyOnce</a>, reusing other parts of the code wherever possible (as always). You then profile again, and look for methods with high method times. Chances are, some new method has appeared as a hot spot, and you can optimize that. That's good, because optimizing a single method is much easier than architectural change.
      </p>
      <p>
        As the architectural changes proceed you still have uniform distribution of execution speed, but you move from being slow to fast.
      </p>
      <p>
        I think that overall, optimizing later is a good technique, but by using the right architecture in the first place you can decrease the number of architectural changed and increase the number of method optimizations to achieve fast code.
      </p>
      <p>
        -- <a href="JohnFarrell.html">JohnFarrell</a>
      </p>
      <hr/>
      <p>
        <a href="CategoryOptimization.html">CategoryOptimization</a>
      </p>
    </div>
  </body>
</html>