<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Web Link List Example In Python
      </h1>
      <p>
        <a href="PythonLanguage.html">PythonLanguage</a> implementations of web link lister. (See <a href="WebLinkListExample.html">WebLinkListExample</a>.)
      </p>
      <p>
        Here's an implementation that lists the hrefs from a web document using a <a href="HyperTextMarkupLanguage.html">HyperTextMarkupLanguage</a> parser. It uses standard modules HTMLParser, urllib, and sys. No special setup is required after Python is installed. The implementation is pretty idiot-proof and fails gracefully when an error is encountered.
      </p>
      <code>
        'linklister1.py'<br/>
      </code>
      <code>
        from HTMLParser import HTMLParser<br/>
        class LinkParser(HTMLParser):<br/>
        def reset(self):<br/>
        HTMLParser.reset(self)<br/>
        self.hrefs = []<br/>
        def handle_starttag(self, tag, attrs):<br/>
        href = [v for k,v in attrs if k.lower() == 'href']<br/>
        if href: self.hrefs.extend(href)<br/>
      </code>
      <code>
        def listLinks(url):<br/>
        import urllib<br/>
        print '*** links in', url, '***'<br/>
        parser = LinkParser()<br/>
        try:<br/>
        parser.feed(urllib.urlopen(url).read())<br/>
        except Exception, e:<br/>
        print '%s: %s\n' % (e, url)<br/>
        return<br/>
        parser.close()<br/>
        for href in parser.hrefs: print href<br/>
        if not parser.hrefs: print 'None!'<br/>
        print<br/>
      </code>
      <code>
        if __name__ == '__main__':<br/>
        import sys<br/>
        if len(sys.argv) > 1:<br/>
        for url in sys.argv[1:]: listLinks(url)<br/>
        else: print 'usage: linklister1 url [url2 ...]'<br/>
      </code>
      <p>
        The program can parse both HTML and XHTML. It retrieves the values of all href attributes it finds in all the start tags. The LinkParser.handle_starttag method can be modified to process only the tags of interest, e.g., <a> and <area> but not <link> and <base>.
      </p>
      <p>
        Results from www.google.com on 19-Apr-2004
      </p>
      <ul>
        <li>
           links in <a href="http://www.google.com/">http://www.google.com/</a> ***
        </li>
      </ul>
      <code>
        /imghp?hl=en&tab=wi&ie=UTF-8<br/>
        /grphp?hl=en&tab=wg&ie=UTF-8<br/>
        /nwshp?hl=en&tab=wn&ie=UTF-8<br/>
        /froogle?hl=en&tab=wf&ie=UTF-8<br/>
        /froogle?hl=en&tab=wf&ie=UTF-8<br/>
        /options/index.html<br/>
        /advanced_search?hl=en<br/>
        /preferences?hl=en<br/>
        /language_tools?hl=en<br/>
        /ads/<br/>
        /services/<br/>
        /about.html<br/>
      </code>
      <hr/>
      <p>
        For something completely different, here's an implementation that lists <em>all</em> the hrefs using <a href="RegularExpression.html">RegularExpression</a>s. It uses standard modules urllib, re, and sys. No special setup is required after Python is installed. The implementation is pretty idiot-proof and fails gracefully when an error is encountered.
      </p>
      <p>
        Tests with Python's timeit module show this regexp implementation is about 22% faster than the HTMLParser implementation on a local html file with 59 hrefs, using Python 2.3 on <a href="MacOs.html">MacOs</a> 9.
      </p>
      <code>
        'linklister2.py'<br/>
      </code>
      <code>
        def listHrefs(url):<br/>
        import urllib, re<br/>
        lookFor = r'href\s*=\s*\"([^\"]*)|href\s*=\s*\'([^\']*)|href\s*=\s*([^\s\"\'>]+)'<br/>
        clookFor = re.compile(lookFor, re.I)<br/>
        print '*** hrefs in', url, '***'<br/>
        try:<br/>
        document = urllib.urlopen(url).read()<br/>
        except Exception, e:<br/>
        print '%s: %s\n' % (e, url)<br/>
        return<br/>
        hrefs = clookFor.findall(document)<br/>
        for tup in hrefs:<br/>
        for href in tup:<br/>
        if href: print href<br/>
        if not hrefs: print 'None!'<br/>
        print<br/>
      </code>
      <code>
        if __name__ == '__main__':<br/>
        import sys<br/>
        if len(sys.argv) > 1:<br/>
        for url in sys.argv[1:]: listHrefs(url)<br/>
        else: print 'usage: linklister2 url [url2 ...]'<br/>
      </code>
      <p>
        The program can search any document until an EOF marker is encountered. If there happens to exist 'href="blah"' in the text of a web document, this regexp implementation finds it in addition to the href attributes in the tags.
      </p>
      <p>
        Results from www.google.com on 19-Apr-2004
      </p>
      <ul>
        <li>
           hrefs in <a href="http://www.google.com/">http://www.google.com/</a> ***
        </li>
      </ul>
      <code>
        /imghp?hl=en&tab=wi&ie=UTF-8<br/>
        /grphp?hl=en&tab=wg&ie=UTF-8<br/>
        /nwshp?hl=en&tab=wn&ie=UTF-8<br/>
        /froogle?hl=en&tab=wf&ie=UTF-8<br/>
        /froogle?hl=en&tab=wf&ie=UTF-8<br/>
        /options/index.html<br/>
        /advanced_search?hl=en<br/>
        /preferences?hl=en<br/>
        /language_tools?hl=en<br/>
        /ads/<br/>
        /services/<br/>
        /about.html<br/>
      </code>
      <hr/>
      <p>
        Contributor(s): <a href="ElizabethWiethoff.html">ElizabethWiethoff</a>
      </p>
      <hr/>
      <p>
        <a href="CategoryPython.html">CategoryPython</a>
      </p>
    </div>
  </body>
</html>