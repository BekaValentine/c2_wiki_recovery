<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Emergent Behavior
      </h1>
      <p>
        Behavior of a system that is not explicitly described by the behavior of the components of the system, and is therefore unexpected to a designer or observer. Very important in the study and design of <a href="ComplexSystems.html">ComplexSystems</a>, and an almost inevitable consequence of any <a href="MultiAgentSystem.html">MultiAgentSystem</a>.
      </p>
      <p>
        The book <a href="TurtlesTermitesAndTrafficJams.html">TurtlesTermitesAndTrafficJams</a> is about emergent behavior, and studies of it using a parallel logo implementation called <a href="StarLogo.html">StarLogo</a>.
      </p>
      <p>
        <em>Is this related to epiphenomena in any way? </em><a href="GoedelEscherBach.html">GoedelEscherBach</a> style?<em> --</em><a href="BobBockholt.html">BobBockholt</a>
      </p>
      <p>
        <em>It seems to me that what we're really talking about here is not exactly "behavior that isn't explicitly described by the behavior of the components of a system." It would be more correct to say that emergent behavior is any behavior of a system that is not a</em> <strong>property</strong> <em>of any of the components of that system. That is, a property that</em> <strong>emerges</strong> <em>due to</em> <strong>interactions among the components of a system,</strong> <em>as mentioned below.</em>
      </p>
      <p>
        <em>For example. flocking is not the behavior of an individual bird. To go a step further, circulation of the blood is not the behavior of an individual (or even many) blood cell(s). Circulation is possible</em> <strong>only</strong> <em>within the context of a</em> <strong>circulatory system,</strong> <em>which includes many such cells among its several types of constituents.</em>
      </p>
      <p>
        <em>You can study avian biology and taxonomy till you're blue in the face -- but as long as you are looking at individuals in isolation, or even as individual members of species, you will neither encounter nor understand flocking.</em>
      </p>
      <hr/>
      <p>
        <a href="TheGoalOfTestDrivenDevelopmentIsEmergentBehavior.html">TheGoalOfTestDrivenDevelopmentIsEmergentBehavior</a>. Suppose you write a new test case that requests behavior completely orthogonal to your existing behavior. The fewer code edits required to pass that case, the more EM you have achieved.
      </p>
      <p>
        <em>Huh?  The goal of </em><a href="TestDrivenDevelopment.html">TestDrivenDevelopment</a> is better code.<em></em>
      </p>
      <hr/>
      <p>
        Brian Eno is an artist who uses emergent behavior in his work. Check out youtube.com/watch?v=UqzVSvqXJYg
      </p>
      <hr/>
      <p>
        Some examples
      </p>
      <ul>
        <li>
           Evolution is emergent from Biology is emergent from Chemistry is emergent from Physics is emergent from Quantum Mechanics...
        </li>
        <li>
           flocking of birds cannot be described by the behavior of individual birds
        </li>
        <li>
           market crashes cannot be explained by "summing up" the behavior of individual investors
        </li>
        <li>
           the success of <a href="ExtremeProgramming.html">ExtremeProgramming</a> depends on the performance of the team exceeding the summed performance of all the programmers....
        </li>
        <li>
           this Wiki and other <a href="WikiClones.html">WikiClones</a>
        </li>
      </ul>
      <hr/>
      <p>
        Flocking can be described by the behavior of individual birds.
        Would it be better to say that:-
        Flocking is the behavior that emerges from the behavior of individual birds.
      </p>
      <p>
        <em>See also </em><a href="InsectBehaviour.html">InsectBehaviour</a>. Basically, all behaviour comes from individuals (where else would it come from?), but as someone else mentioned, the interactions are what makes things difficult to understand. I think this is similar to when people forget the edges in a graph have informational content or just brush them aside as somehow inconsequential. Then again, maybe the human mind has trouble grokking graph structures.<em></em>
      </p>
      <p>
        <em>Basically, all behaviour comes from individuals...</em>
      </p>
      <p>
        Yes, but WhatsAnIndividual? Am I an individual? Are my organs individuals? Are the cells that comprise them (me) individuals?
      </p>
      <hr/>
      <p>
        The references to "summing" in the above list are somewhat misleading, aren't they? 
      </p>
      <p>
        Isn't it that emergent behaviour, well, emerges, form the <em>interactions between</em> the members of an ensemble, rather than from the behaviours of the members of the ensemble taken in isolation. The behaviour need not necessarily be a surprise to the designer, but it is very, very difficult to predict a priori what behaviour will emerge from a set of interactions.
      </p>
      <p>
        The really significant thing about emergence (and <a href="ComplexSystems.html">ComplexSystems</a> in general) is that it forces us to abandon the assumption that complex behaviours must arise from complex rules. -- <a href="KeithBraithwaite.html">KeithBraithwaite</a>
      </p>
      <p>
        <em>Isn't it that emergent behaviour, well, emerges, form the </em>interactions between<em> the members of an ensemble...?</em>
      </p>
      <p>
        The interactions are important, but even those, taken in isolation, don't explain emergence. When individuals produce behaviors that affect other individuals and other behaviors, ultimately affecting the original individuals, then you have the complex feedback dynamic you need for emergence. High complexity is key, because without it we could easily predict the outcomes of these interactions. Because of high complexity, our internal modeling apparatus is overwhelmed, and we either fail to expect any result, or expect results that are simple (linear) extrapolations of observed behaviors. (See "nonlinearity" explanation immediately below.) -- <a href="WaldenMathews.html">WaldenMathews</a>
      </p>
      <hr/>
      <p>
        While the word "summing" may seem a bit vague, it's actually informed by the most probable origin of all <a href="EmergentBehavior.html">EmergentBehavior</a>: nonlinearity. The "summed" flight behavior of 100 birds held in isolation from one another is different from their behavior when they're together in a flock <em>because</em> the behavior of each bird in the latter case is interdependent on the state of the others.
      </p>
      <p>
        It's admittedly a bit of a CircularArgument to say that <a href="EmergentBehavior.html">EmergentBehavior</a> <em>is</em> nonlinear dependencies, but it turns out that the notion of emergence is itself prone to circularity and tautology. The philosopher SunnyAuyang has what I think is the most reasonable definition of emergence in her book <em>Foundations of Complex-Systems Theories</em> (ISBN: 0521778263) - but it's many pages long. Basically, she points out the difference between ResultantPhenomena and EmergentPhenomena: Resultant behavior is that which could be "reasonably expected" from a collection of agents or objects given observations of their individual behavior, while <a href="EmergentBehavior.html">EmergentBehavior</a> is that which doesn't follow. And, yes, that means it's subjective - once your description of the components comes to include what was emergent, it basically goes away into the world of expected, common knowledge. -- <a href="BillTozier.html">BillTozier</a>
      </p>
      <p>
        <em>Hmmm. I wonder if there is any essential/accidental split to be had here?  Is this resultant/emergent split fundamental in some way, or just an artifact of our limited understanding? And would we be able to tell, anyway -- </em><a href="KeithBraithwaite.html">KeithBraithwaite</a><em></em>
      </p>
      <hr/>
      <p>
        <em>Keith, can you fill in more about the "now anomalous nature of the label 'complex' in analysis" please? I'm quite interested in this.</em> -- <a href="WaldenMathews.html">WaldenMathews</a>
      </p>
      <p>
        Apparently I can't. I tried, but was falling foul of some mis-remembered mis-conceptions. Sorry. And thanks to <a href="CameronSmith.html">CameronSmith</a> for putting me straight. He provides this example:
      </p>
      <p>
        <em>To make the point you're trying to make, a much better term than "irrational", "complex", or "imaginary" is "surd" - from the Latin "surdus", literally meaning "mute", and therefore, metaphorically "saying nothing", or "meaningless". The word "absurd" derives faithfully from this metaphorical usage. The term "surd" was used in mathematical writing at one time to denote an irrational root of an equation with rational coefficients. (Note that this term is not in current usage.)</em>
      </p>
      <p>
        It is not in current usage because these irrational roots no longer challenge anyone's assumptions about what a root should be like. Which is perhaps similar to the kind of change that I'm suggesting might one day happen to emergent behaviour. -- KB
      </p>
      <hr/>
      <p>
        <em>I think you're correct if you're suggesting above that there exists no universal split between expected and emergent, only individual perspectives. Isn't it kind of like how magic ceases to be magic once you've learned the trick?</em> -- WM
      </p>
      <p>
        Yes.
      </p>
      <p>
        <em>Also, think about the difference in adult ability to anticipate events versus that capability in young children, whose thinking may not even be "linear" at that stage... -- </em><a href="WaldenMathews.html">WaldenMathews</a><em></em>
      </p>
      <dl>
        <dt> </dt>
        <dd><em>I think you're correct if you're suggesting above that there exists no universal split between expected and emergent, only individual perspectives. -- WM</em></dd>
      </dl>
      <p>
        I'm not sure I suggesting that none such exists, but I do wonder if we aren't just missing some information.
        -- KB
      </p>
      <hr/>
      <p>
        From above:
      </p>
      <dl>
        <dt> </dt>
        <dd><em>The really significant thing about emergence (and </em><a href="ComplexSystems.html">ComplexSystems</a> in general) is that it forces us to abandon the assumption that complex behaviours must arise from complex rules. -- <a href="KeithBraithwaite.html">KeithBraithwaite</a><em></em></dd>
      </dl>
      <p>
        Abandoning this assumption leads to an interesting place in which we may make leaps of faith that lead to quantum improvements in analysis. In this sense, really powerful analysis is emergence in reverse. Finding the simplest nonlinear roots to a complex of observed behaviors. -- <a href="WaldenMathews.html">WaldenMathews</a>
      </p>
      <hr/>
      <p>
        It also breaks the assumption that simple behaviour must arise from simple rules. This is even more significant, in my view. Without this, you have a devil of a job explaining where all the simplicity comes from. (See <a href="CollapseOfChaos.html">CollapseOfChaos</a>.)
      </p>
      <p>
        <em>Or are we freed from the need to explain where either simplicity or complexity comes from? At the cost of having to abandon some assumptions and having to develop some understanding of when we get which.</em>
      </p>
      <hr/>
      <p>
        As a practical matter, I want to know where complexity comes from because I want to control it, perhaps by getting hold of its simple roots. I don't have similar leanings in my instincts for dealing with simplicity. If anything, my instinct there is to find out what complicated stuff I can make out of it. -- <a href="WaldenMathews.html">WaldenMathews</a>
      </p>
      <hr/>
      <p>
        I'm no expert on this stuff, but I find it interesting that nowhere on this page does anyone explain it in the way that I've always understood it. It seemed such a simple concept to me, but reading this page, it seems really complex. Am I oversimplifying?
      </p>
      <p>
        I've always understood <a href="EmergentBehavior.html">EmergentBehavior</a> as referring to large-scale or aggregate behavior that seems organized <em>at that scale</em> but is actually just the natural consequence of localized, smaller-scale rules. This has some of the characteristics mentioned above - namely, that when you're looking at the localized rules, it's rarely obvious that the larger-scale behavior will be the result.
      </p>
      <p>
        For example: birds don't have any concept of "fly in a vee shape". Each bird, though, knows to fly in a particular relationship to one or at most two nearby birds. For some kinds of birds, each bird doing the right thing relative to adjacent birds results in the characteristic vee formation.
      </p>
      <p>
        Likewise the concept of architecture in <a href="ExtremeProgramming.html">ExtremeProgramming</a>. The XP practices that deal with the design of the system rarely (if ever) try to look at the "big picture" of the system, instead making design decisions based on the current iteration, or task, or story, or class, or test, or even method. (The big exception is <a href="SystemMetaphor.html">SystemMetaphor</a>, and even that one is advocated primarily for its influence on naming.) But the idea behind it is that if you choose the right rules to apply on small scales, a good architecture will emerge. Ralph Johnson said it best in <a href="ExtremeProgramming.html">ExtremeProgramming</a>: 
      </p>
      <dl>
        <dt> </dt>
        <dd>... with the right value system, making good short term decisions leads to good long term results.</dd>
      </dl>
      <p>
        -- <a href="GlennVanderburg.html">GlennVanderburg</a>
      </p>
      <p>
        <em>-However, </em>JohnNash with his now famous <a href="NashEquilibrium.html">NashEquilibrium</a> demonstrated that making good short term deciscions does not necessarily make for good long term results.  Also, the counterargument to<em> if you choose the right rules to apply on small scales, a good architecture will emerge</em> is that since the behavior is emergent only rules producing good architecture can be considered "right."  No matter how good a set of rules seems to be at time T there is always a chance of unwanted behavior emerging at time T+dt.  The initial rules are only validated after the fact, if the system preforms in a useful manner over a useful TimeFrame<em> --</em>AndrewFischer
      </p>
      <hr/>
      <p>
        Glenn, I think you're touching on something really important here, and it relates to the architectures discussion on other pages.
      </p>
      <p>
        All of the behaviors around us have <em>emerged</em>, and some of those we as humans with conscious judgment have deemed valuable. Wishing to have more of what we value, we then embark on what you might call "artificial emergence", i.e., the quest to make value materialize on demand. This leads to analytical thinking "why did that happen?". It leads to primitive, linear analytical models that say things like "yellow plus blue makes green". Great, now we can make green, but we're not satisfied because we still can't produce big software in teams. We've seen it happen on rare occasion, but when we try to replicate what we perceived to be the critical components, something is always missing. Are we just mixing the wrong pigments, or is our fundamental model for composing a machine to make great software just too simplistic?
      </p>
      <p>
        The great paradox of our time is that we need simplicity in order to control, yet we value things of high complexity. The notion of emergence weds these two ends of the spectrum and provides the hope that we can learn more powerful ways of making what we value.
      </p>
      <p>
        Above, you talk about choosing the right rules to make good architecture emerge. But without the big picture to guide, how does one choose those rules? Even with the big picture, how does one choose the primary colors to use when the outcome will not follow any color theory we can understand? I guess this is where faith comes in, but it's only good for replicating results already had. How do we exploit this system to make new things? Must we always wait for faith and value systems to emerge?
      </p>
      <p>
        I think the answer is that we have to change our understanding. The practicality behind studying emergence is to learn to be better analysts, <a href="AnalyzingEmergentSystems.html">AnalyzingEmergentSystems</a>. I can see the yellow in something green. I can hear the partials in a vibrating piano string. These are learned skills. Will I someday be able to see or hear simple components that are a nonlinear dynamic away from my complicated little world?
      </p>
      <p>
        -- <a href="WaldenMathews.html">WaldenMathews</a>
      </p>
      <p>
        <em>Fantastic. I'll go chew on that for a while ...</em>
      </p>
      <hr/>
      <p>
        For a good book on the subject, check out Steven Johnson's <em>Emergence</em> ISBN: 0684868768.
      </p>
      <hr/>
      <p>
        An example of evolving predator/prey flocking <a href="ArtificialLife.html">ArtificialLife</a> with complex <a href="EmergentBehavior.html">EmergentBehavior</a> can be found at <a href="http://www.neocoretechs.com/alife.">http://www.neocoretechs.com/alife.</a>
        Hopefully, this is an entertaining and informative example of the <a href="GeneticAlgorithm.html">GeneticAlgorithm</a> as well. -- <a href="JonGroff.html">JonGroff</a>
      </p>
      <hr/>
      <p>
        <em>The really significant thing about emergence (and </em><a href="ComplexSystems.html">ComplexSystems</a> in general) is that it forces us to abandon the assumption that complex behaviours must arise from complex rules. -- <a href="KeithBraithwaite.html">KeithBraithwaite</a><em></em>
      </p>
      <p>
        <a href="StephenWolfram.html">StephenWolfram</a> has compellingly elaborated this in <a href="NewKindOfScience.html">NewKindOfScience</a>. Here's the basic sketch, paraphrased from Wolfram:
      </p>
      <p>
        <strong>Q:</strong> Where does complexity come from?
      </p>
      <p>
        <strong>A:</strong> Complexity emerges from <strong>very</strong> simple rules
      </p>
      <p>
        <strong>Q:</strong> What's an example of a "simple rule"?
      </p>
      <p>
        <strong>A:</strong> A <a href="CellularAutomaton.html">CellularAutomaton</a> for a row of bits, such that the state of a bit at generation N+1 is determined by the state of the bit and its two nearest neighbors at time N.
      </p>
      <p>
        <strong>Q:</strong> Can a system built from such simple rules really generate complex behavior?
      </p>
      <p>
        <strong>A:</strong> A system built from rule 30 (there are 256 possible rules) and applied to a bit vector (of sufficient size) centered about a single asserted bit generates results that satisfy all current definitions of complexity/randomness.
      </p>
      <p>
        <strong>Q:</strong> Is rule 30 an isolated example?
      </p>
      <p>
        <strong>A:</strong> To the contrary. CA's fall into four "classes". The universe is <em>filled</em> with them, and "Class 4" CA's (as Wolfram calls them) are quite common.
      </p>
      <p>
        <strong>Q:</strong> Do Class 4 CA's demonstrate other interesting behavior?
      </p>
      <p>
        <strong>A:</strong> Every CA can be viewed as a computer executing an unknown program, with the initial state of the bit vector as its input condition. The 256 possible CA's include those needed to build a UniversalComputer. For most Class 4 CA's, an initial state exists that allows the CA to emulate every <em>other</em> CA. This means that most Class 4 CA's are UniversalComputers.
      </p>
      <p>
        <strong>Q:</strong> But surely these rules oversimplify the reality of natural phenomena?
      </p>
      <p>
        <strong>A:</strong> CA's can be elaborated in a multitude of ways - multiple bits per cell, multiple dimensions, more connectivity, etc. The behavior demonstrated by these elaborations is not measurably more complex than that of the most simple rules.
      </p>
      <p>
        The essence of all of this is that <a href="EmergentBehavior.html">EmergentBehavior</a> is the rule, rather than the exception from the rule. In particular, the UniversalComputer is an upper, as well as lower, limit on computability -- it can perform any computation that is possible. The universality of even the simplest CA means that UniversalComputers are abundant, rather than scarce. Among other things, it means that the human brain is not fundamentally different from any other UniversalComputer. It would appear that the role of evolution is to prune the tree of life of abundant branches that do not work, rather than to create species through mechanisms such as mutation.
      </p>
      <p>
        These are some hints as to why Wolfram's concepts are so revolutionary.
      </p>
      <hr/>
      <p>
        Soon after someone got around to building the computer <a href="AlanTuring.html">AlanTuring</a> imagined he put it to work playing with cellular morphogenesis.  He was fascinated with the question of how a collection of single cells could each carry out simple, isolated rules and produce such complex structures.  He wrote programs to model how giraffe spots, zebra stripes and Fibonacci numbers could emerge from collections of single cells.  See <a href="http://www.swintons.net/jonathan/turing.htm">http://www.swintons.net/jonathan/turing.htm</a> for discussion of this work.
      </p>
      <p>
        I'm bothered by the way some folks give emergence a sort of mystical value.  From where I sit (on my reductionist butt) emergence clobbers mysticism, holism, synergy, etc.  Everywhere I look I see complex properties and behaviors emerging from simpler properties and behaviors.  The fact that many of them make my jaw drop in awe just reveals how easily impressed my nervous system is.
      </p>
      <p>
        -- <a href="EricHodges.html">EricHodges</a>
      </p>
      <p>
        <em>I wonder why it bothers you that "some folks give emergence a sort of mystical value". It seems to me that it is precisely </em>'because<strong> emergence potentially explains (rather than "clobbers") mysticism, holism, synergy, etc, that it is interesting to contemplate. It seems to me that the observation that our nervous systems are easily impressed leads to a compellingly deep and meaningful basis for the awe that has exemplified humankind's reaction to the universe throughout history. On the other hand, it is certainly a disturbing notion -- perhaps because it means that a significant portion of what humankind has attributed to arbitrary, capricious, and abusive "Gods" can now be explained without resort to such superstitious smoke-and-mirrors. I find the prospect deeply satisfying. -- </strong><a href="TomStambaugh.html">TomStambaugh</a><em></em>
      </p>
      <p>
        It bothers me because they aren't giving up spooks and spirits, they're just changing the names.  There's nothing mystical about emergent behaviors.  There's nothing mystical about anything.  Mysticism is one way our limited brains react to systems more complex than we can comprehend.  They say things like "the whole is greater than the sum of its parts" as if the extra bit was a magical ghost.  It isn't.  The extra bit is the consequence of how the parts interact.  Add that to the parts and everything is accounted for.
      </p>
      <p>
        Ask any mystic and I bet he'll agree that explaining mysticism clobbers it.  That which can be explained is not the eternal tao, etc., etc..
      </p>
      <p>
        The "basis for the awe that has exemplified humankinds reaction to the universe" is that we are limited in ways we don't (and can't) know.  There are limits to what we can think and we can know there must be limits but we can't know what they are because our thinking is limited.
      </p>
      <p>
        -- <a href="EricHodges.html">EricHodges</a>
      </p>
      <p>
        <em>Ok, I understand you now. I wonder if I might ask you to search for more tolerance for people, like myself, who choose different words to express the same awe that almost all of us feel. As I said earlier, it is the fact that </em><a href="EmergentBehavior.html">EmergentBehavior</a> lets me explain how the "extra bit" comes about that draws me to it. I am a mystic, and <a href="EmergentBehavior.html">EmergentBehavior</a> unleashes, rather than clobbers, my mysticism. For example, I find the actual chemistry of how pre-biotic molecules with hydrophobic and hydrophilic ends self-organize into closed ecologies that virtually guarantee the emergence of metabolism to be <strong>far</strong> more awe-inspiring than any folk tale from any culture, no matter how many references to tao, God, Baal, and so on.<em></em>
      </p>
      <p>
        Some ancient Greeks realized that everything humans attributed to gods could be explained without superstition.  That idea has gone in and out of fashion since then, but it isn't new.  It was big with TheEnlightenment crowd 200 years ago. -- <a href="EricHodges.html">EricHodges</a>
      </p>
      <p>
        <em>Yes, I know. I hope to help swing the pendulum back towards an integration of science and theology -- I think we need a new kind of god, as well as a new kind of science. I think the ancient Greeks had it right, and I think the western world got it wrong when it took the path of Dualism -- insisting that science and theology are separate. I suspect that you perhaps mis-spoke in citing </em>TheEnlightment crowd as "getting it right" -- since the primary theme of "TheEnlightment crowd" was to argue that science had nothing to say about God and theology had nothing to say about Science. Instead, you may be thinking of the dialog between the Rationalists and the Empiricists (largely resolved today). In any case, <a href="EmergentBehavior.html">EmergentBehavior</a> (along with a set of related phenomena) pulls me towards "Monism" (as opposed to Dualism) -- the assertion that there is just one thing in the world. Further, I assert that Fredkin, Mandlebrot, Wolfram, Hawkings and others are demonstrating that the "one thing" is information (as opposed to material). Finally, I think we agree that the universe follows rules -- no superstition required.<em></em>
      </p>
      <p>
        I think we agree on most of this stuff but use the words "mysticism" and "mystic" differently.  To me, mystics seek to preserve mystery, usually through mystery religions.  What I see happening in some popularizations of emergent behavior is an attempt to replace the old mysteries with a new one.  We also disagree about what the "one thing" is, but I don't think that's worth arguing about.  I think matter/energy/space is all there is and that information is a side effect, but I recognize that's only a working hypothesis.  I'm an operational materialist.  If someone shows that it's the other way around I won't be upset or surprised. -- <a href="EricHodges.html">EricHodges</a>
      </p>
      <p>
        <em>Which illustrates one of the enormous benefits to be gained from letting go of the superstition, smoke and mirrors. Discussions about whether the "one thing" is "matter/energy/space" or "information" can be fruitful -- we can show each other evidence, we can show that they are duals, and even if they are not, the sharing of information enriches the exchange. Sounds like science to me. -- </em><a href="TomStambaugh.html">TomStambaugh</a> <em></em>
      </p>
      <p>
        Amen.  -- <a href="EricHodges.html">EricHodges</a>
      </p>
      <hr/>
      <p>
        For an example of emergent behavior you can play with, see <a href="http://sourceforge.net/projects/rudeboycurve.">http://sourceforge.net/projects/rudeboycurve.</a>
      </p>
      <hr/>
      <p>
        OK I did a Google and did find links of the "Emergent Behavior" term to complex systems. (e.g. <a href="http://www.research.ibm.com/infoecon/paps/html/icmas98/icmas_public.html)">http://www.research.ibm.com/infoecon/paps/html/icmas98/icmas_public.html)</a> Now my question is why was there not a simpler name (e.g. macro behavior, borrowing from macro vs micro economics) used. Is it a matter of the first prominent researcher gets to name the concept?
      </p>
      <p>
        Also for other clueless people <a href="WikiPedia.html">WikiPedia</a> definition of Emergence at <a href="http://en.wikipedia.org/wiki/Emergence">http://en.wikipedia.org/wiki/Emergence</a> (Oct05 version) is very readable.
      </p>
      <code>
        -- <a href="PlainEnglishPlease.html">PlainEnglishPlease</a><br/>
      </code>
      <p>
        <em>"Macro behavior" doesn't adequately express the idea of emergent behavior: that it 'emerges' from the complex interaction of many agents. "Emergent behavior" is not a complicated name, anyway.</em> I had a prior notion of "emergence" being equated to "rising", and therefore there is no discontinuity. Maybe my focus on business terminologies have resulted in that bias.
      </p>
      <hr/>
      <p>
        <a href="CategorySoa.html">CategorySoa</a> because of relationship to <a href="ComplexEventProcessing.html">ComplexEventProcessing</a>
      </p>
    </div>
  </body>
</html>