<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Bee Hive
      </h1>
      <dl>
        <dt><strong>Pattern Name</strong></dt>
        <dd><a href="BeeHive.html">BeeHive</a></dd>
      </dl>
      <dl>
        <dt><strong>Aliases</strong></dt>
        <dd>Hub, Collector, Concentrator, Accumulator, Amortize Failure</dd>
      </dl>
      <dl>
        <dt><strong>Context</strong></dt>
        <dd>A data-mining process must make the best effort possible to locate, and then process, information that is very multi-dimensional and distributed.</dd>
      </dl>
      <dl>
        <dt><strong>Problem</strong></dt>
        <dd>A system must process information that is available through a vast state space that is constantly changing. Processing an area until it is exhausted is not enough because new information may become available at any time. Iterating through the state space sequentially is impossible due to its size.</dd>
      </dl>
      <dl>
        <dt><strong>Forces</strong></dt>
        <dd>Part of the effort to locate new information must be dedicated to inspect both completely new and previously inspected areas of the state space. Areas already inspected may be likely to have appropriate new information, but at relatively slow rate of appearance.</dd>
      </dl>
      <dl>
        <dt><strong>Solution</strong></dt>
        <dd>Break up the problem into many independent agents, each inspecting a portion of the state space in a somewhat random way. Have each agent return not only with the information harvested itself, but where the information came from as well. Record the information in a centralized repository. As each agent returns with its information, it is re-instructed to search in a new area with adjusted search criteria depending on current needs. Uninspected portions of the state space are penetrated by a stochastic process. When an area rich in appropriate information is revealed, then more agents are redirected into that state space when they become available.</dd>
      </dl>
      <dl>
        <dt><strong>Resulting Context</strong></dt>
        <dd>Parts of the data space finally get some attention rather than none. The effort spent investigating the vast unknown does not occupy a major portion of the processing power. This is essential particularly if well-known portions of the state space have a 'peak period' that requires dedicated resources. 'Off-peak' investigation optimizes overall utility of such systems because no absolute 'downtime' occurs.</dd>
      </dl>
      <dl>
        <dt><strong>Design Rationale</strong></dt>
        <dd>When a system must comb through large amounts of information in a vast state space, the biological model of a Bee Hive is a useful model for a 'collector-concentrator' approach to what is being gathered. Each bee goes out, looking for a nectar source, returning with whatever it finds and instructions on where to find it. Each bee is subject to a wide variety of conditions and factors that might by chance place it near a resource it can notify other bees about. The key factor here is that in order to exploit the state space effectively, a large portion of the initial effort to gather resources must be spent on <em>failure</em>. After having searched through the areas that yield nothing, eventually [shift to calculation-based metaphor] the collector node directs the satellite nodes to independently exploit the state space of the richest sources. The collector node also occupies a portion of its dialog with the satellites to direct them to as-of-yet uninspected areas or to revisit previously unfruitful areas. From an N-dimensional way of talking, the system as a whole does not exhaustively traverse the state space, but stochastically inspects it in a non-deterministic way.  This 'fills in the picture' like the plotting of sparse points in a fractal pattern. Eventually, depending on the richness of the data source, the satellites may penetrate, via an N-dimensional 'pinhole', an area that is much richer than its 'neighborhood'. This methodology amortizes the cost of failure while taking full advantage of available resources.</dd>
      </dl>
      <dl>
        <dt><strong>Examples</strong></dt>
        <dd> Groups of Intelligent Agents with a common goal, Data mining the World Wide Web, <em>ad hoc</em> queries of Data Warehouses that search for critical data patterns, Making honey.  (Immune response too, perhaps?  -- <a href="BrianFoote.html">BrianFoote</a> ; <em>Yes, the goal is to eliminate antigens. Each white blood cell is an independent agent, mutating antibody RNA sequences. -- David</em>)</dd>
      </dl>
      <dl>
        <dt><strong>Related Patterns</strong></dt>
        <dd><a href="ModelYourEnvironment.html">ModelYourEnvironment</a>, <a href="CriticalNumberOfWorkers.html">CriticalNumberOfWorkers</a>, <a href="CriticalResourceFlow.html">CriticalResourceFlow</a>, <a href="ModelYourSelf.html">ModelYourSelf</a></dd>
      </dl>
      <p>
        -- <a href="DavidCymbala.html">DavidCymbala</a>
      </p>
      <hr/>
      <p>
        I appreciate your design rationale section, especially!  That helped me most, even the N-dimensional stochastic search bit.  Then I went back and read the pattern top to bottom understanding it. It does remind me a little bit of the stochastic anti-aliasing algorithm used in computer graphics (although there the data is static while enormous).  I could do with some examples I understand though, if I get to put in a request.  Simply saying data mining and ad hoc queries doesn't educate or convince me.  Are there specific systems out there that use this technique (besides bees)?  -- <a href="AlistairCockburn.html">AlistairCockburn</a>
      </p>
      <hr/>
      <p>
        <em>After attending the Autonomous Agents '98 conference, I found</em>
        <em>a veritable flood of examples of this pattern. Agents are ideal</em>
        <em>examples of uses for it. The </em>RoboCup competition displayed some<em></em>
        <em>intriguing examples of centralized control stratgies versus individual</em>
        <em>robot autonomy. Making each robot smart enough to handle movement</em>
        <em>and navigation tasks, they worked their way up to team strategy in the</em>
        <em>centralized part of the system. -- David</em>
      </p>
      <p>
        <em>try </em><a href="http://av.yahoo.com/bin/query?p=robocup&z=2&hc=0&hs=0''">http://av.yahoo.com/bin/query?p=robocup&z=2&hc=0&hs=0''</a>
      </p>
      <hr/>
      <p>
        Verrry Interesting. Questions:
      </p>
      <ul>
        <li>
           What algorithm do the individual bees follow? Heuristic? Genetic?
        </li>
        <li>
           How does performance contrast with other stochastic mining methods (<a href="GeometricDatabase.html">GeometricDatabase</a>, <a href="SimulatedAnnealing.html">SimulatedAnnealing</a>, ...)?
        </li>
        <li>
           What's the relationship with the (<a href="PartyOfFive.html">PartyOfFive</a>) <a href="BlackBoard.html">BlackBoard</a> pattern?
        </li>
      </ul>
      <p>
        --<a href="PeterMerel.html">PeterMerel</a>
      </p>
      <p>
        <em>A </em><a href="BlackBoard.html">BlackBoard</a> can be used by systems that create decision theoretic plans<em></em>
        <em>and attempt to create a crude of sophisticated model of the strategy</em>
        <em>environment. </em><a href="BeeHive.html">BeeHive</a> probably doesn't directly imply this aspect of the<em></em>
        <em>system. I'm hoping to beef up </em><a href="ModelYourEnvironment.html">ModelYourEnvironment</a> to address these issues.<em></em>
        <em>-- David</em>
      </p>
      <hr/>
      <p>
        <em>Bees probably model the external environment as a group, building mutual</em>
        <em>awareness of food sources. The 'dance' that a bee does to transmit the</em>
        <em>information to the other bees in the hive probably also reinforces the</em>
        <em>model of the internal state of the hive that the bees collectively hold.</em>
        <em>-- David</em>
      </p>
      <hr/>
      <p>
        Remember HoneyCombs have a  <a href="HexagonalArchitecture.html">HexagonalArchitecture</a>
      </p>
      <hr/>
      <p>
        <a href="CategoryPattern.html">CategoryPattern</a> 
      </p>
    </div>
  </body>
</html>