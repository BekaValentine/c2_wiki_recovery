<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Analogy Processing
      </h1>
      <p>
        Based on material in <a href="ArgumentByAnalogy.html">ArgumentByAnalogy</a>:
      </p>
      <p>
        Neural nets and the <a href="WetWare.html">WetWare</a> of most animals rely heavily on <a href="ArgumentByAnalogy.html">ArgumentByAnalogy</a>. For example, if you've had several frightening encounters with large creatures that have a lot of teeth, forward-facing eyes, and are heading straight toward you; then the next time you see this set of features, or even most of them, you will be quick to get the hell away. It's not perfect, but turned out to be quite a <a href="UsefulLie.html">UsefulLie</a>, especially when time to observe and explore are in short supply. 
      </p>
      <p>
        Why it may be fairly good at making many kinds of decisions, it may not be so good at explaining the rational behind them. In the above example, it does not "explain" why sharks are dangerous, only that they fit the profile of creatures that have proved dangerous in the past. It's kind of like an economist using statistical analysis to predict bubbles based on a set of factors. Even though their model may indeed have some predictive value, it still does not by itself "explain" why bubbles happen, and thus has limited value in reductionism debates. Related: <a href="AddingEpicycles.html">AddingEpicycles</a>.
      </p>
      <p>
        For a simplified example, let's say a system monitors 26 variables, A through Z.  Let's consider the following variables:
      </p>
      <code>
        F = forward eyes<br/>
        L = large object<br/>
        M = moving toward observer<br/>
        T = teeth spotted<br/>
      </code>
      <p>
        The formula for the threat analogy may resemble:
      </p>
      <code>
        If F > F_threshold And L > L_threshold  And M > M_threshold And T > T_threshold <br/>
        The Scram!<br/>
      </code>
      <p>
        The neural net system "trains" the weights, i.e., the thresholds. It's not exactly an AND statement, but it's our rough approximation. A better model for setting the analogy would be:
      </p>
      <code>
        // example 34<br/>
        If A*AW + B*BW + C*CW........ > targetThreshold Then scram(...)<br/>
      </code>
      <p>
        The "xW" variables are the weights. In this case, most would be zero or near zero except the 4 listed (F, L, M and T).
      </p>
      <p>
        As an approximation of the analogy process, the organism's "learning center" would have an algorithm that copies the observed levels of each variable level from short term memory just after the event. (We tend to remember traumatic events far clearer than mundane ones.)
      </p>
      <p>
        Let's follow factor T. During the threat, the T "recognizer" portion of the victim's brain goes to a high level because teeth are spotted. The recognizer neurons simply recognize only teeth at this point and are not concerned with other factors. (They may share links with other circuitry, such as recognizing white food, but that's another topic.)
      </p>
      <p>
        Just after the threat happens (assuming we live), the high T value is still in short-term memory. The organism will take factors with high levels, such as T, and store these values in a kind of "template array" that is put into an observation stack, which constantly applies something like Statement 34 during the course of a day. 
      </p>
      <code>
        If justFacedWithThreat Then<br/>
        L = mapOfVariableLevelsInObservationBuffer()<br/>
        OA = new Map   // observation action "list"<br/>
        For (v, i) = each item in map L  // v=variable-name, i=intensity-level<br/>
        If i > recentThreatIntensity * adjustmentConstant  // <br/>
        OA[v] = i   // save new observation level<br/>
        EndIf<br/>
        EndFor<br/>
        EndIf<br/>
        addToThreatObservationLoop(OA)  // put array into observation loop<br/>
      </code>
      <p>
        Statement 34 is just one of the many maps in the daily observation loop stack. We could store all factors, even the low ones, but it's possibly better compression of info to only focus on the higher ones.
      </p>
      <p>
        However, this is lossy, an imperfect abstraction, in that low level values can also sometimes be a clue to phenomena.  A better matcher would perhaps calculate the absolute difference between each and every factor of the traumatic imprint map, and a low total difference would trigger the alert systems.
      </p>
      <code>
        // example 36 - a modified version of #34<br/>
        If abs(A-AW) + abs(B-BW) + abs(C*CW) ... > targetThreshold Then ...<br/>
      </code>
      <p>
        However, this may risk irrelevant factors overriding relevant ones. Generally we want to "store" what's different from the normal. In other words, what was "out of the ordinary" when the threat happened. Calibrating factors or weights for "normal" is a later discussion. 
      </p>
      <p>
        Keep in mind that lower-level organisms don't sit around and reason about what happened. They mostly just react to stimuli. If a given stimuli was present during the trauma, its level is stored in the template regardless of whether it is "rational" to consider it relevant or not.
      </p>
      <p>
        But in complex systems, such as our "bubble" example above from the field of economics, even humans may not know what factors to disregard. Multi-variable regression has often proven equal or better to so-called "experts" in the field.
      </p>
      <p>
        --top
      </p>
    </div>
  </body>
</html>