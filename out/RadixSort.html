<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Radix Sort
      </h1>
      <p>
        See other <a href="SortingAlgorithms.html">SortingAlgorithms</a>
      </p>
      <p>
        A category of sorting algorithms (not just a single algorithm, although it is usually casually referred to as if it were) based on characteristics of values rather than just on comparisons. As such, can be faster (e.g. O(n)) than the O(n log n) limit of comparison-based sorts.
      </p>
      <p>
        It is therefore preferable when the speed of sorting is important; however, it cannot be used on completely random data, since the values won't be found to have any relevant patterns that can be taken advantage of.
      </p>
      <p>
        Also see Mc<strong>'Ilroy and Bostic's "Engineering Radix Sort" (</strong><a href="http://citeseer.ist.psu.edu/mcilroy93engineering.html)">http://citeseer.ist.psu.edu/mcilroy93engineering.html)</a> for coding details. It can be an extremely fast string sorter.
      </p>
      <hr/>
      <p>
        There are two types of <a href="RadixSort.html">RadixSort</a>s:  MSD <a href="RadixSort.html">RadixSort</a> and LSD <a href="RadixSort.html">RadixSort</a>.  LSD <a href="RadixSort.html">RadixSort</a> works on the least significant digit first.  As such, it right-aligns its values, so it is suitable for sorting integers.  MSD <a href="RadixSort.html">RadixSort</a> works on the most significant digit first, so it left-aligns its values.  It is often used to quickly sort a list of strings.  See en.wikipedia.org/wiki/Radix_sort for more information.
      </p>
      <p>
        LSD <a href="RadixSort.html">RadixSort</a> works as follows:
      </p>
      <ol>
        <li>
           Sort by the least significant digit of the key, usually with <a href="CountingSort.html">CountingSort</a> or <a href="BucketSort.html">BucketSort</a>.  The sort <em>must</em> be stable; you'll see why next.
        </li>
      </ol>
      <ol>
        <li>
           Repeat for the rest of the digits, working up to the MSD.  Because it's stable, the ordering from the previous iterations remain.  The end result will be sorted.
        </li>
      </ol>
      <p>
        MSD <a href="RadixSort.html">RadixSort</a> works differently, and could be considered a special case of <a href="BucketSort.html">BucketSort</a>.
      </p>
      <ol>
        <li>
            <em>Partition</em> the list into buckets by the most significant digit.
        </li>
      </ol>
      <ol>
        <li>
            Recursively MSD <a href="RadixSort.html">RadixSort</a> each non-empty bucket.
        </li>
      </ol>
      <ol>
        <li>
            Concatenate the results.
        </li>
      </ol>
      <hr/>
      <p>
        Strictly speaking, it's not O(n) except in the subset of cases where there are at most 'k' bits needed to describe an element's position in the sorted set, and 'k' is constant.  If 'k' is not constant, the complexity becomes O(kn).  It's likely that we don't need to add a bit for every new element to be distinguished (which would result in O(n^2), rather one only adds a bit where it is required to differentiate an ambiguous key (bounding case, each comparison in a conventional sort becomes a bit in the key: k = log(n)), and so the complexity becomes O(n log n).  Does that complexity sound familiar to anyone?	Remember, big-O isn't average case.  It's a guide to see what you have in common with an infinite number of monkeys to sort. -- <a href="WilliamUnderwood.html">WilliamUnderwood</a>
      </p>
      <hr/>
      <p>
        Moved here from <a href="SortingAlgorithms.html">SortingAlgorithms</a> (<a href="RefactorMe.html">RefactorMe</a>):
      </p>
      <p>
        <strong></strong><a href="RadixSort.html">RadixSort</a><strong> Kicks ass when applicable. O(n) complexity. <em>More information, please? I've heard of this one but rather forgotten...</em></strong>
        If the key is all there is to the data, and k << n, then this is the fastest possible sort.
        (<em>someone correct me if I mess up this explanation:</em>)
        A <a href="StableSort.html">StableSort</a>.
        <a href="RadixSort.html">RadixSort</a> is useful when the key you are sorting on is a very small integer (0..k), but you have such a large data set keys tend to be repeated many times. For example, if you are sorting strings, you can use <a href="RadixSort.html">RadixSort</a> to (partially) sort by the first 2 letters of the string (interpreted as a number between 0 and 65 535).
        You start with an temporary array t[0..k] initialized to zero.
        Make 2 passes through the data.
        On the first pass, count how many times each key occurs:
      </p>
      <code>
        for(i=0; i<n; i++){<br/>
        t[A[i]]++;<br/>
        };<br/>
      </code>
      <p>
        .
        If the key is all there is to the data, we can generate the output file directly from the temporary array, and we're done. (See
        "Address Calculation: The Forgotten Sort" by Douglas Davidson <a href="http://massmind.org/techref/method/sort/addrcalc.htm">http://massmind.org/techref/method/sort/addrcalc.htm</a> for details.)
      </p>
      <p>
        But usually there's more data associated with each key, so ...
        First we find out where each key should start in the output array:
      </p>
      <code>
        sum=0;<br/>
        for(i=0; i<k; i++){<br/>
        sum += t[i];<br/>
        t[i] = sum;	<br/>
        }<br/>
      </code>
      <p>
        At this point, we know that data with the key "0" starts at location 0,
        data with the key "1" starts at location t[0], data with the key "65 535" starts at location t[65 534].
        At this point, t[k] should equal n.
      </p>
      <p>
        Next we make the second complete pass through the data and move each item directly to the proper place in the output array.
      </p>
      <code>
        for(i=0; i<n; i++){<br/>
        current_key = A[i];<br/>
        destination = t[current_key]++;<br/>
        OutArray[destination] = A[i];<br/>
        };<br/>
      </code>
      <ol>
        <li>
           passes through the input data, one pass through the temporary key table: O(n+k).
        </li>
      </ol>
      <p>
        (<em>Is this stable if we sort-in-place ?</em>).
      </p>
      <p>
        Actually, that's just one pass of <a href="RadixSort.html">RadixSort</a>, which actually means that it is an unrelated sort being used as part of <a href="RadixSort.html">RadixSort</a>.  Specifically, this is a <a href="CountingSort.html">CountingSort</a>.  The idea of <a href="RadixSort.html">RadixSort</a> is that you sort the list by the first digit, then sort it again by the second digit, and so on.
      </p>
      <hr/>
      <p>
        <a href="CategoryAlgorithm.html">CategoryAlgorithm</a>
      </p>
      <hr/>
      <p>
        Research Article December 2013, Joshi et al., Page 65
        International Journal of Emerging Research in Management &Technology ISSN: 2278-9359 Volume-2, Issue-12
      </p>
      <p>
        <a href="http://www.academia.edu/5683159/Analysis_of_Non-Comparison_Based_Sorting_algorithms_A_review">http://www.academia.edu/5683159/Analysis_of_Non-Comparison_Based_Sorting_algorithms_A_review</a>
      </p>
      <p>
        CONCLUSION
        In this paper, we have studied and analysed about non-comparison based sorting algorithms. We analyse the time complexity of each algorithms with time taken by each step of algorithm. After analysing the time we have seen that non-comparison based sorting algorithms beat O(n lg n) by O(n).
      </p>
    </div>
  </body>
</html>