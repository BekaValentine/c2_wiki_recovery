<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Anti Spam Bot
      </h1>
      <p>
        <a href="AntiSpamBot.html">AntiSpamBot</a> was created 2005/01/27 after a multiple hour spam attack.
      </p>
      <p>
        It worked by querying <a href="RecentChangesRss.html">RecentChangesRss</a> on a variable interval that was automatically adjusted to match the rate of changes. For each edit, it would download the text of the page and perform some simple heuristics on the number of external links. If the heuristic identified the edit as spam, it would then automatically revert the page to its previous version. There were also provisions for deleting pages that were created just to contain spam.
      </p>
      <p>
        There was a simple back-off feature in case the bot upset wiki's anti-bot technology. However, it turned out that there was more to the anti-bot technology than was anticipated. The bot was blocked (received 403 errors), and the block was not lifted. It is unclear whether the block was put in place by the anti-bot code, or manually placed by Ward. In either case, a quick email conversation with Ward indicated that in the past, spammers have been delighted to work around bots and/or server-side rules. The bot was taken offline, and the block has stayed in place.
      </p>
      <p>
        Ward's public statement is that he is unwilling to enter into a programming ArmsRace. No matter what processes are put in place, the spammers will try to work around them, and we all enter a never-ending time-consuming hate-producing cycle. This bot was a reasonable attempt at vigilante justice, but we should instead focus on the real, comprehensive, <a href="WikiSpamSolutions.html">WikiSpamSolutions</a>.
      </p>
      <p>
        -- <a href="MichaelSparks.html">MichaelSparks</a>
      </p>
      <p>
        Suppose a person or script deletes various pages (vandalism) or creates various pages (spam). These pages will be restored or deleted later as appropriate. This applies regardless of whether or not a script was used. The effect of the script is on the timing of these events, and hence the extent to which the actions are clustered in <a href="RecentChanges.html">RecentChanges</a>. A script cannot favour one opinion over another, but, if run very frequently, it can inhibit normal editing of pages, especially when others don't know what the script is trying to do. Hence really excessive scripted vandalism or spamming is best dealt with initially by a surge-protection mechanism; a (slower) script is useful for repairing the damage afterwards.
      </p>
      <hr/>
      <p>
        <a href="CategoryWikiSpam.html">CategoryWikiSpam</a> <a href="CategoryWikiMaintenance.html">CategoryWikiMaintenance</a>
      </p>
    </div>
  </body>
</html>