<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Unit Tests Tell You When Youre Done
      </h1>
      <p>
        <em>[From </em><a href="UnitTestsReconsidered.html">UnitTestsReconsidered</a>...]<em></em>
      </p>
      <p>
        <strong></strong><a href="UnitTest.html">UnitTest</a>s tell you when you're done.<strong></strong>
      </p>
      <dl>
        <dt> </dt>
        <dd><em>Many programmers don't know when they are done. They keep implementing long after the thing they need is sufficiently complete. Unit tests help you know when to stop - when you can't think of anything relating to your task to test. And when you are refactoring, your refactoring works when the tests run again. -- </em><a href="RonJeffries.html">RonJeffries</a><em></em></dd>
      </dl>
      <p>
        The question naturally arises, how do you know when you've written enough <a href="UnitTest.html">UnitTest</a>s? Strictly, unless you can enumerate the entire domain of a function, then you haven't written enough tests. The aim for a complete <a href="UnitTest.html">UnitTest</a> is for complete functional coverage.
      </p>
      <hr/>
      <p>
        When you <a href="CodeUnitTestFirst.html">CodeUnitTestFirst</a>, you know that you're done when...
      </p>
      <ol>
        <li>
           All your <a href="UnitTest.html">UnitTest</a>s pass.
        </li>
        <li>
           You can't think of any other tests to write to meet the requirements you are implementing.
        </li>
        <li>
           ...unless the <a href="CodeSmell.html">CodeSmell</a>s, in which case you'd refactor it.  <em>(See </em><a href="WhatIsRefactoring.html">WhatIsRefactoring</a>?)<em></em>
        </li>
      </ol>
      <p>
        <em>If you continue writing code after that point, then you're wasting your time; no additional functionality is needed.</em>
      </p>
      <hr/>
      <p>
        I submit that <a href="FunctionalTest.html">FunctionalTest</a>s tell you you're done. One doesn't need to test every class to know that the XML parser is complete. One just needs to feed in enough cases of XML to know that it is working. The entire subsystem then can be verified to a sufficient level of confidence without verifying each method. 
      </p>
      <dl>
        <dt> </dt>
        <dd><em>Why then are you bothering to verify the subsystem?  Won't the </em><a href="FunctionalTest.html">FunctionalTest</a>s for the whole system reveal any problems in the subsystem?<em></em></dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>In this scope, we're not looking for problems. We're looking for completeness. Different problems. There is a difference between verification and validation. Verification aims for defect-freeness (consistency), whereas validation aims for requirements satisfication (completeness). So, yes, strictly speaking, one would only need the topmost tests. Users don't care if the networking module works, but whether they can send and receive e-mail.</dd>
      </dl>
      <p>
        Moreover, this is much easier to work with, because most well-written subsystems use a narrow public interface (see <a href="NarrowTheInterface.html">NarrowTheInterface</a>, <a href="FacadePattern.html">FacadePattern</a>) to which they must code to. Everything beneath that interface is inconsequential to the rest of the world. Thus, having the friction of functional equivalence at these lower layers is pointless. Testing beneath this layer should not be strict nor restrictive with respect to the interfaces of classes because those interfaces should be pliable in order to work fast. In other words, you don't gain much by doing complete testing, but it costs you in time while you must continually fix tests as you rework the implementation.
      </p>
      <p>
        <em></em><a href="FunctionalTest.html">FunctionalTest</a>s do a good job of telling you what functionality is present, but won't tell you how reliable and bug-free the software is.  Like, XP customer-specified <a href="FunctionalTest.html">FunctionalTest</a>s probably wouldn't test to see what happens when the file contains invalid, unmatched, or otherwise malformed tags.  <a href="UnitTest.html">UnitTest</a>s will, because they're typically written at a lower level of abstraction, where those issues are more obvious.<em></em>
      </p>
      <p>
        See above re: validation vs. verification. You're right regarding verification but that's not the debate here. Actually, you can test invalid XML files at the functional level. I'm not really sure that's the best example you could have provided. Perhaps, say, testing against errors in the Java Virtual Machine if you are writing a secure application? Maybe the line between functional and unit tests is weak.
      </p>
      <hr/>
      <p>
        "When you're done" leaves out an important parameter: <em>what</em> you're doing.
      </p>
      <p>
        A single <a href="FunctionalTest.html">FunctionalTest</a> tells you when you're done implementing some large piece of functionality the customer wants.  Your whole suite of <a href="FunctionalTest.html">FunctionalTest</a>s tells you when you're done implementing everything the customer wants (and has expressed as <a href="FunctionalTest.html">FunctionalTest</a>s).
      </p>
      <p>
        Now assume you're doing <a href="CodeUnitTestFirst.html">CodeUnitTestFirst</a> (otherwise, you don't have the <a href="UnitTest.html">UnitTest</a>s for what you're working on yet, so of course they can't tell you when they're done):
      </p>
      <p>
        A single <a href="UnitTest.html">UnitTest</a> tells you when you're done implementing some very small piece of functionality, which needn't be directly visible to the end user.  The collection of <a href="UnitTest.html">UnitTest</a>s for a given Unit tells you when you're done implementing the Unit.  The main insight I gained by trying it was this: you only end up changing the <a href="UnitTest.html">UnitTest</a>s for the Unit you're changing, and (since you're changing the tests just before you change the code) it's only a tiny bit more work than just changing the code.
      </p>
      <p>
        The "friction of functional equivalence" should be empirically measurable.  The claim of <a href="ExtremeProgramming.html">ExtremeProgramming</a> is that it's lower than the cost of not having <a href="UnitTest.html">UnitTest</a>s.
      </p>
      <dl>
        <dt> </dt>
        <dd>True. More information is required to resolve this problem.</dd>
      </dl>
      <p>
        So is the question settled, then?  Do we all agree that: "A single <a href="UnitTest.html">UnitTest</a> tells you when you're done implementing some very small piece of functionality"?
      </p>
      <hr/>
      <p>
        Finally, <a href="UnitTest.html">UnitTest</a>s can have bugs too.
        <em></em>'Sometimes there are <a href="BugsInTheTests.html">BugsInTheTests</a>!<em></em>'
      </p>
      <hr/>
      <p>
        This discussion would be easier for me to follow with an example.
      </p>
      <p>
        <em>How about chapter 14 of </em><a href="ExtremeProgrammingInstalled.html">ExtremeProgrammingInstalled</a>?<em></em>
      </p>
      <hr/>
      <dl>
        <dt> </dt>
        <dd><em>Many programmers don't know when they are done. They keep implementing long after the thing they need is sufficiently complete. Unit tests help you know when to stop - when you can't think of anything relating to your task to test. And when you are refactoring, your refactoring works when the tests run again. -- </em><a href="RonJeffries.html">RonJeffries</a><em></em></dd>
      </dl>
      <p>
        Not wishing to knock it if it works, but <em>why</em> does it work?  How is this different from <em>the implementation tells you when to stop - when you can't think of anything necessary for the spec that you haven't implemented</em>?  -- <a href="DanBarlow.html">DanBarlow</a>
      </p>
      <p>
        One counterargument is that <a href="FunctionalTest.html">FunctionalTest</a>s tell you you're done, and as a complete subsystem has a narrower interface than the units comprising it, are better than unit tests because they don't get in the way when refactoring the internals of the implementation.
      </p>
      <p>
        Testing beneath this layer should not be strict nor restrictive with respect to the interfaces of classes because those interfaces should be pliable in order to work fast. In other words, you don't gain much by doing complete testing, but it costs you in time while you must continually fix tests as you rework the implementation. -- <a href="SunirShah.html">SunirShah</a>
      </p>
      <hr/>
      <p>
        <em>Serious question: how do you unit test a UI? Is it user experience testing at that point or is there a programmatic framework I don't know about yet?</em>
      </p>
      <p>
        Read up: <a href="TestFirstUserInterfaces.html">TestFirstUserInterfaces</a>. Because Views are the only part of a program that you "look at", they are high-bandwidth but low feedback. Tests can't check for esthetics or usability, but they _can_ preserve these at refactor time. And, at their highest level, tests can help you build-out new forms and widgetry without excessively stopping to "look at" your view.
      </p>
      <hr/>
      <p>
        <a href="CategoryTesting.html">CategoryTesting</a>
      </p>
    </div>
  </body>
</html>