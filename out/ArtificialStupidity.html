<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Artificial Stupidity
      </h1>
      <p>
        Birds fly by flapping their wings. Airplanes fly, but their wings don't move (at least, not in the same way). Are airplanes artificial birds?
      </p>
      <p>
        Not really.  
      </p>
      <p>
        Flying is not what makes a bird a bird. Things that fly are not artificial birds.
      </p>
      <p>
        And yet flight is very valuable to us. So why do we care whether or not an airplane is an artificial bird? It's the flightness of an airplane that's useful to us, not the birdness.
      </p>
      <p>
        Hence <a href="ArtificialStupidity.html">ArtificialStupidity</a>. Being unyoked from <a href="ArtificialIntelligence.html">ArtificialIntelligence</a>, your program can be artificially stupid in very useful ways.
      </p>
      <hr/>
      <p>
        There is a Dr. near Pittsburg who is working on how to make a computer simulate stupidity and forgetfulness. The theory is that making the computer forget things like a human is the next step to AI. The book is supposed to come out 2002-2003. A little bit different from the <a href="ArtificialStupidity.html">ArtificialStupidity</a> discussed on the rest of the page.
      </p>
      <p>
        Sounds like he just needs to get with the rest of the world and buy a windows box...
      </p>
      <p>
        <em>That isn't such a bad theory. </em><a href="ExpertSystems.html">ExpertSystems</a> are developed as lossy (forgetful) algorithms that make predictions in accord with a large data set. Learning algorithms are similar in scope. My own ruminations on the subject are that this lossiness is an important part of intelligence - it is what causes us to develop and use abstractions and generalizations, and to gain confidence in them. That said, you'd need the right "flavor" of forgetfulness.<em></em>
      </p>
      <hr/>
      <p>
        <em>I like this. This is one of the best descriptions of why AI isn't so important that I've read. -- </em><a href="SunirShah.html">SunirShah</a><em></em>
      </p>
      <p>
        If natural flying is defined as what a bird does, airplanes are complete failures at artificial flying. I have yet to see a bird that flies by lighting its tail on fire so that the escaping gases drive it forward while holding its wings rigidly at its side. There is no production aircraft that lands by swooping down to a near zero speed stall while grabbing a branch with its claws. 
        <em>[carrier landings are done full thrust, so that if you *miss* the tailhook, you don't go *plonk* off the end of the deck and into the water. -- Pete Hardie]</em>
        The point is that it is very easy to equate a concept (flying) with an instance that expresses the concept (birds). As the title of this page indicates, I make this comparison when the subject of AI comes up. My objective is to point out that people express the concept of intelligence, but just like birds, if we define natural intelligence as "that thing that people do", then AI will always be a failure. If on the other hand, we look at AI in light of AF (artificial flying) then I think it is possible to create a form of intelligence that is useful and will change the way we live. -- <a href="LeoScott.html">LeoScott</a>
      </p>
      <p>
        <em>Of course, how do we know that producing an airplane that flapped it's wings wouldn't be better than airplanes that light their butt on fire? Maybe flapping is better, but just beyond our means to do.</em>
      </p>
      <p>
        Great question. And like most great questions it contains its own answer. Each instance that expresses a concept is constrained by the reality of the components that are available for its construction. People have tried and failed to create wing flapping (bird-like) aircraft <em>(Well, most failed. These folks didn't: </em><a href="http://www.utias.toronto.edu/lowsped.htm)''.">http://www.utias.toronto.edu/lowsped.htm)''.</a> What is important is that AF is still a success in spite of the fact that we are forced to construct it out of components that fail completely at being bird like. -- <a href="LeoScott.html">LeoScott</a>.
      </p>
      <hr/>
      <p>
        Flapping is not really a means of lift in birds, but of propulsion. The lift comes from the funny shape that the wings have. Airplanes get their propulsion differently, but they get their lift the same way and their wings do have the same shape in the important respects. Birds and planes have a lot in common and certainly they both can fly. We could reasonably call birds "natural flying" and airplanes "artificial flying".
      </p>
      <p>
        The first basic problem with artificial flying was understanding how natural flying actually worked. People misunderstood the flapping for 100s of years. A second problem was getting materials with the right weight and strength.
      </p>
      <p>
        I like the metaphor, but I don't see where the "stupidity" bit comes in. We may get "artificial intelligence" by a different mechanism to natural intelligence, but it will still be intelligence rather than its opposite. I suspect the mechanisms will actually be similar too, in important respects, just as airplane flight is similar to bird flight once you understand it. We are not yet in the position of understanding natural intelligence, and it's not clear whether we have the right materials to build an artificial one even if we knew how.
      </p>
      <hr/>
      <p>
        "The question of whether a computer can think is no more interesting than the question of whether a submarine can swim." -- <a href="EwDijkstra.html">EwDijkstra</a> 
      </p>
      <hr/>
      <p>
        <em>Of course, how do we know that producing an airplane that flapped it's wings wouldn't be better than airplanes that light their butt on fire? Maybe flapping is better, but just beyond our means to do.</em>
      </p>
      <p>
        Changing wing profile is extremely important for birds in flight, and is even used on some planes.  Birds use wings for propulsion, lift and steering.  Planes separate all these out. The flightness of birds is very different from that of planes.  
      </p>
      <p>
        <em>What you say is obviously true, but didn't answer the question. We *don't* know that a 'flapping wing' airplane wouldn't be better (for some problem domain) because we haven't the slightest hope of building one with our current understanding of materials, engineering, and fluid dynamics.</em>
      </p>
      <p>
        I thought tiny ornithopters were becoming popular - especially down at insect-size, where things like turbines and props don't work so well.
      </p>
      <hr/>
      <p>
        Ok, so airplanes don’t fly naturally, so what? Sorry if I seem to be aggressive but can anyone answer me, how can I make <a href="ArtificialStupidity.html">ArtificialStupidity</a>? This page is about ways or methods to do artificial stupidity.
      </p>
      <p>
        The metaphor was good and appealing but we shouldn’t lose ourselves in the analogy. -- <a href="GuillermoAlcantara.html">GuillermoAlcantara</a>
      </p>
      <hr/>
      <p>
        One could consider <a href="ArtificialStupidity.html">ArtificialStupidity</a> a totaligism or could one consider <a href="ArtificialStupidity.html">ArtificialStupidity</a> a <a href="NonTotaligism.html">NonTotaligism</a> -- <a href="RobertKausch.html">RobertKausch</a>
      </p>
      <hr/>
      <p>
        Why would one AutomateStupidity (AS) or even AutomateIntelligence (AI)? Don't we have enough of both? <em>I would say we have more than enough of the former, and not nearly enough of the latter.  Not that I think AI will solve that problem...</em>
      </p>
      <p>
        Why do you need <a href="ArtificialStupidity.html">ArtificialStupidity</a> when you can write like this? 031013 fredderf
      </p>
      <hr/>
      <p>
        On Google street-view, Google tries to <strong>blur out specific faces</strong> and license plates that may inadvertently appear in the photos for legal reasons. One Mexican restaurant has a nicely-done painting of a dancing lady in colorful, traditional Mexican garb on the front wall. But her face is blurred out; and that's how you tell it's a bot doing the blur selection and not a human. Similarly, road or parking signs that have a resemblance to license plates are also blurred out. I give the bot credit for recognizing that face as a face, but I also give it dumb-ass points for not understanding the context. 
      </p>
      <p>
        Although it could be argued that a human would also blur it out if the rule was ("when in doubt, blur it out"). As it looked, most people would be nearly certain it was a painting and was a part of the building decoration and/or ads. A portrait (face) painting without context perhaps would be considered fair game for "legal" blurring being one may not want the face depicted to be public, so I'm not sure realism is the real issue. The rule is "decoration" or "ad", and without real-world experience, a bot won't know that with sufficient certainty. A human from a <strong>remote jungle village</strong> may similarly not know the difference between a happenstance facial portrait leaning on a wall versus commercial ads/decorations. It's the experience of living (and eating) in the civilization being photographed that's the real difference-maker and not so much being human itself.
      </p>
      <p>
        If an actual lady in colorful flowing traditional Mexican garb happened to be walking in front of that Mexican restaurant and was photographed by the Google van, and if a human "blur clerk" inadvertently mistook her image for a restaurant decoration (or even a paid promotional actress), and Google was sued for that, a jury would likely agree that it was an honest mistake and it wouldn't be a significant issue. A jury of bots? Well, that's a different story.
      </p>
      <hr/>
      <p>
        Would ArtificialHumour need a dose of <a href="ArtificialStupidity.html">ArtificialStupidity</a> as well as <a href="ArtificialIntelligence.html">ArtificialIntelligence</a>? Is there an equivalent to the <a href="TuringTest.html">TuringTest</a>? (can't tell whether there is an idiot or a computer on the other terminal).
      </p>
      <hr/>
      <p>
        iTroll, anyone?
      </p>
      <hr/>
      <p>
        <a href="CategoryArtificialIntelligence.html">CategoryArtificialIntelligence</a>
      </p>
    </div>
  </body>
</html>