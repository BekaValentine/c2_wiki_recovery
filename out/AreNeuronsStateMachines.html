<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Are Neurons State Machines
      </h1>
      <p>
        [From <a href="WisdomOfTheEast.html">WisdomOfTheEast</a>]
      </p>
      <hr/>
      <p>
        My brain can write programs (with some help from my body).  My neurons are state machines.  Therefore writing programs is a purely logical activity.  So is intuition.  Complex, but still logical.
      </p>
      <p>
        <em>Your neurons are not state machines. That's just your way of understanding what your neurons do. A </em><a href="FiniteStateMachine.html">FiniteStateMachine</a> is most likely an inadequate model of what neurons do in that it is an inadequate model of what any simple tropism does. See <a href="InfiniteStateMachine.html">InfiniteStateMachine</a> for more on this.<em></em>
      </p>
      <p>
        No, a <a href="StateMachine.html">StateMachine</a> is an accurate model of what neurons do.  Given neurotransmitter state and input strength at the axon they send or don't send signals down dendrites.  There are a finite number of states a neuron can be in, although that number may be quite large.  There is nothing magical going on.  Writing a program is a purely logical activity.  So is intuition.
      </p>
      <p>
        <em>"Neurotransmitter state" and "axon state" are purely statistical attributes - not physics.</em>
      </p>
      <p>
        Wait a second.  You're saying the levels of neurotransmitter at a synapse are statistical attributes but not physics?  I don't see the dichotomy, and I don't see why it isn't physics.  It's chemistry, and chemistry is physics. Statistics is a way to model complex processes like physics, but the processes don't care how we model them.  They are still physics.
      </p>
      <p>
        <em>It's a matter of granularity. The predictive power of chemistry relies on having honking big vats of molecules to play with. Avogadro's number sized vats of the stuff, or some significant fraction thereof. On those scales there are a number of extremely reliable statistical relationships we can use to describe the state of a process.</em>
      </p>
      <p>
        Chemistry models the interaction of molecules, not just vats.
      </p>
      <p>
        <em>Explain further. URLs for chemical-as-opposed-to-physical models of the interaction of individual molecules would be helpful. Chemical models of neurotransmitter interactions in particular.</em>
      </p>
      <p>
        Does it matter if we call it chemistry or physics?  No one (to my knowledge) has shown quantum effects influencing neuron behavior.  Even if they do, they just introduce probability, not intuition.
      </p>
      <p>
        <em>But the less stuff we have to play with, the more the physical models come to dominate the statistics. When we're talking about synapses we're way down below the levels described by chemistry's reaction rates and similar distinctions. We're in QM-land talking about molecular machines, governed only by the rules of </em><a href="QuantumMechanics.html">QuantumMechanics</a>.<em></em>
      </p>
      <p>
        Can you give an example of a quantum effect exhibited in the behavior of a neuron or set of neurons?  I haven't seen any.
      </p>
      <p>
        <em>Read </em><a href="RogerPenrose.html">RogerPenrose</a>'s <a href="ShadowsOfTheMind.html">ShadowsOfTheMind</a>. Here's a URL for a review: <a href="http://psyche.cs.monash.edu.au/v2/psyche-2-03-klein.html''">http://psyche.cs.monash.edu.au/v2/psyche-2-03-klein.html''</a>
      </p>
      <p>
        Good review.  The author of that review doesn't find Penrose convincing either.
      </p>
      <p>
        Everything is governed by the rules of <a href="QuantumMechanics.html">QuantumMechanics</a>.
      </p>
      <p>
        <em>Key word in that statement was "only".</em>
      </p>
      <p>
        Everything is governed only by the rules of <a href="QuantumMechanics.html">QuantumMechanics</a>, then.  A transistor surely is.  PnP junctions exhibit quantum effects, but they we can model them accurately enough to build computers out of them.
      </p>
      <p>
        <em>Um, everything? Where's your </em><a href="QuantumGravity.html">QuantumGravity</a> when you need it? QM is not a complete description of anything.<em></em>
      </p>
      <p>
        <em>Demonstrably. But then does there exist a biological neural network that reproduces the behavior of an FSM neural network? If so, your isomorphism is proved. If not, then quantum wiggle room remains. I'd be very curious to see any such evidence.</em>
      </p>
      <p>
        <em>In any case, the point made on </em><a href="InfiniteStateMachine.html">InfiniteStateMachine</a> is that the state of your biological process is not contained in your brain. Your state depends for the most part on the rest of the universe. DescartesWasaWanker.<em></em>
      </p>
      <p>
        Neurons are not understood well enough for a complete FSM model.  That doesn't mean one can't be created.  Quantum wiggle room doesn't put magic back into brain behavior.  Just randomness (or hidden variables).
      </p>
      <p>
        <em>Thank you for </em><a href="ShiftingTheBurdenOfProof.html">ShiftingTheBurdenOfProof</a>. If you don't understand neurons well enough for a complete FSM model, kindly stop claiming same. Say <a href="IdontKnow.html">IdontKnow</a>.<em></em>
      </p>
      <p>
        If what you say is true then nothing behaves like a <a href="StateMachine.html">StateMachine</a>.  A transistor behaves exactly like a <a href="StateMachine.html">StateMachine</a>, goverened by the rules of <a href="QuantumMechanics.html">QuantumMechanics</a>.
      </p>
      <p>
        <em>Neurons aren't transistors and don't behave anything like transistors. </em><a href="StrawMan.html">StrawMan</a>.<em></em>
      </p>
      <p>
        I didn't say neurons were transistors.  I said both behave like state machines.
      </p>
      <p>
        And I challenged you on it. So now you're just restating it for good measure?
      </p>
      <p>
        Unless you're arguing that neuron behavior depends on amplifying quantum events (ala Schrodinger's Cat), the neurons are predictable (in other words, able to be modeled accurately) the same way transistors are predictable, albeit more complex and therefore more difficult to predict.
      </p>
      <p>
        <em>The behaviour of a neural synapse can indeed hinge on the transmission of a single molecule. Our understanding of the behaviour of single molecules is dominated by their QM description. Now the question is whether neural function depends in any way on quantum effects. And the answer is we don't know. </em><a href="RogerPenrose.html">RogerPenrose</a> has famously asserted that exactly these quantum effects are necessary to gross brain functions<em></em>
      </p>
      <p>
        And this somehow make writing a program an intuitive and not a logical process?  Sorry, if there's a quantum effect it may introduce randomness or a hidden variable (or parallel worlds), but the processes can still be considered logical.  They can be accurately modeled.  I've never seen any evidence that a single vector state collapse is amplified to alter neuron behavior.  Have you?
      </p>
      <p>
        <em>Whether Penrose is correct or not, </em><a href="QuantumMechanics.html">QuantumMechanics</a> admits no single local deterministic state-description of a single molecule of neurotransmitter.<em></em>
      </p>
      <p>
        Sure it does.  It may not allow the description of a single particle, but a molecule is a different beast.
      </p>
      <p>
        <em>If you can't adequately describe a particle, how can you describe a gaggle of 'em? The closer you get to classical scales, the less QM is relevant to description. At best a neuron, and everything else, is splitting constantly into an indeterminate number of parallel versions of itself, one for each possible subatomic configuration (</em><a href="ManyUniversesTheory.html">ManyUniversesTheory</a>) or the event of a neuron firing is correlated with events occurring in all parts of the universe all at once (<a href="TransactionalInterpretation.html">TransactionalInterpretation</a>). Depending on which flavor of physics you prefer - no one's been able to think of an empiricism, yet, to choose between 'em. In any case, no FSMs here.<em></em>
      </p>
      <p>
        So why bother with science if everything is unpredictable?  It's all magic from where you sit.
      </p>
      <p>
        Anything that's not an FSM is magic?
      </p>
      <p>
        And yet neurons fire based on input and neurotransmitters. I think you're misinterpreting quantum physics. It doesn't say nothing happens, or that nothing can be modeled.
      </p>
      <p>
        <em>I haven't asserted that nothing happens, or that nothing can be modeled. More </em><a href="StrawMan.html">StrawMan</a>s. I've asserted that the state of a neuron is feasibly non-local, and so no FSM can model it adequately.<em></em>
      </p>
      <p>
        Why is a neuron less local than a PnP junction?
      </p>
      <p>
        <em>Because its behavior hinges on the behavior of QM-relevant critters - a single atom of Nitrogen Oxide, for example. A </em>PnP junction uses a torrent of electrons in order to simulate part of an FSM. Even then it need not be simulating an FSM - plenty of transistors in NonTuringComputers.<em></em>
      </p>
      <p>
        <em>Even ignoring the QM issues, a </em><a href="FiniteStateMachine.html">FiniteStateMachine</a> is a lousy description of what neurons do because any process they govern depends on events outside their internal configuration. For example, consider a man with an axe. Foolishly or suicidally, the man embeds the axe in his own skull, severing the connections of a particular neuron to its fellow neurons. I humbly submit that no <a href="FiniteStateMachine.html">FiniteStateMachine</a> description of neurons can account for the result of this common everyday occurrence. Or if you think suicidal axe-men are too rare to consider you may contemplate an FSM description of a brain cancer patient, or an epileptic, or a child eating sugar. "We're no computers, Sebastian. We're physical."<em></em>
      </p>
      <p>
        Finite state machines depend on events outside their internal configuration.
      </p>
      <p>
        <em>Not for the determination of their state and configuration they don't.</em>
      </p>
      <p>
        Yes, they do.  External vents trigger state changes.
      </p>
      <p>
        <em>Unless you want to assert that that axe blade/cancer-cell/whole-brain-neurotransmitter-imbalance/ambient-blood-born-sugar-rush is part of description of state of each particular FSM, the FSM model simply fails to capture neural ontology.</em>
      </p>
      <p>
        The <a href="StateMachine.html">StateMachine</a> describes the behavior of a neuron.  There are a finite number of ways it can respond to external events.
      </p>
      <p>
        Computers are physical.  Who is Sebastian?
      </p>
      <p>
        <em>Many apologies - my fault. It's a quote from </em><a href="BladeRunner.html">BladeRunner</a>. Sebastian is an engineer who asks a pair of rogue androids to show him some feat of technological prowess, like adding up numbers really fast. The androids enslave and then kill him.<em></em>
      </p>
    </div>
  </body>
</html>