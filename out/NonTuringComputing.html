<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Non Turing Computing
      </h1>
      <p>
        What on earth is <a href="NonTuringComputing.html">NonTuringComputing</a>? Is it intended to mean
      </p>
      <ul>
        <li>
           <a href="NotTuringEquivalent.html">NotTuringEquivalent</a> or
        </li>
        <li>
           possible but <a href="NotNaturalOnaTuringMachine.html">NotNaturalOnaTuringMachine</a> or
        </li>
        <li>
           <a href="ImpossibleOnaTuringMachine.html">ImpossibleOnaTuringMachine</a>, but clearly computation or
        </li>
        <li>
           <a href="NonTuringModelOfComputation.html">NonTuringModelOfComputation</a> or
        </li>
        <li>
           <a href="QuestionablyEvenComputing.html">QuestionablyEvenComputing</a> at all - what the heck does computable mean, anyway?
        </li>
      </ul>
      <p>
        <a href="HomeostaticComputing.html">HomeostaticComputing</a> should fit under <a href="ImpossibleOnaTuringMachine.html">ImpossibleOnaTuringMachine</a> or <a href="NonTuringModelOfComputation.html">NonTuringModelOfComputation</a>. I'm inclined toward the former, since a <a href="TuringMachine.html">TuringMachine</a> should be able to generate the same result. -- <a href="AlistairCockburn.html">AlistairCockburn</a>
      </p>
      <p>
        <em>If I may suggest a direction: there are some fundamentals to </em><a href="TuringMachine.html">TuringMachine</a>s that are not true of all SignalProcessors. For example, the representation of state by the machine, rather than by the signal.<em> -- </em><a href="PeterMerel.html">PeterMerel</a>
      </p>
      <hr/>
      <p>
        The discussion is better understood (and perhaps refactored) from the standard truism that a turing machine can simulate (slowly) absolutely any digital computer. (There's a small possibility that certain problems may even be better suited to the turing machine...)
      </p>
      <p>
        <em>As I've been reading recently, the above is not true... A turing machine is defined to only take input at the start of its run, and then it runs to completion (or non-completion, as the case may be). A growing number of people have been publishing about the limits of that sort of "single-computation" computer compared to one that accepts input along the way. Peter Wegner of Brown Univ argued in a refereed journal (CACM) that the latter can compute things that the Turing machine can't. I've seen additional authors of this view since then. The point being, that a Turing machine has a particular sort of limitation that distinguishes it from, say, biological cells, which interact with their surroundings. This point of view may affect the correctness of the paragraphs that follow. -- </em><a href="AlistairCockburn.html">AlistairCockburn</a><em></em>
      </p>
      <p>
        <em>That's absurd; if you want incremental output from a Turing Machine, just have it reach completion periodically with an output value which encodes enough information to 'restart' the computation immediately thereafter. Keep feeding the machine's output back in to itself, gleaning bits of the answer each time. -- </em><a href="AdamMegacz.html">AdamMegacz</a><em></em>
      </p>
      <p>
        <em>(Hi, Adam, you seem to have misread... the previous para said "input", not "output")</em>
      </p>
      <p>
        Anyway, a large enough digital computer can also simulate any actual turing machine with a fairly trivial program.
      </p>
      <p>
        <em>One could give the Turing Machine three tapes (equivalent to one tape): one is the conventional working tape, the other is a "write-only" tape on which the head is constrained to move right one square every time it writes a symbol, and the third is a "read-only" tape on which the head is constrained to move right one square every time it reads a symbol. Incremental output and input: every now and then the machine's instructions might see it reading something from the read-only tape, or writing something to the write-only tape. The two tapes could be referred to, respectively, as stdout and stdin). The contents of the third tape (or interleaved squares in the equivalent one-tape model) could be anything until such time as the machine reads it - just because </em>'we<em>' know what it says is irrelevant: many many things about the physical world exist right now that we don't know about, but once we do we'll no doubt be going around saying that we learned them.</em>
      </p>
      <p>
        Therefore, what people are really talking about here is the question of computability in the digital paradigm. In a sense, the question is "Does there exist the (possibly unwritten) computer program to perform interesting task FOO?". This makes the whole thing easier to think about.
      </p>
      <p>
        Then there are those comments concerned with the cost of computation. Obviously a real turing machine is outrageously impractical for virtually any task. However, some tasks are better done not by computer, and some tasks just can't be done by digital computer. Assembling chickens from atoms is currently one of them. I anticipate that task to be the sole domain of chickens for quite some time.
      </p>
      <hr/>
      <p>
        There's an article about <a href="NonTuringComputing.html">NonTuringComputing</a> at <a href="http://www.techreview.com/currnt.htm">http://www.techreview.com/currnt.htm</a> (better reference?)
      </p>
      <hr/>
      <p>
        There are many kinds of computation that differ from those modeled by a Turing machine. Consider analog computers, neural nets, protein regulation, quantum computing to name a few. Tempers only flair when one is argued to be <em>faster</em> than another.
      </p>
      <p>
        <em>This is an incorrect use of terminology. These are "non-von-Neumann" models of computation, not "non-Turing" (with the probable exception of quantum computing). In the real world, analog computers do not have infinite accuracy, so they can be simulated on Turing machines. It is however true that a theoretical infinitely accurate analog computer could be non-Turing, but even then it would have to use Lukasiewicz logic to be so. Ordinary analog computers, of the sort that once were widely used commercially, are not even as powerful as Turing machines.</em>
      </p>
      <p>
        <em>And as for neural nets and protein/DNA/RNA computing, they are simulated exactly on ordinary computers all the time. They are interesting in a number of ways, e.g. DNA computing can, in theory, be considerably faster than von Neumann architectures. But they are no more powerful, in the theoretical sense, than Turing machines: Turing machines can simulate them in a finite number of steps. That's the defining issue. It doesn't matter how </em>'many<em>' finite steps the simulation takes.</em>
      </p>
      <p>
        <em>Even quantum computing is a big question mark. It is widely agreed that they </em>'might<strong> be more powerful than Turing machines, but not that they </strong>definitely<em>' will be, because there are foundational issues in quantum physics at stake that we are not 100% sure of.</em> -- <a href="DougMerritt.html">DougMerritt</a>
      </p>
      <p>
        OK, perhaps these need to be moved to a page where we discuss things that are Turing machines, and yet are NonVonNeumann architectures. Perhaps combine with the list at <a href="VonNeumannArchitecture.html">VonNeumannArchitecture</a>.
        -- <a href="DavidCary.html">DavidCary</a>
      </p>
    </div>
  </body>
</html>