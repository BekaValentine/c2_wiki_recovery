<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Mistakes Of Roger Penrose
      </h1>
      <p>
        According to <a href="StephanHouben.html">StephanHouben</a> in the page discussing <a href="TheEmperorsNewMind.html">TheEmperorsNewMind</a>, <a href="RogerPenrose.html">RogerPenrose</a>'s biggest mistake is to be one of those <a href="HardCorePlatonists.html">HardCorePlatonists</a>. This means that, at least in Stephan's non-platonist mind, he is unable to give a fair account of the implications of <a href="GoedelsIncompletenessTheorem.html">GoedelsIncompletenessTheorem</a>. Stephan also complains that Penrose uses <a href="CommonSense.html">CommonSense</a> arguments while in quantum land, which is "not the most reliable guide". I make a few amateur comments in defence of Penrose in these areas in <a href="TheEmperorsNewMind.html">TheEmperorsNewMind</a> and <a href="ShadowsOfTheMind.html">ShadowsOfTheMind</a>. -- <a href="RichardDrake.html">RichardDrake</a>
      </p>
      <p>
        I never accused <a href="RogerPenrose.html">RogerPenrose</a> of actually making <strong>mistakes</strong>. However, I <strong>did</strong> accuse him of interpreting <a href="GoedelsIncompletenessTheorem.html">GoedelsIncompletenessTheorem</a> in a particular, Platonist, way. I read <a href="TheEmperorsNewMind.html">TheEmperorsNewMind</a> before I started studying mathematics, and at that point of time I thought his conclusion (that Fk(k) is true) was inevitable. It was only at university that I met the other viewpoint, which is arguably a bit counter-intuitive but perfectly valid. That doesn't mean that <a href="RogerPenrose.html">RogerPenrose</a>'s view is a <strong>mistake</strong>, it is just that it's not as clear-cut as one may think after reading the book. Perhaps <a href="RogerPenrose.html">RogerPenrose</a>'s biggest "mistake" is to be such a good writer ;-) -- <a href="StephanHouben.html">StephanHouben</a>
      </p>
      <p>
        <em></em><a href="MeaCulpa.html">MeaCulpa</a>, Stephan. Mostly I wanted your point of view on this page. <a href="StephenHawking.html">StephenHawking</a> would sympathize with you. (Looking at your name again, you're not a Dutch transcription of his are you?)<em></em>
      </p>
      <p>
        [Penrose made a <strong>huge</strong> mistake. He completely forgets that human mathematicians are inconsistent systems: they make mistakes and believe in provable falsehoods fairly frequently (unintentionally, of course). They are thus perfectly well handled by Goedel's theorems.]
      </p>
      <hr/>
      <p>
        Another objection runs as follows:
      </p>
      <dl>
        <dt> </dt>
        <dd>Quantum theory is probably at too low a level to be directly relevant to consciousness. Rules about quarks lead to higher level rules about protons. Rules about protons lead to higher level rules about atoms. Rules about atoms lead to higher level rules about chemistry. And so on. Quark theory is not relevant to biologists. They only care about the emergent phenomena that present themselves as the rules of the next level down. (This argument is from <a href="CollapseOfChaos.html">CollapseOfChaos</a>, which interested parties will find, well, interesting.)</dd>
      </dl>
      <p>
        Again I ask, how do we <strong>know</strong> consciousness is about the high level rules?
      </p>
      <dl>
        <dt> </dt>
        <dd>Ultimately we don't, but it seems likely. For example, we don't consider rocks to be conscious, and cats aren't very conscious, and humans lose it when they die, yet they are all built from the same low-level quantum components. Therefore it is not the components themselves which are interesting, but the way in which they are arranged.</dd>
      </dl>
      <p>
        The whole point of BoseEinsteinCondensates, of which lasers are one well-known example, are that quantum effects <em>can</em> operate at a larger scale, but only if things are so arranged, as you say. So far, no disagreement?
      </p>
      <ul>
        <li>
           Lasers are an example of Bose Einstein <strong>statistics</strong>, but are not <a href="BoseEinstein.html">BoseEinstein</a> <strong>condensates</strong>. They are closely related, of course, but not identical. But yes, clearly quantum effects can become macroscopic in scale, and lasers are one of many examples.
        </li>
      </ul>
      <p>
        <em>I've read somewhere in </em><a href="RichardDawkins.html">RichardDawkins</a> that some recent <strong>experimental</strong> results would indicate that quantum processes do not, in fact, play a crucial role in human neural organization. To be taken with a grain of salt, of course, since I don't have references to provide.<em></em>
      </p>
      <p>
        I think everyone agrees that experimental results have not yet confirmed any variety of the BoseEinsteinCondensates thesis. Whether it has been shown to be false, for all possible "locations" in the brain, I also doubt, from what I've read. Particular hypotheses as to how BE condensates arise and are shielded for a time within the brain, before interacting with more conventional "switching", may well have been falsified by experiment. I think TheJurysStillOut on this one. That's partly why I thought it would be interesting to track on Wiki.
      </p>
      <hr/>
      <p>
        I think the above objections to Penrose are worth more discussion on Wiki, so I thought I'd put 'em together here. But strangely, I think it's even more helpful, for those interested in this area, to record some "mistakes" Penrose himself admits to making:
      </p>
      <ul>
        <li>
           some (Penrose claims minor) mistakes in the logic related to Goedel in <a href="ShadowsOfTheMind.html">ShadowsOfTheMind</a>, as pointed out politely but firmly by SolomonFeferman (who it seems is also a pretty hard core platonist as well as a world class logician) <em>[also pointed out not so politely and somewhat more firmly by </em><a href="DrewMcDermott.html">DrewMcDermott</a> at the same site]<em> - see </em><a href="http://psyche.cs.monash.edu.au/v2/psyche-2-23-penrose.html">http://psyche.cs.monash.edu.au/v2/psyche-2-23-penrose.html</a>
        </li>
        <li>
           the proposed "one graviton" basis for the collapse of the wave function in <a href="TheEmperorsNewMind.html">TheEmperorsNewMind</a> is described as "too crude" in <a href="ShadowsOfTheMind.html">ShadowsOfTheMind</a> and replaced by a rate of decay based on more elegant considerations of gravitational energy differences, based on the ideas of Diosi and others (section 6.12, p339, <a href="ShadowsOfTheMind.html">ShadowsOfTheMind</a>)
        </li>
        <li>
           the hoped-for role of quantum gravity in <em>brain plasticity</em> - the famed changes in synaptic connections between neurons in the human brain - in <a href="TheEmperorsNewMind.html">TheEmperorsNewMind</a> (p512) is transferred to the much smaller, "possibly intelligent in their own right" <em>microtubules</em> in the <em>cytoskeleton</em> of each neuron, where perhaps coherence of the BoseEinsteinCondensate type may indeed occur (as described in <a href="ShadowsOfTheMind.html">ShadowsOfTheMind</a>, p357-371).
        </li>
      </ul>
      <p>
        Either this guy is being pretty sloppy with us or we're watching what real science is like, long before the dust clears and the Nobel prizes are announced. The breadth of the issues Penrose is trying to communicate (and readability is one of the finest qualities of his two books in my view), plus his daring, are bound to lead to some "slip ups". But you can tell a lot about someone's quality as a thinker from his reaction to such "gaffes" (ho ho, as if most Wiki readers could have pointed them out in advance).
      </p>
      <p>
        But the most amazing "mistake", to my mind, I've left to last, because it's one that as Penrose himself says, has been a tacit assumption of "many other physicists" since the 1920s (and I assume that includes some with pretty good reputations). This is taken from p461 of <a href="TheEmperorsNewMind.html">TheEmperorsNewMind</a>, where Penrose has just showed that the probabilities involved in quantum state reduction are <em>different</em> if time is reversed - the first inkling in all of mainstream physics since Newton of <strong>time-asymmetry</strong>:
      </p>
      <dl>
        <dt> </dt>
        <dd>It is remarkable how many physicists seem tacitly to assume that these two probabilities are the same. (I, myself, have been guilty of this presumption, cf Penrose 1979 p 584.) However, these probabilities are likely to be wildly different, in fact, and only the former [with time going forward] is correctly given by quantum mechanics!</dd>
      </dl>
      <p>
        Now when the vast body of physicists overlook something of such fundamental importance - the first real time-asymmetry in physics for centuries - and for sixty odd years, I agree with Penrose that it deserves a quick mention. Especially when we <a href="HumanBeing.html">HumanBeing</a>s have had for so many more centuries this strange concept of past, present and future, with our free choices apparently only able to affect the latter. -- <a href="RichardDrake.html">RichardDrake</a>
      </p>
      <p>
        <em>The bit about microtubules should be a dead giveaway that something is wrong. Amoebae are composed partly of microtubules, and they don't exhibit the sorts of behaviors most people would count as intelligent.</em>
      </p>
      <hr/>
      <p>
        Sure, but this concept of past, present and future can adequately be explained by Thermodynamics - no need to add additional time-asymmetric facets to the theory. Of course, <a href="RogerPenrose.html">RogerPenrose</a> notes that this raises the question what caused the universe to be so ordered in the first place. 
      </p>
      <p>
        <em>can be explained by Thermodynamics</em> I wish someone <em>would</em> explain. and how is that related to news that many systems will run both directions? (see <a href="http://www.sciencenews.org/20020727/fob1.asp)">http://www.sciencenews.org/20020727/fob1.asp)</a>
      </p>
      <p>
        About this time-asymmetry: I'm not an expert in <a href="QuantumMechanics.html">QuantumMechanics</a>, but it is important to note the way QM is <em>used</em> to compute things. <a href="RogerPenrose.html">RogerPenrose</a> also talks about this, but perhaps I should stress it again. When you want to compute, for example, the orbit of an electron, you <em>only</em> use Schroedinger's equation - Penrose calls this the "U" procedure. You then get a completely deterministic answer, phrased in terms of a linear combination of "classic" states for the electron. When at the end of the day your boss walks in and asks you where the electron <em>really</em> is, you apply the "R" procedure and get a statistical distribution for the position of the electron. That is, the "R" procedure is not considered to be something which happens at a particular point of time; rather, it is a kind of "post-processing" to interpret the results of QM.
      </p>
      <p>
        Penrose suggests that "R" is actually something which happens in reality. "R" is the part of QM which is irreversible. So if "R" is actually a physical process, then QM would indeed be time-asymmetric.
      </p>
      <p>
        The traditional "Kopenhagen" interpretation of QM, on the other hand, says that QM is just a procedure to compute the behaviour of a given system, and that no physical meaning should be attached to this "R" procedure. I agree with Penrose that this is not very attractive from a philosophical point of view. But that <em>is</em> the traditional view on QM. In this view, there is no time-asymmetry.
      </p>
      <p>
        -- <a href="StephanHouben.html">StephanHouben</a>
      </p>
      <p>
        Isn't it fair to say that only a small minority of real physicists in the last seventy five years have taken a strict "Kopenhagen" view of QM? Traditional it may be, but "not very attractive from a philosophical point of view" to many of us and not very widely held by those most familiar with the subject matter? 
      </p>
      <p>
        -- <a href="RichardDrake.html">RichardDrake</a>
      </p>
      <p>
        <em>Yes, I think this is fair to say. -- </em><a href="StephanHouben.html">StephanHouben</a><em> </em>
      </p>
      <p>
        This sounds somewhat off. Copenhagen insists ultimately that wave functions have to collapse, which means that it's the combination of U and R that describes reality. The main alternative, many-worlds, only uses the U procedure and relies on thermodynamics to separate everything out.
      </p>
      <hr/>
      <p>
        <em>Sure, but this concept of past, present and future can adequately be explained by Thermodynamics - no need to add additional time-asymmetric facets to the theory.</em>
      </p>
      <p>
        Hmm, two points here. The Second Law of Thermodynamics is, according to Penrose and a lot of other physicists, simply the result of the extraordinarily low entropy in the very first milliseconds of the big bang. There's no time-asymmetry in the more fundamental laws of physics and stochastics that give rise to the Second Law, given the very low entropy starting point. Interestingly, although <a href="TheEmperorsNewMind.html">TheEmperorsNewMind</a> has a light-hearted cartoon showing a bearded God choosing an incredibly low entropy point in the total phase space on "booting" the universe, Penrose prefers to ascribe the initial entropy to fundamental physical law in the form of the unproven (and presumably unprovable) <strong>Weyl Curvature Hypothesis</strong>. Penrose never declares whether he considers such physical laws themselves, which he agrees were key to the evolution of self-conscious human life, to be part of a divine design. He certainly started out as a materialist and sceptic, by his own admission. 
      </p>
      <p>
        But point two is that nobody is claiming, are they, that the time-asymmetry we observe with entropy can have anything to do with the detailed working of our minds and consciousness? Whereas Penrose and a few others that he's now persuaded believe that the not-yet-discovered rules of a non-computable theory of <a href="QuantumGravity.html">QuantumGravity</a> will be both time-asymmetric (like current Quantum Theory's "R" state reduction) and key to the working of human brains. -- <a href="RichardDrake.html">RichardDrake</a>
      </p>
      <hr/>
      <dl>
        <dt> </dt>
        <dd>Penrose's argument seems to be: <em>We don't understand consciousness. We don't understand quantum theory either. Perhaps they are the same.</em> It is not a compelling argument.</dd>
      </dl>
      <p>
        It's not compelling and it's not Penrose's argument. Even his most speculative proposals are based on more solid things, including the very strange experimental evidence about consciousness and time, which almost nobody seems to have commented on in reviewing the books. His key argument starts with the assertion that human beings <em>understand</em> <a href="GoedelsIncompletenessTheorem.html">GoedelsIncompletenessTheorem</a>. One of the undoubted ironies here is that most of us don't find old Kurt's stuff quite so easy to follow as Penrose did when he first encountered it in his student days at Cambridge. But even if only a select number of human beings really <em>understand</em> Goedel's theorem then they surely <em>know</em> that Fk(k) is true, which means their minds must work non-computably. According to RP. (I'm not sure what a dualist interactionist - like Goedel himself seems to have been - thinks at this point, whether non-computably or otherwise!)
      </p>
      <p>
        Penrose believes that this argument is very strong logically, especially as he's re-expressed it in <a href="ShadowsOfTheMind.html">ShadowsOfTheMind</a>. But he also accepts that it is likely to be just one example of a much broader issue: that human understanding of anything, even if very much less open to logical scrutiny than Goedel, is going to require non-computable, time-asymmetric physics. From the moment I first opened <a href="TheEmperorsNewMind.html">TheEmperorsNewMind</a>, I've found this a compelling point of view. And quite honestly a terrific relief from what had seemed to be the extraordinary combination of astounding claims, great pride yet complete non-achievement in reductionist artificial intelligence. There is a underlying influence here that I've come to believe at least partly explains why we in software have so often eschewed <a href="ExtremeHumility.html">ExtremeHumility</a> and produced such mediocre results. Since the original speculations and projections of <a href="AlanTuring.html">AlanTuring</a> we've had self-delusion at the heart of our discipline. We need some hard science to get us back on track.
      </p>
      <p>
        Those last four sentences were intended to stir up some debate. Please don't <a href="DisagreeByDeleting.html">DisagreeByDeleting</a> but do use all other means <a href="WardCunningham.html">WardCunningham</a> has made available to you. I of course reserve the right to change my own flawed understanding.
      </p>
      <p>
        -- <a href="RichardDrake.html">RichardDrake</a>
      </p>
      <p>
        <em>The error lies in the fact that</em> <strong>Goedel's Incompleteness Theorem is not a Goedel's Theorem!</strong>
      </p>
      <p>
        <em>I will clarify the last sentence. The fact that you know (or, more exactly, believe) that Fk(k) = true, and the fact that you understand Goedel's Incompleteness Theorem are totally unrelated. Why?</em>
      </p>
      <p>
        <em>Simple. Because Goedel DID prove his theorem in the Whitehead/Russell set of axioms. So, the proof of this theorem could be accomplished by a complex enough Turing machine. VERY different from not being able to prove a theorem, but believing in its reality.</em>
      </p>
      <p>
        <em>Also, if you just believe that Fk(k) = true, you are just limiting yourself. We could create a Turing Machine that:</em>
      </p>
      <ul>
        <li>
          Starts from a axiom set A,
        </li>
        <li>
          Builds a Goedel's theorem Fk(k) in A, which is unprovable,
        </li>
        <li>
          Creates two new axiom sets, C and D, in which Fk(k) = true and Fk(k) = false respectively, and goes back to point one.
        </li>
      </ul>
      <p>
        <em>Do you see that pretty Turing Machine sitting in front of you? Yeah, your computer. It is just a lot of transistors, that are based on quantum effects. It is still a Turing machine. So, even if the microtubules are helping the brain's processes in quantum ways, this doesn't mean that the brain processes are not computable.</em>
      </p>
      <p>
        -- <a href="JuanPabloNunnezRojas.html">JuanPabloNunnezRojas</a>
      </p>
      <p>
        I <em>think</em> I agree entirely, though I can't be sure - which is the whole point. Penrose believes in absolute proof. He beliefs in an infallible creature called a Mathematician. It knows when it has got something correct. And it is correct about that knowledge. It just knows. Mistakes aren't a problem for it. If that's true of Penrose, then I guess if he says something, we can't argue! But I doubt if it really is. There are two explanations for that 'Eureka' feeling you get when think you've got something right: 1. You got it right. Well done! Or 2. You're fooling yourself. Proof was invented to encourage self-doubt and careful checking to eliminate reliance on false assumptions, but your stomach may rumble when you are thinking something through, and your concentration drifts. This can happen at any time. How do you <em>know</em> you really know something is true? How do you prove you've proven it? So the apparent ability of a mathematician to "see" truth doesn't require any magic - just an acceptance that they are often wrong, and we as a race make progress by bumbling through difficulties and occasionally getting lucky. No contradiction with Goedel. No quantum magic required. How was Fermat's last theorem proven? How was the Four Colour conjecture proven? (And how do we <em>know</em> they are proven now, anyway?!) It took a lot of people hundreds of years, many of whom thought they'd done it, several times, only to have a flaw pointed out to them. And someone may find a flaw yet in either of those famous examples - only a few dozen people in the world are really capable of doing so, due to the obscure techniques involved. That doesn't give much scope for effective peer review. (Looking at it from a programming point-of-view, I expect that Penrose is rather like one of those <em>lucky</em> programmers who never has any bugs in his code, no siree! Until someone finds one...) -- <a href="DanielEarwicker.html">DanielEarwicker</a>
      </p>
      <p>
        For discussion of the idea that, as computing is not purely algorithmic, Penrose (and others) may be challenging a strawman, see <a href="AlgorithmsOrInteraction.html">AlgorithmsOrInteraction</a>.
      </p>
      <hr/>
      <p>
        <a href="PenroseCannotConsistentlyAssert.html">PenroseCannotConsistentlyAssert</a> or can he? I've moved the detailed discussion of the Goedel stuff there. It's a very important foundation for Penrose's argument and it deserves discussion. But I'd like to make room if possible for other aspects of Penrose's proposals and their implications both for <a href="HumanBeing.html">HumanBeing</a>s and <a href="ComputerScience.html">ComputerScience</a>. Trouble is, Wiki may be short of real bio-neuro-psycho-quanto-cosmo-philosophy experts compared with the Goedel stuff. Or maybe it's easier to bluff in the Goedel arena ...
      </p>
      <p>
        <em>I don't know which is worse: mathematicians pretending to be philosophers, or philosophers pretending to be mathematicians... undoubtedly the former, because mathematicians are less likely to be lead astray by non-rigorous math (but rigor in philosophy is just tedious, eh?), and then we have physicists pretending to be mathematicians and philosophers...</em>
      </p>
      <p>
        Finally it becomes clear to me why Plato/Socrates argued that each man should have one (and only one) area of expertise. 
      </p>
      <p>
        Yeah, Philosophy is not for the dilettante.
      </p>
      <p>
        <em>Philosophy is only worthwhile if they know as little as possible about everything else?</em>
      </p>
      <hr/>
      <p>
        Some online criticisms of Penrose:
      </p>
      <ul>
        <li>
           <a href="http://orpheus-1.ucsd.edu/philo/EPL/Penrose.html">http://orpheus-1.ucsd.edu/philo/EPL/Penrose.html</a>
        </li>
        <li>
           <a href="http://psyche.cs.monash.edu.au/psyche-index-v2.html">http://psyche.cs.monash.edu.au/psyche-index-v2.html</a>
        </li>
      </ul>
      <hr/>
      <p>
        <a href="TheoVerelst.html">TheoVerelst</a> : Always good to read about fundamental science, or is it?
      </p>
      <p>
        Without reading them back, some remarks about the subjects I found on the page.
      </p>
      <p>
        First, quantum physics isn't a completed building a mathematician models with complete coverage of every physical and other observable phenomenon. Not that, just like Newtonian Physics, it has been disproven for what it claims to be, but it simply isn't a Complete Theory of Everything, nor does it claim to be.
      </p>
      <p>
        Some 'laws' are known well in their context, for instance the Heisenberg equation states something about the simultaneous measurements of position and impulse (velocity), where the law states that it isn't a possibility to measure both with infinite accuracy, with as extremes that full measurement-wise knowledge of either leaves you without a clue about the other, no matter how those measurements are conceptualized as 'ordered'.
      </p>
      <p>
        Quantum physics has a complete and strong basis in observations, and statistical foundations, it speaks about probabilities, and its fundamental integrals speak about combined probability densities, mainly, though one can define important parts in other terminology, the expectation values and variances, and (advanced) statistical mathematics based on observables are the main mathematical vehicles.
      </p>
      <p>
        Functional integrals, especially of squared kind (...) lend themselves well for the important gaussian function/curve which every repeated observation is statistically ('law' of big numbers) inclined to converge to in the presence of (on average) neutral measurement noise. And they (or their differential counterpart) form a big part of most quantum computations.
      </p>
      <p>
        Goedel; labeling is about the possibility to continue naming all things you want to consider, which is not so much the direction of most physics, where most laws state generalized behaviour of matter, so that the law may be complicated, but not so much in need of more indices, and in principle Fock space (infinite number of Hilbert spaces to represent a completely general (convolvable and possibly limited to normalized) mapping from any Hilbert space signal to any Hilbert space range result) is dimensional enough to no put you in goedel games when the number of particles considered is bounded or countable. And possibly beyond.
      </p>
      <p>
        The idea is that all the let's say quarks in the universe are probably never enough to describe everything about all quarks in the universe when we assume they must describe themselves, so that a computer consisting of the whole of the universe can never contain all data about itself, let alone that we can make it predict its own future.
      </p>
      <p>
        That depends on the aggregation possibilities, and on how much exact information we require for our particular computation, and the laws involved therein. We would run into a goedel like problem if we'd need a number of atoms (let's say one for each of 64 bits) for storing the position of each atom in the universe for each dimension. THAT is a certified problematic goedel-like problem.
      </p>
      <p>
        If, however, we'd be interested in the average mass and momentum of the whole universe, we'd only need the sum of all masses, and a point of inertia we don't have, that is definitely not even a bit of a mathematical theory problem, but a major physical and philosophical problem.
      </p>
      <p>
        The 'state' of the mind in quantum mechanical/theoretical sense is hard to define, and therefor hard to reason on, especially when it isn't well-defined or the knowledge of the essential boundaries of quantum theory isn't present.
      </p>
      <p>
        Some remarks remind me of study work I did before '96, when I had been into quantum physics more than a bit (I'm a network theory (academical) electrical engineer), and an interesting book, also in the context of Penrose, where the idea of consciousness is brought forward by an anesthesiologist who describes the at the time newer area of nanotechnology in the book 'Ultimate Computing' by Stuart R. Hameroff (1986), which I happened to have come across during a library literature search for parallel computing.
      </p>
      <p>
        About the importance of the right physical models and decent model-wise thinking, what is the state of the mind when the tide is high, as compared to when the tide is low? Strictly physically speaking, there is an observable difference, which is rarely accounted for.
      </p>
      <p>
        Even stronger: unless gravity is seriously quantized (and there is no reason till this date to even try rigidly assuming that), and when the same holds for EM fields, all models of anything containing matter known to man has essentially to deal with intrinsic holistic features of both quantum and classical models of reality.
      </p>
      <p>
        Making and working with a model of reality is always a matter of common sense, except that experiment results, when not immediately or at all fitting in expectation patterns, may not appeal to a certain human being's common sense. The makers of quantum theory made perfect sense to themselves, but when a newcomer or not as knowledgeable (or sufficiently intelligent) person looks at it, it is possibly counter-natural. It makes perfect theoretical sense, though, as long as you see it for what it is: a in major ways (heavy) statistical theory based theory where (decent and fullout) fourier analysis and dirac theory are assumed known.
      </p>
      <p>
        Reasoning in mathematics, or alternatively mathematical reasoning is another story, but every mathematician should know that maybe certain (hopefully correct) reasoning steps yield results which seem counter-intuitive, but the reasoning steps have to have been understood to have come into existence at all, let alone be applied.
      </p>
      <p>
        To quote the most important philosopher of science of the 20th century: every theory is valid, until it is falsified. The main mathematical assumptions, axioms and proofs go unfalsified for a long human time and an amazingly short geological or cosmic time, unless the dinosaurs or the little green men from somewhere out of space can contribute to the weighing against time of that statement.
      </p>
      <p>
        [To clarify, this is using one particular technical definition of the word "valid". This could confuse readers; people are confused about Goedel's theorem and undecidability etc quite frequently. The above statement is <strong>not</strong> necessarily true given other common definitions of the word "valid".]
      </p>
      <p>
        Theo Verelst Not knowing who I'm responding to, in normal scientific and reasonable academic language, and in all reasonability, my statements are in common language. The above added statement represents an opinion which to me indicates the reader did not understand the basics of the theories discussed to the normal level where they apply, than those theories are valid, and Goedel is about what I described, for most practical use. The rest is gibberish or not to the point for the areas I brought forward, I'm quite sure. And more than qualified. The confusion comes from invalid use and explanations of often indeed counterintuitive, non-deterministic (which is not necessarily non-platonian, that'
        s a philosophically tinted discussion, whereas my paragraphs are about fundamental sciences, which I assure everyone in the proper use are quite, quite valid, AND have limitations) quantum mechanical theories. The expectation value of throwing a dice is maybe hard to accurately define statistically, but a quite valid concept. And it is quite valid theory to assume on average you'll throw 3 1/2 after many throws. Quite valid reasoning and theory and practical application, in normal language. Believe me.
      </p>
      <p>
        ["Gibberish"? How terribly unkind. To clarify, if you do not mean "valid" in a technical sense, if you mean "every theory is valid, until it is falsified" using everyday definitions of the word "valid", then you are wrong.]
      </p>
      <p>
        TV Unless you mean the rather childish or boring play upon words that of course you can think of some theory which is untrue, and don't mention it or refuse to disprove it, and don't blame me for not stating with great accuracy on a wiki, you'd have to talk to one of the top philosophers of this time (he might be still alive). That you don't understand the essence of what he himself called 'logic der forschung' doesn't mean he's wrong. No serious scientist would say so, I'm quite sure. Unless you prove you are that, I think you don't understand the point very well.
      </p>
      <p>
        [Many things have turned out to be technically "independent of the axioms of the system". This is not identical to "valid until falsified" except using a technical definition of "valid". The most general 4 truth values are "provably true", "provably false", "inconsistent" (paradoxical), and "undecidable", which is the same as independent of axioms.]
      </p>
      <p>
        TV Then you talk about a combination of language and formal logic. Provably true is challenged by that philosopher, which is an interesting, and important part of his work. Do your homework first, I suggest. Just the draw the setting, this guy was from the time of Einstein, and not unknown to him. I your language, every (also in normal language) theory is undecidable at best in mathematical language, unless proven false. You never know for sure whether some theory or though is really actually true, but when you given a well defined one using normal derivations can proof it false, you are certain it is false. Major, century old, mainstream, quite accepted and acceptable philosophy of science, the denial of which probably indicates you're either a bad scientist, or indeed don't understand what that is supposed to say.
      </p>
      <p>
        It actually says in a way that you're not a good scientist when you simply state something, and don't challenge what you're saying and call it true. Who agrees with your four truths? The maharadji? [<em>Who?</em>] Your mother? Your friends? A reasonably intelligent bystander? The power of the natural sciences, of which you, and others at times, use the manner of speaking, is in a very clear science of research. Experiments are supposed to be repeatable, and the logic is according to usually understandable mathematically foundable reasoning lines. Sort of like: if I do a clearly defined experiment, under fixed circumstances, it should always give me the same results. That game works until it is proven that at some point your theory fails. Until that point, you can maintain your theory.
      </p>
      <p>
        Many things independent of the axioms of the system. Oh boy. Who are you, a mathematics minor (minor, mind you...) with an idea of a political position in science or something? Your definitions are so away from most things in decent science or human reasoning it's tempting to repeat words I used. I mean I am serious about the subject but such a phrase either doesn't indicate the same in return, or (to me) that you indeed do not understand what this stuff is about.
      </p>
      <p>
        Major philosophers have dealt with 'proof', 'existence', 'reasoning', 'reality', and such concepts for centuries and longer, and you already to begin with state you know it all? How do you know you are not dreaming your whole existence and interactions with the world? A quite reasonable and maintainable philosophic line (but quite practically useless, probably) could see you and I as little brains in some brain tank invisibly linked to our bodies, which just exist in dreamspace. Or something. I mean whatever. The whole point of good science and philosophy, also in normal life, is that you are able to take a little distance from your opinions and theories and try to be correct in general.
      </p>
      <p>
        [The oft-repeated summary of Goedel as saying that many things are true but unprovable is a wrong summary. They are not "true but unprovable", they are simply "unprovable with regard to axioms of system A", and for any given enlarged system B in which such a theorem is provably true, there is an alternate system C enlarged with <strong>different</strong> axioms in which that same theorem is provably false.]
      </p>
      <p>
        [TV] I didn't give that summary. You have to be something of a mathematician to appreciate goedel correctly, he was when I remember correctly (and I don't mean from some popularistic book, which is fine, but no scientific source, necessarily) talking about mathematical proofs, and though along the lines which I indicated.
      </p>
      <p>
        Assuming you're serious and worthy of some of the self-ascribed authority: how do you prove that the day after tomorrow, the gravity constant is still the same, and that we won't all be floating around on the surface of earth like on the moon?
      </p>
      <p>
        Not being obnoxious, that IS a serious physics question. The assumption of the repeatability of experiments, and the practical applicability of the theory of gravity determines when you are right to think gravity will be the same at some point in the future.
      </p>
      <p>
        No one will find it hard to share the assumption that in all human normality and practice, it will. So a normal person would call the theory of gravity true. But strictly speaking you can prove that only by extrapolation from the often repeated and repeatable experiment of walking on earth and how gravity is thus far. Which is not problematic, but it is for your type of thinking in other areas fundamental sciences.
      </p>
      <p>
        The idea of the natural sciences is that they provide models of reality, and rely on correct (formal) mathematical proof mechanisms, and that especially the fundamental ones give us a highly reliable view of what repeatably is true. But we have nothing else but repeated experiments and observations to base our 'truths' on. Really. That's a fundamental point in science.
      </p>
      <p>
        And when you don't want to accept that or don't understand that in the longer run, you're doomed not to get taken all to seriously as a scientist, or take the risk of being written off as someone who merely wants to use (abuse) mathematical formulations to sound more convincing in some argumentative way, without having understood the rules of either decent mathematics or natural science.
      </p>
      <p>
        And when you claim only mathematics, which is rather limited, because OF COURSE mathematical thinking human beings is influenced by their normal observations about reality, and at least by human modes of thinking, than you aren't saying much at all. And at least suggest I make mistakes that in all reasonability in these fields I don't make. And just for the sake of being clear: I have formal and heavyweight university training in philosophy (of science), formal (mathematical) reasoning, that is proof-mechanisms, advanced mathematics, and quantum physics. Which wouldn't be all needed to understand highschool physics basics of the kind that everything is a model. Or the main thoughts of Karl Popper. I'm not just talking, and my points to me and I'm sure every reasonable scientist in the relevant field are clear and nothing out of the ordinary.
      </p>
      <hr/>
      <p>
        <em>The bit about microtubules should be a dead giveaway that something is wrong. Amoebae are composed partly of microtubules, and they don't exhibit the sorts of behaviors most people would count as intelligent.</em>
      </p>
      <p>
        A human is more intelligent than a rat. How the brain works in each is the same though. Intelligence is a layering on the base functionality. It's the base functionality that may use microtubules via quantum means. It is now thought that proteins reach confirmation from a shape space of 500 billion options using quantum tunneling. Google this and you'll find a bunch on it. Something more subtle has to be going on for such complexity at such a scale to happen so fast. 
      </p>
      <p>
        [That shows something interesting about cell growth and metabolism. Cells are remarkably complex and intelligent (in the very loose sense) in their design, and microtubules may have something to do with this. But none of that is any kind of support for Penrose's theory about microtubules and human-level intelligence. Occam's razor says microtubules have more or less the same function in rat brains as in human brains, and that human intelligence derives from higher level architecture.]
      </p>
      <p>
        Rats are very intelligent. They are not as intelligent as humans. So part of it is architecture which may not be related to microtubules, but the architecture part still relies on the underlying capability of the brain which would use microtubules and tunneling. Rather than invoking occam to come to a conclusion, isn't it better to just say you don't know how it works and do the research?
      </p>
      <p>
        [Unfair retort. That does not follow at all. Yes, the higher level architecture depends on the functioning of the lower level architecture, which itself uses microtubules, that is true. Your jump immediately after that is the unfair part. No, it is not better to prefer "we don't know" over "use Occam's razor".]
      </p>
      <p>
        [Penrose makes a fairly outrageous claim, and doubt is shed on his claim by the obvious fact that non-humans, though intelligent, nowhere approach human intelligence, even though they have micro-tubules.]
      </p>
      <p>
        You are making an unsupported judgement about the relative intelligence of humans to other animals and then using that to make an equally unsupported conclusion. When you are trying to say how something works, not just give a general opinion, it usually is better to say I don't know, instead of jumping to a conclusion based on no evidence. The razor doesn't give you any evidence to say how something really works so it isn't a valid principle when talking about descriptive topics.
      </p>
      <p>
        [I'm not following. Surely you don't mean that it is an "unsupported judgement" to say that humans are more intelligent than other animals?]
      </p>
      <p>
        It's unsupported that animals "nowhere approach human intelligence" therefore micro-tubules are not part of an explanation for human level intelligence stemming form the evolution of the cerebral cortex.
      </p>
      <p>
        [In addition to my neuroscience books, I have a whole section on animal and insect intelligence: I am far from being a human intelligence bigot. But I'm a little stumped here. No animal has complex grammar (neither non-trivial symbol ordering nor nested constructions), and in addition to what this means for <strong>linguistic intelligence</strong>, there is also strong evidence that this is either the same as, or at least very similar to, more general cognitive capacities in human. And there is no evidence of similar complex cognition in animals...all of the contenders are either instinctive, completely rote learned behavior, etc; there is no example of nontrivial conditional sequence nor nesting in any behavior, including animal language, that is not instinctive.]
      </p>
      <p>
        [So just what are you trying to claim here? That some animals might be as smart as humans? I sure hope not, because that is unsupported, no matter how amazing it is to find out that, <strong>in their own ways</strong>, some animals (like dolphins and chimpanzees and parrots and eusocial insects) exhibit surprising levels of intelligence compared with what human-intelligence-bigots used to think. That doesn't make it human level intelligence. No such evidence.]
      </p>
      <p>
        <em>I think the question is this: is human intelligence qualitatively different than animal intelligence? That is, is there a fundamental difference between them? Is human intelligence akin to animal intelligence, only more developed? Is there a fundamental limit on animal intelligence that humans have surpassed by some mechanism? The latter position is favoured by some people for non-scientific reasons, but is not supported.</em>
      </p>
      <p>
        [The answers seem clear (albeit not proven beyond unreasonable doubt). Compare the sonar processing cortex of dolphins; it is still beyond human ability to reproduce all its capabilities. Does that make it qualitatively different than other kinds of animal/human cognition? Depends on exactly what you mean, but largely "no, not in any dramatic sense". It does what it does because of the evolutionary demands of its environment, which caused a novel higher level architecture. The low level architecture appears to be identical to that of other mammals.]
      </p>
      <p>
        [The evidence is overwhelming (albeit not proven beyond unreasonable doubt), that the same is true of human cognition.]
      </p>
      <p>
        <em>We would seem to be in agreement then.</em>
      </p>
      <p>
        Sonar isn't a form of cognition at all. It's a form of perception. Really now, how hard is it to keep these two radically different things separate?
      </p>
      <p>
        Human language is a form of cognition. It is in fact the <em>basis</em> for human cognition. And yet, no animal has anything resembling human language. Thus, no animal has anything resembling human cognition.
      </p>
      <p>
        On this point, I think we should give animal cognition more credit. For example, how about gorillas learning human sign language to express their own ideas? Or prairie dogs' calls that can distinguish among different types of people they see? What type of intelligence is needed for a cat to climb a tree? For this, I believe a lot of conscious decision making is involved even if a cat won't tell you about it in the English language. What type of consciousness is involved in elephant paintings, or humpback whale songs?
      </p>
      <hr/>
      <p>
        <a href="RogerPenrose.html">RogerPenrose</a> has released a new book called "the Road to Reality". This is over 1000 pages long and is a no holds barred introduction to mathematical physics for the (extremely) motivated layman. It has little on consciousness, but does discuss his latest views on Mathematical Platonism in a few dozen pages. There are lots of links to reviews & forum discussion threads on this page:
      </p>
      <p>
        <a href="http://www.321books.co.uk/reviews/the-road-to-reality-by-roger-penrose.htm.">http://www.321books.co.uk/reviews/the-road-to-reality-by-roger-penrose.htm.</a>
      </p>
      <p>
        <strong>Argumentum ad Populum</strong>
      </p>
      <ol>
        <li>
           pages to introduce mathematical platonism. Gobsmackingly astonishing when you consider that mathematical platonism hasn't been a serious position since the field of mathematical logic was invented almost a century ago.
        </li>
      </ol>
      <p>
        -- Note I said "a few dozen pages". The rest of the book covers maths/physics that doesn't need the assumptions of Platonism.
      </p>
      <p>
        In fact, excluding religious fanatics like Roger Penrose who are simply incapable of making any coherent argument for their chosen position, mathematical platonism is dead, dead, dead. It was given mortal wounds by Russell, killed by Goedel, and utterly annihilated by whoever it is who invented a system which includes the opposite of the Continuum Hypothesis, which really is nothing but the heir to non-Euclidean geometries.
      </p>
      <p>
        Mathematical platonism has all the credence of creation science. That's probably because it IS creation science. <strong>There is only one true mathematics.</strong> sound familiar to anyone?
      </p>
      <p>
        <em>Aren't these awfully cheap arguments? Mathematical platonism is out of fashion, therefore pooh-pooh on </em><a href="RogerPenrose.html">RogerPenrose</a>? BTW, <a href="KurtGoedel.html">KurtGoedel</a> was a mathematical platonist, not that it matters. See the "snob appeal" section of <a href="http://philosophy.lander.edu/logic/popular.html.''">http://philosophy.lander.edu/logic/popular.html.''</a>
      </p>
      <p>
        So by your reasoning, the fact that creationism has been a forbidden subject among biologists for the past century informs us of nothing at all. Yet in practice, that is the precise reason why creationism is dismissed by all right-thinking people.
      </p>
      <p>
        The fact is that any explanation of why mathematical platonism is crap would be impenetrable and incomprehensible without an introduction to mathematical logic. And I'm not here to give an introductory course on mathematical logic. If you want to remedy the glaring deficiencies in your education then any half-assed university will let you take a course. That's not even counting the countless books on the subject. So demanding that I provide a defense of mathematical formalism or concrete arguments against mathematical platonism, is utterly unreasonable and disingenuous in the extreme.
      </p>
      <p>
        The only thing people need to know is that the top experts in the relevant field (mathematical logic) have all rejected it, and that the situation will never, ever reverse itself. The entire field of mathematical logic is the rejection of mathematical platonism. Much like chemistry is the rejection of vitalism from alchemy, or biology is the rejection of creationism from natural history. So mathematical formalism is about as likely to go away, or let up enough for mathematical platonism to make a comeback, as evolution is to do so. And just like evolution is the basis of all biology, mathematical formalism (the antithesis of mathematical platonism) is the basis of all mathematical logic. The analogy is exact.
      </p>
      <p>
        Except for one thing. Mathematics was more than ten times more ancient than natural history when the latter got turned upside down. And having such a long tradition, mathematicians are a very traditionalist lot. Which means that mathematical platonism remains reputable even many decades after it's been formally disproved, rejected and supplanted. This contrasts sharply with the kangaroo courts that were held against creationists after evolution became accepted. And it's why ignoramuses like you can get away with the crap you do. Crap like implying that I have the burden of proof just because you're an undereducated fool! -- RK
      </p>
      <p>
        Except that the only argument that you present for the supposed demise of mathematical "platonism" and the victory of "formalism" (whatever brand of the two you are referring to), is "because <a href="RichardKulisz.html">RichardKulisz</a> says so". Oh, well, maybe this has some value in some places, who knows?
      </p>
      <p>
        <em>No, you nitwit. Because </em>'mathematical logic<em>' says so.</em>
      </p>
      <p>
        No, really. When and where has this <strong>mathematical logic</strong> been heard to say such a thing? 
      </p>
      <p>
        <em>And if you want to know why it says so, then I suggest you study the damn subject!</em>
      </p>
      <ul>
        <li>
           As someone who has a PhD in mathematics, and am a bit of a Platonist myself, I am a little perplexed by this argument between a formalist and a Platonist.  I have never seen a "proof" that Platonism is false--indeed, in my study of mathematics, I can only be struck by how we can do something as simple as formulate a handful of rules of logic, throw in a handful of axioms to describe the natural numbers, and then go on and construct <em>everything</em> from there...only to decide that the entire foundation is flawed, and decide to accept a <em>different</em> set of axioms to describe the natural numbers, and then <em>still</em> construct everything from there.  And yet there are people who somehow think that the natural numbers (and ideas in general, for that matter) don't exist independently from our minds--and that they then have the arrogance to say "I can prove it, too!"
        </li>
      </ul>
      <p>
        I suggest you quit handwaving when you've been on record with your disregard for the technicalities related to mathematics. You attack only to cover your lack of solid background on the subject.
      </p>
      <p>
        ['Scuse the intrusion, but both of you, please note that mathematical logic has been in a search for better foundations ever since it was invented; we have a provisional system that is used meanwhile, but it is not some kind of ultimate, and research in this topic remains white hot. <a href="JohnMcCarthy.html">JohnMcCarthy</a> for instance has been working on that for some decades, although I personally don't care aesthetically for his approach. -- DM]
      </p>
      <ul>
        <li>
           Your comment is both irrelevant and crappy, Doug. You shouldn't presume other participants know less than you do. Especially, you're not entitled to presume that they don't know trivia. This is not about the technical stuff, this is about <a href="RichardKulisz.html">RichardKulisz</a> appointing himself as supreme judge when commenting about sciences he doesn't really know, based on his peculiar philosophical inclinations, and being idiotically offensive in order to enshrine his point of view on wiki. -- Costin
          <ul>
            <li>
               For me to make a technical comment in the midst of a flame war is irrelevant? Disagree. I was presuming no one else knew what I said? Disagree. This is not about the technical stuff? Well, that's between you and him, but this being by presumption a technical wiki, I will continue to feel free to make technical comments as I see fit, and you'll just have to put up with me doing so, even if it gets in the way of your current flame. Don't see why it would, actually, but whatever.
            </li>
            <li>
               <em>Whatever you feel like it, Doug. But when you say "both you, please note this trivia that I'm contributing", the tone is gratuitously condescending to say the least (and don't confuse technical contributions with adding trivia stuff), the same goes about your comments about the working mathematicians (even highly knowledgeable ones) not knowing stuff. Maybe even highly knowledgeable mathematicians know at least as much as you do about the subject.</em> 
            </li>
            <li>
               You are apparently reacting on the basis of the judgement of it being "trivia". I did not call it trivia, and I don't consider it trivia. In fact, I strongly object to it being called trivia. It's a subject of very deep and long interest for me, and I happen to think it's an extremely important topic - <strong>AND</strong> although you clearly disagree, I actually thought it was apropos (technically) at that point in the conversation, as well.
            </li>
          </ul>
        </li>
      </ul>
      <ul>
        <li>
           If it's stuff that's of very deep and long interest to you, then you can actually contribute something about it. Your contributions above are not only trivia but also <strong>uninformative</strong>:
        </li>
        <li>
           ["please note that mathematical logic has been in a search for better foundations ever since it was invented"] - that's a trivia with very little useful content. Anybody who doesn't know that either didn't take history of mathematics 101 or is otherwise culturally impaired. However, this piece of trivia contributes <strong>nothing</strong> to the discussion which was about the allegedly doomed mathematical platonism of "The road to reality". The "please note" is just bad style.
        </li>
        <li>
           ["we have a provisional system that is used meanwhile"] Uninformative and useless. What "provisional system"? Does it have a name, is it important, does it relate to the current topic? Don't think so. It's more like your private 1000 feet assessment of the state of a whole branch of mathematics, and even if it was accurate you had to justify it with some kind of argumentation or a reference to some authoritative source on the subject, and connect it in some relevant way to the discussion.
        </li>
        <li>
           ["<a href="JohnMcCarthy.html">JohnMcCarthy</a>, for instance, has been working on that for some decades, although I personally don't care aesthetically for his approach"] Again, totally uninformative and quite possibly irrelevant. He has been working on what? On artificial intelligence? Did he contribute something specifically to the foundations of mathematics? There is no prima facie argument, not even for folks who happened to study the subject a bit, to connect your allusions to an unspecified part of <a href="JohnMcCarthy.html">JohnMcCarthy</a>'s work with the foundations of mathematics. FYI, <a href="JohnMcCarthy.html">JohnMcCarthy</a> is not quite the most cited author in books or papers that deal with the foundations of mathematics. As for "you don't care too much aesthetically for his approach" this is just good enough to leave the wiki reader completely puzzled. To begin with, you haven't established any context to allow the reader to judge your statement, and how can this statement be relevant? Yeah, it feels good to throw an aesthetical judgement in to the mix, but who cares about your aesthetical judgements and why <strong>should</strong> anyone care?
        </li>
        <li>
           All in all, your interjection into discussion is a good example of how <strong>not to</strong> contribute to wiki. Not that RK's contribution was any better, but because you know more much more is expected from you (at least from my part). While it seems quite easy for you to be sloppy, uninformative and gratuituously condescending.
        </li>
      </ul>
      <ul>
        <li>
           <em>AH! A light dawns! You don't have the slightest clue what I was referring to, including what sort of math research </em>McCarthy has been doing for 30 years, and so rather than ASK me, you just try to rip me to shreds for not saying more in the first place (which is all your criticisms really boil down to). Look, you know lots of math, you don't have to get prickly every time it turns out you don't know *everything* about all areas of math.<em></em>
        </li>
        <li>
           McCarhy has done tons of research; why I should be aware of anything particular that connects to the foundational problem that was the topic of the discussion is beyond my comprehension - he's definitely not known for his contribution to the foundations of mathematics. The problem is that you made a reference in handwaving style, and now you want to blame it for not knowing everything? It's <a href="ShiftingTheBurdenOfProof.html">ShiftingTheBurdenOfProof</a>, Doug. I have a 600 pages book Practical Foundations Of Mathematics, and not a single reference to <a href="JohnMcCarthy.html">JohnMcCarthy</a> (and it does have quite a few pages of bibliography). Not only did you say not enoug, you actually handwaved, and you did it in a <strong>gratuituously condescending tone</strong>. Like I said, it can be made into a example of <strong>how not to</strong>.
        </li>
        <li>
           <em>Simple: </em>McCarthy has had only one <strong>primary</strong> research area for 30 years: non-monotonic logic. Everything else, even AI, is more like a side-interest. There may well not be any reference to non-monotonic logic in your book; I wouldn't consider it a "practical" area of the foundations of math. It's aiming in the direction of becoming one, was my point. My tone was not condescending, by the way, that's pure projection on your part. You're consistently condescending.<em></em>
        </li>
        <li>
           Now for that you may need to present a case, given that it is not common knowledge that <a href="JohnMcCarthy.html">JohnMcCarthy</a> explored non-monotonic logic in conjunction with foundational problems of mathematics while it is common knowledge (including his own representation in his own writing) that his research of logics was related to AI in both practical aspects and philosophical foundations (one just needs to pay a visit on his page). So again, if you have an argument to make,by all means, <strong>do make it</strong>. But abstain from throwing more assertions at a problem just to satisfy your own vanity. As for the "condescension" issue, if you are too much on the defensive/counter-attacking mode to discuss it any more. So in order to salvage anything from this crappy conversation we're having here, please, point out where and how McCarthy's research connects to the foundations of mathematics.
        </li>
        <li>
           <em>Common knowledge? I will address the technical question, but first I must explain my frustration: you have slapped me really hard for: (1) saying what everyone knows (2) for not explaining *immediately*, without waiting for questions, anything that not everyone knows, (3) for assuming I know what everyone knows, (4), for being condescending about assuming things about #3, etc, etc, etc, all of which just makes me feel like there is no win with you. If you know what I say, you're unhappy with me, if you don't know what I'm talking about, you're unhappy... where is the happy medium of communication????</em>
        </li>
        <li>
           <em>Anyway: I have every reason to think that </em>McCarthy's work is <strong>NOT</strong> well-known to non-specialists. I also, please note, am not claiming that McCarthy's research area is going to be some kind of ultimate new work in the foundations of math. I <strong>am</strong> claiming that <strong></strong>McCarthy<strong>' hopes it will be, and here is why: </strong>McCarthy obviously has a very long-term interest in AI (and I have read perhaps 70% of his writings, and have talked to him face to face, and have had <strong>extensive</strong> discussions with some of his former grad students), and <strong>he</strong> hopes, basically, that non-monotonic logic will eventually be the new foundation of mathematical logic that solves the <a href="FrameProblem.html">FrameProblem</a> (which subject I have tried to keep clean and neat on wiki in the face of much entropy). If you are still unhappy with that explanation, say so, and I will go do the time-consuming work of dragging up specific research paper references.<em></em>
        </li>
        <li>
           <em>But you know what, all you had to do in the first place was </em>'ask<em>' WTF I was talking about...it is extremely counter-productive to instead criticize the hell out of me for not saying more in the first place. Just ask, damnit all to hell!</em>
        </li>
      </ul>
      <ul>
        <li>
           <em>Also note the irony of criticizing a hundred words of mine for having too little explanation, while using ten thousand words of your own. Which is worse? The 10K of substance-free words, obviously.</em>
        </li>
        <li>
           Obviously I had to go into details to explain it to you, because your infatuation with your own writings and excessive care with your public image stands in the way of your contributing to wiki. I obviously would have preferred not to go into details but for you to take notice and fix your own messes. This is not about you showing off to me or to RK (big deal, nobody's gonna give you a medal for that), but about <strong>putting an honest effort</strong> to build up a page that's gonna be able to <strong>say something to the reader</strong>. If you want to learn from your mistakes you can do that, otherwise you can be just as cocky as you are now, and reproach me that I went to great length to explain to you what it was your responsibility to know. 
        </li>
        <li>
           <em>Talk about the pot calling the kettle black! Your critique applies at least as much to your own writing as to mine.</em>
        </li>
      </ul>
      <ul>
        <li>
           As for mathematicians, your sentence is not entirely clear, but yes, obviously many mathematicians know vastly more about some or all areas of math than I do... so? That doesn't seem to contradict anything I said. Are you objecting to my implicit claim that I may know more about that particular specialty area than some mathematicians? I hope not, since it only takes one example, and I do know particular examples (friends of mine who are mathematicians yet know less about that particular specialty area).
        </li>
      </ul>
      <ul>
        <li>
           Incidentally, the issue about the foundations of mathematical logic is widely considered by working mathematicians to be irrelevant to their work, and as a result, it's actually the case that many working mathematicians are sufficiently unaware of the details of that area such that they would <strong>disagree</strong> with what I said (I can dig up multiple authoritative sources on that, if you doubt it). Therefore you have it backwards: I cannot just assume that anyone, even highly knowledgeable mathematicians, would "know" (i.e. and agree with) that comment.
        </li>
      </ul>
      <p>
        <em>The singularity of mathematics (platonism) was disproved the </em>'instant<em>' that alternatives were proved viable. It only drove the last nail in the coffin when whoever proved a general procedure for coming up with these alternatives starting from Quine's conception of mathematics.</em>
      </p>
      <p>
        Yeah, whatever. Like this "singularity of mathematics" had something to do with anything. If you speak about a domain you hardly know, it would pay if you used its concepts and terminology rather then invent your own mumbo jumbo to put up an appearance of knowledge. 
      </p>
      <p>
        <deleteWhenCooked>
      </p>
      <dl>
        <dt> </dt>
        <dd>"Singularity of mathematics" = "There being one true mathematics" vs "the mathematical concept of singularity meaning point at which there is no derivative". In other words, it was a sentence which means exactly what a dictionary would suggest it means; any resemblance to a technical term is purely coincidental.</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd><em>So where have these "platonists" you think you demolish proclaimed the said "singularity of mathematics"? And exactly what it consists of, in mathematical terms, please? Moreover, where in the book you're talking about does </em><a href="RogerPenrose.html">RogerPenrose</a> proclaim or allude to the said "singularity of mathematics"? It's just a <a href="StrawMan.html">StrawMan</a> of your own invention for you to knock down a very decent book (to say the least) written by some <strong>real scientist</strong> to whom you just happen to have a personal and irrational aversion.<em></em></dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>Please don't confuse the explanation of a third party who assumes good faith as the original author.</dd>
      </dl>
      <p>
        </deleteWhenCooked>
      </p>
      <dl>
        <dt> </dt>
        <dd>Singularity or Uniqueness? That's what Platonism <strong>is</strong>. Mathematical platonism is the belief that mathematics is real, and that it is singular. The modern formalism is the realization that mathematics is <strong>not</strong> singular, that it is plural. And in fact, mathematics as a whole is completely different from how most people conceive of it. As to the reality of mathematics, that's a completely different question and it's possible to think that mathematics is unreal without being a complete uneducated fool.</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd><em>Actually, most common definition for platonist is that they accept the independent existence of abstract mathematical objects (like, for example, the limit of Cauchy sequences of rational numbers, otherwise known as real numbers). This has very little to do with there being only one mathematics. </em></dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>Well, I won the definition war over <a href="DefinitionOfLife.html">DefinitionOfLife</a>, what do you think's the chance that I'll win the one over platonism?</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>Defining platonism by its second attribute (realism of mathematics) is <strong>extremely</strong> misleading since there is nothing in formalism (math is just a system of inherently meaningless symbols) which contradicts realism. The crucial characteristic is not realism, but singularity vs plurality.</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>And platonists <strong>do</strong> in fact think that mathematics is singular. They may think that mathematics has independent existence out there, but so do I. The difference is that they think mathematics has a <em>singular</em> existence. They think that whatever type of existence mathematics has, this existence is singular.</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>When platonists say that a goedel sentence cannot be both true or false depending on the system, they mean that <em>only one</em> of the possible systems can <em>exist</em>. The precise words they use is that only one is "really true". And it's not the "true" in that phrase that's the keyword since you can't define truth using truth.</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>In contrast, I would say that both systems exist, each in their own mathematical reality. And being a hardcore realist, I would say that both of these mathematical realities are as meaningful as physical reality. And I believe this because physical reality has no meaningful definition other than "the mathematical reality in which WE exist" and I'm not prepared to take physical reality as a given, nor to accept that there is no explanation why mathematics models (is a huge chunk of) physical reality so well.</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>Here's this handy-dandy little table to keep everything straight:</dd>
      </dl>
      <ul>
        <li>
           Realism
          <ul>
            <li>
               Singular --- Classical Platonism
            </li>
            <li>
               Plural   --- Smart Formalism
            </li>
          </ul>
        </li>
        <li>
           Irrealism
          <ul>
            <li>
               Singular --- Modern Platonism
            </li>
            <li>
               Plural   --- Dumb Formalism
            </li>
          </ul>
        </li>
      </ul>
      <dl>
        <dt> </dt>
        <dd>The fact that lots of people think realism matters to platonism vs formalism just goes to prove they don't have a solid conception of existence.</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>And finally, it's not redefining a word to provide a better definition for the CONCEPT that it's attached to. It's only abuse of language when you try to attach an entirely different concept to a word. I'm doing the former, CCC is trying to defend the latter.</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>This is all I'm writing on the subject since I have much, much better things to do with my time than to get into a stupid war with my nemesis <a href="CostinCozianu.html">CostinCozianu</a>. Gargling my mouth out with hydrochloric acid comes to mind. -- RK</dd>
      </dl>
      <p>
        Can you provide a reputable source that defines mathematical platonism as you claim it to be defined? 
      </p>
      <p>
        <em>I don't need to provide sources for my definition any more than I ever needed to provide any for my definition of life. The fact is, this is the way the words are used. These are the </em>'concepts<em>' they are attached to. And just because everyone else fucks up the definitions of these concepts doesn't make it any less obvious that my definition is right (fits actual usage in the literature) and the "common" definition is dead wrong (destroys any understanding of the literature). And if YOU think my definition is wrong then it's up to YOU to explain why there's a completely separate word for the positions of mathematical existence vs non-existence (realism vs irrealism).</em>
      </p>
      <p>
        This is not "the way words are used", see for example <a href="http://www.amazon.com/exec/obidos/ASIN/0195143981,">http://www.amazon.com/exec/obidos/ASIN/0195143981,</a> <a href="http://www.sm.luth.se/~torkel/eget/thesis/chapter1.html">http://www.sm.luth.se/~torkel/eget/thesis/chapter1.html</a> . Sure you can claim your definition is "right", but then the reader need be aware that you're operating with your definition. Under your definition I can hardly see a justification to attach your version of platonism to <a href="RogerPenrose.html">RogerPenrose</a>, in particular with regards to TheRoadToReality.
      </p>
      <p>
        So you claim that modern platonists adhere to "singularity" and "irrealism". Where can we verify this assertion, i.e. any particular mathematician claiming himself "modern platonist" exposed (in what paper/book) the "singular + irrealist" view. In contrast, one has few problems to find contemporary mathematicians who call themselves platonist, adhere to realism (actually that's their working definition of platonism ) and don't proclaim any kind of "singularity of mathematics" thesis. 
      </p>
      <p>
        <em>Well, that's a first one for you Costin. Providing evidence and argument instead of insult and condemnation. But I think that an entire book with Realism in the title trumps a single article with platonism buried within it. An article which supports my definition since Platonistic == Modern Platonism.</em>
      </p>
      <p>
        <em>The problem comes entirely because modern people don't understand exactly how fucked up classical thinking was. It's so far outside their frame of reference that they literally can't conceive of it so they try to force-fit it to their modern conception of the world and end up confusing everything. So a little history lesson is in order.</em>
      </p>
      <p>
        <em>Classical platonism was of the form "the four elements do not correspond to but ARE the first four regular solids such that physical reality's atoms are the tiny little geometric shapes of mathematics" (singular + realist). Modern platonism has rejected the realism of classical platonism but kept the "we don't KNOW whether a goedel sentence is true or false but we know that only one CAN be true or false in the one true mathematics".</em>
      </p>
      <p>
        You meant to say a book recently published by Oxford University Press on the very subject (platonism and anti-platonism)? I don't care, call it "realism" if it suits you and call "platonism" whatever you want to call "platonism". If you provide your definition, I can kind of make sense of what you're trying to say.
      </p>
      <p>
        But then it's not OK, if you want to discredit what you call platonism, and then use the label to discredit other folks who call themselves platonist but do not operate with your peculiar definition for platonism.
      </p>
      <p>
        Here's one more quote for you: "Views of mathematical objects as independently existing abstract entities are generally called a form of platonism." Solomon Feferman ISBN:0195080300
      </p>
      <p>
        Yet another quote, for the laymen (from <a href="http://research.microsoft.com/~gurevich/Opera/123.pdf):">http://research.microsoft.com/~gurevich/Opera/123.pdf):</a> 
      </p>
      <code>
        "Working in mathematics, one develops a strong feeling of dealing with objective<br/>
        reality. As in archaeology, one digs and discovers things and does not create them<br/>
        in any way. One feels, as you do, that mathematical objects really exist and have<br/>
        existed before anyone discovers them. That is mathematical Platonism."<br/>
      </code>
      <p>
        <em>First, your own reference supports me.</em> Is this handwaving or wishful thinking?
      </p>
      <dl>
        <dt> </dt>
        <dd>And then he elaborates and proves that he left all the important bits out of his own definition. To wit:</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>In the philosophy of mathematics, classical mathematics is often associated with mathematical realism or Platonism, according to which the numbers, functions, and so on, of mathematics belong to <strong>a</strong> mathematical reality existing independently of human thought. A closely related view, also called Platonistic, is that mathematical truth is independent of our mathematical knowledge, so that e.g. Poincare's conjecture has a determinate truth value, whether or not the conjecture is ever settled. </dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>The key word in the entire first sentence is <strong>a</strong>, meaning <strong>one</strong>, <strong>only one</strong>, <strong>unique</strong> and <strong>singular</strong>. The second sentence which describes "a closely related view" proves that the "a" was the key word in the entire first sentence. And if you actually understood and appreciated what realism meant in the classical sense, you'd know that Platonistic thinking is far, far from that level of realism.</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>People often associate realism with uniqueness due to the simple fact that physical reality is unique <em>to their experience</em>. But they are wrong. Any modern physicist would be able to tell them that they are wrong, flat wrong, dead and utterly completely wrong.</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd><em>The above does not imply the singularity of mathematics. For example, a Platonist can hold the objective existence of both euclidean and non-euclidean spaces, so here you have it. The point remains though that platonism is equated with mathematical realism, in all the references I provided.</em></dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>Considering that you still don't understand what realism means and that you still equate it with uniqueness, I'm not surprised you come up with these warped conclusions. No modern platonist (platonistic, whatever you want to call it) believes that mathematics has <strong>physical</strong> existence like physical reality. No modern platonist believes in a World Of Math as physically real as the physical universe. And if some platonists believe in both euclidean and non-euclidean spaces, this isn't because they accept muturally contradictory systems, but for the simple reason that geometry simply isn't important in mathematics any more and that <em>neither</em> euclidean <em>nor</em> non-euclidean geometries are considered central to any mathematical systems. And then there's the fact that there are plenty of systems floating around (general relativity being one) where you can derive <em>either</em> euclidean <em>or</em> non-euclidean spaces as limiting cases. So mathematicians haven't learned to accept contradictory systems at all, they've just learned to separate them to make them non-contradictory. There is a world of difference between accepting both euclidean and non-euclidean spaces as limiting cases and accepting both the truth and the falsity of a Goedel sentence. And anyone who does the latter simply <strong>isn't</strong> a platonist, no matter what they claim themselves to be, and they haven't the faintest clue what the word has meant throughout history. -- RK</dd>
      </dl>
      <dl>
        <dt> </dt>
        <dd>Useless descriptive comments from a non-mathematician about how he thinks actual mathematicians really work and their internal motivation. Your comment that mathematicians who claim to be platonist don't know what they're talking about is just as irrelevant, because you don't have a standing to accuse any real mathematician of ignorance. By the way, in case you haven't figured out, mathematical platonism is just a label loosely connected to platonism in philosophy, and it stands simply for what the overwhelming majority decides it stands for, not for whatever you want it to be. -- Costin </dd>
      </dl>
      <p>
        <em>Second, both classical and modern platonism are condemnable. Both are wrong and far, far more wrong than irrealism.</em>
      </p>
      <p>
        <em>Third, you really shouldn't feel bad about this because this isn't your field of expertise. This </em>'isn't<em>' mathematics we're discussing. It's metaphysics and philosophy of mathematics.</em>
      </p>
      <p>
        Indeed, we don't discuss mathematics, we're discussing your trolling. You haven't provided a single reference to support your handwaving. 
      </p>
      <p>
        <em>Why would I need to when you're doing the work for me? You've yet to produce any references for your own position that platonism == realism. And you'll have to actually counter your own reference which says that platonism == singularity. And even if I lost on references, you'd still have to justify using your confusing terminology when mine makes so much more sense. You'll note that using my terminology, we can intelligently discuss every stance from classical mathematical platonism to modern mathematical irrealistic formalism. If you choose to redefine platonism as realism, then what terms will you use to refer to singularity vs plurality?</em>
      </p>
      <p>
        That's the point, Richard. I don't give a damn (and neither does anyone else) about discussing <strong>your</strong> terminology, and I'd be wasting my time for nothing to convince you to accept commonly used terms for what they are.
      </p>
      <p>
        <em>Accept them how they're used in the literature? Or accept them how idiots like you CLAIM they are used?</em>
      </p>
      <p>
        Yes, accept how they're used in literature which is the same as I claim they are used and I provided enough references, and I could provide even more, if it wasn't a useless exercise because you're just an irrelevant troll trying to spin it any way it fits your ridiculous prejudices.
      </p>
      <p>
        Now the bottom line is this: did you get that classification of yours from somewhere or did you make it yourself? That's a simple question, demanding a simple answer.
      </p>
      <p>
        <em>As already stated, I got it from the fact that mathematical realism is treated as a completely different position from mathematical platonism, despite your claim that they are identical. But then, listening to people is not your forte.</em>
      </p>
      <p>
        Your intepretation of "fact" is always to suit your purpose, but then I don't have time to waste arguing subjective matters with you. I asked you if you take that classification from any kind of relevant reference (like a book/article on history of mathematics, an encyclopedia , or a book on philosophy of mathematics). 
      </p>
      <p>
        Back to <a href="DisagreeByDeleting.html">DisagreeByDeleting</a>, Richard?
      </p>
      <hr/>
      <p>
        At risk of stirring stagnant waters, Penrose makes many mistakes. One obvious problem is that he only considers Turing Machines, which are internally deterministic. Remove this constraint (by opening the system) and his arguments fall away as straw men. Open systems are not constrained to stasis, and thus need not be limited by Goedel's theorems etc. I suppose this is equivalent to the diagonalization implied in Goedel sentences, and their response, though I think it is probably a lot more messy than that since the influence of external factors is likely to be somewhat random.
      </p>
      <p>
        Indeed it needs to be, since a system cannot know which direction to go to lift itself out of Goedel's trap. Nevertheless, it can recognize when it has been lifted out, giving us a simple algorithm which broadly reflects the way that neuronal nets interact with their environment.
      </p>
      <p>
        I don't need quanta to give me a random input. Just heat and stir. Sorry Roger. Like your tiles though. -- <a href="RichardHenderson.html">RichardHenderson</a> 
      </p>
    </div>
  </body>
</html>