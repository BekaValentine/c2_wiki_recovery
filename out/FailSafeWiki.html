<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Fail Safe Wiki
      </h1>
      <p>
        A wiki that is supposed to be <a href="FailSafe.html">FailSafe</a>. Along the ideas of <a href="FolkMemory.html">FolkMemory</a>.
      </p>
      <p>
        Requirements:
      </p>
      <ul>
        <li>
           Share the burden of hosting the wiki (CPU, power, bandwidth, storage) within a network of volunteers with no single point of failure.
        </li>
        <li>
           Blend in with the existing infrastructure.
        </li>
      </ul>
      <p>
        resulting in a permanent wiki grid.
      </p>
      <hr/>
      <p>
        Quick hack ideas.
      </p>
      <ul>
        <li>
           Some sort of round robin DNS, or the user will just type in cXXX.com where XXX is a number; if c2.com does not respond, he'll try c3.com. Even if the user first hits c3.com he'll be redirected to a random wiki server so that all servers get a fair share, or the distribution can be weighted relative to the capacity available on all servers. 
        </li>
      </ul>
      <ul>
        <li>
           For every wiki page, there will be a hash computed of the page name that will determine what the primary server for that page will be. If the site is known to be down (either in the client, or in the server to which the client is connected) the browser is sent to another wiki server that has a backup for the copy. If <a href="FailSafeWiki.html">FailSafeWiki</a> is to be widely popular, there won't a server to host backups for all copies. A copy will reside on 3-4 computers and one of them will be designated as primary. (One of the backup computers will temporarily take over as primary if the primary goes down - or at least is not available from one part of the world.)
        </li>
      </ul>
      <ul>
        <li>
           Edits will be saved at the primary server for that page. The primary server will send asynchronous updates to the backup servers. Users will be recognized by certificates.
        </li>
      </ul>
      <ul>
        <li>
           Some part of the metadata, such as usernames, will be replicated globally.
        </li>
      </ul>
      <hr/>
      <p>
        In the unlikely event that there are conflicting edits to 2 of the servers hosting a page (some part of the world perceived that some other [part was offline), the conflict is detected by the sync algorithm and a branch is created automatically; the merge will be done by human intervention if necessary. The basic wiki functionality will need to support versioning and branching.
      </p>
      <p>
        That is just a sketch to be expanded. Brainstorming welcome. -- <a href="CostinCozianu.html">CostinCozianu</a>
      </p>
      <hr/>
      <p>
        OceanStore is a distributed, persistent storage system which has most/all the features you want. There appears to be a prototype version available (PondStore). <a href="http://oceanstore.cs.berkeley.edu/info/overview.html">http://oceanstore.cs.berkeley.edu/info/overview.html</a>
      </p>
    </div>
  </body>
</html>