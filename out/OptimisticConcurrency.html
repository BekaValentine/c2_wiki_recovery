<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Optimistic Concurrency
      </h1>
      <p>
        Is this not the same thing as <a href="OptimisticLocking.html">OptimisticLocking</a>?  -- <a href="SteveJorgensen.html">SteveJorgensen</a>
      </p>
      <p>
        <em>I believe it is the same thing. Admittedly </em><a href="OptimisticLocking.html">OptimisticLocking</a> doesn't actually hold any <strong>Locks</strong> on resources, and so <a href="OptimisticConcurrency.html">OptimisticConcurrency</a> seems a better name for the concept.<em></em>
      </p>
      <p>
        I suspect that it might be something along the lines of pipelining. -- <a href="MartinRudat.html">MartinRudat</a>
      </p>
      <p>
        <strong>Re</strong> "pipelining": Not really.  It's more to do with controlling access to shared resources by blindly updating them <em>without locking</em>, with the observation that most attempts to lock succeed anyway.  However, the updates are atomic (typically a single pointer in RAM to a more sophisticated structure).  The structure in question is best expressed as a tree, since only the root pointer need be updated.  Hence, multiple threads may compute a new tree, but only the very last one to update the root wins (not that last one wins is any different in lock based protocols).  Threads need to check that their setting remains in effect (or use a reservation protocol, as on the PowerPC instruction set); if their setting doesn't hold, it is incumbent on them to re-compute their tree <em>again</em>, and repeat the process for as long as necessary, timeouts notwithstanding.
      </p>
      <p>
        <a href="SoftwareTransactionalMemory.html">SoftwareTransactionalMemory</a> is an approach to implementing <a href="OptimisticConcurrency.html">OptimisticConcurrency</a> that has many nice properties and is becoming fairly popular (having an implementation in Clojure). It helps automate support for atomic transactions that read and write many places in memory. To make <a href="SoftwareTransactionalMemory.html">SoftwareTransactionalMemory</a> efficient usually involves eschewing 'small' mutable cells in favor of large immutable values with shared structure. <a href="SoftwareTransactionalMemory.html">SoftwareTransactionalMemory</a> can be implemented with just CompareAndSwap or TestAndSet. However, there are also more primitive forms of <a href="OptimisticConcurrency.html">OptimisticConcurrency</a>, such as those designed for operating on queues and other structures using DoubleCompareAndSwap. These forms don't allow the degree of ad-hoc atomic operations provided by STM, but they do provide very efficient operations over some common data structures (notably queues, which are critical for message passing). You can find examples of this application of <a href="OptimisticConcurrency.html">OptimisticConcurrency</a> in <a href="SynthesisOs.html">SynthesisOs</a>.
      </p>
      <hr/>
      <p>
        See: <a href="OptimisticLocking.html">OptimisticLocking</a>, <a href="SoftwareTransactionalMemory.html">SoftwareTransactionalMemory</a>
      </p>
    </div>
  </body>
</html>