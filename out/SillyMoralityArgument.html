<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Silly Morality Argument
      </h1>
      <p>
        [moved from <a href="AxiomaticMorality.html">AxiomaticMorality</a>]
      </p>
      <hr/>
      <p>
        Proposition:  (contributed by <a href="GarryHamilton.html">GarryHamilton</a>)
      </p>
      <p>
        Individuals do not survive in a vacuum.  Life interacts in order to survive at all levels.  This framework of interaction can be called a system.  Absence of interaction reduces survival.  Valid interaction promotes survival of the greater system as a whole, thus interaction that promotes individual survival at the expense of the system is undesirable in the context of the system.
      </p>
      <p>
        Morality only has meaning within a system.  Morality is a measure of tendency toward survival of actions as framed in the context of the system.  The interaction of individuals within a system, in order to promote the continued and improved survival of the system, must comply with the most basic princical:  the greatest good for the greatest scope of members of the system.
      </p>
      <p>
        This, then, provides a foundation for moral terms such as "right" (more survival) and "wrong" (less survival).  "Right" would mean "causing more benefit than destruction" in the greatest relevant scope, while "wrong" would be the reverse.
      </p>
      <p>
        There are systems within systems.  An individual is (in a very limited sense) a system.  A family is a system.  "Mankind" is a system.  "All living things" is a system.  "All things required to support life" is a system.  There may be a superset of these systems that exists as non-corporeal intellect, but this is beyond the scope of this proposition.
      </p>
      <p>
        Morality has validity to the degree that it establishes those principles of conduct that promote the survival of system or systems at the greatest possible scope.  Morality establishes survival vectors.
      </p>
      <p>
        Morality is not an absolute and cannot be an absolute within any context less than the most complete system possible.
      </p>
      <p>
        Conclusion:  morality is that set of principles of conduct which establishes the best chance of survival within the greatest known system framework.
      </p>
      <hr/>
      <p>
        <em>the greatest good for the greatest scope of members of the system</em>
      </p>
      <p>
        Huh, nope. This is an <em>assumption</em> you make, one which upon reflection turns out to be either dubious or vacuous.
      </p>
      <p>
        And the same thing holds for your obsession with survival. It's extremely dubious. I can think of several dozen situations off the top of my head where death is preferable over continued survival.
      </p>
      <p>
        What you're trying to do is reduce people's utility to "good" or survival and then claim that you can aggregate these pathological utility functions, thus rescuing utilitiarianism. Of course, this is wrong right off the bat; you <strong>cannot</strong> reduce utility to mere "survival" or "good" (whatever that means) or "happiness" or anything so simple-minded. If you could then morality would already have been solved centuries ago as opposed to being a great unresolved problem. [rk]
      </p>
      <hr/>
      <p>
        Survival has degrees.  You can survive by "just staying alive" or by living in a castle with your Rolls Royce collection.  Survival is the one thing all levels of life have in common, from pond scum, to trees, to ants, to dogs, to people.
      </p>
      <p>
        I'm not using it in its "just barely living" sense.  I'm using it more in the sense of "to live successfully and flourish" which would be awkward in sentences.  Survival includes quality of life.  You may prefer a different word, but trying to find a perfect word would be a <a href="RedHerring.html">RedHerring</a>.
      </p>
      <p>
        The words "good" and "bad" and "right" and "wrong" are not absolutes in this context (see "not an absolute" above) but are matters of degree.  Some things can be more right than others.  Some things may peg the meter but most will fall somewhere in the middle.
      </p>
      <p>
        An example of <strong>death</strong> being preferable to <em>living</em> is not a contradiction with optimum <em>survival</em>.  Many men have chosen to die that others might live.  Their decision is calibrated toward a greater good than "just me."
      </p>
      <p>
        There is no attempt to imply that the systems in question are not complex.
      </p>
      <p>
        I think you would agree (based on your other writings) that it's a bad idea for an individual to prosper at the expense of the rest of the individuals.  Likewise that it's a bad idea for a person or group to prosper at the expense of the encompassing ecosystem.
      </p>
      <p>
        My proposition is an attempt to present, without a bunch of buzzwords or appeals to authority, the minimum requirements for the axioms of morality.  Nothing in the proposition implies that we exist to "stay alive" or "only serve the community."
      </p>
      <p>
        You think public schools are bad.  Why?  Because they do more harm than good.  Harm in what scope?  The scope of "civilization" or "family" or "Mankind?"  If it offends the individual and benefits civilization, is that bad or good?
      </p>
      <p>
        You write insulting diatribes.  I find them offensive, and this would not surprise you.  Why do you do that?  Because you believe some greater good is served by kicking my teeth in verbally so that either I will stop thinking my way and think your way, or at least I'll quit telling people what I think where you can see it.  I don't think that's in my personal best interests.  You either think it is, or think that my best interests are irrelevant because you are serving some greater good.  What you write will probably offend someone else, too, and that won't matter because your end, whatever it is, justifies your means.
      </p>
      <p>
        If you imagine you are doing something good (necessary, required, advisable, desirable) then you clearly believe that the greater good is worth more than my personal sense of well-being.  If you imagine you are doing something bad and want to be as destructive as possible, then you would, of course, be a sociopath or pyschopath.  Benefit of the doubt would mean that you are trying to accomplish what you deem to be the greatest good within your most relevant scope.
      </p>
      <p>
        My point is that morality should be a tool to calibrate conduct in the direction of the greatest benefit within the greatest relevant scope.
      </p>
      <p>
        I don't think you can muster an argument -- an actual logically developed proposition -- that refutes this.
      </p>
      <p>
        You will notice that in my proposition, I didn't invoke anyone else's work.  No appeal to authority.  I wanted my proposal to stand on its own merits.
      </p>
      <p>
        Telling me I'm stupid is not a refutation.  Telling me my reasoning is "obviously flawed" or my choice of terms "dubious" is not a refutation.  Saying I'm obsessed is not a refutation.  If you have something better to propose, something that can be read for its own content without appeal to authority or arrogance, something more than a list of buzzwords, then let's see it.
      </p>
      <p>
        -- <a href="GarryHamilton.html">GarryHamilton</a>
      </p>
      <p>
        If you wish to discuss moral philosophy, then learn some of the <strong>technical terms</strong> used in it. It's not my job to dumb everything down so you can understand it. If you had asked nicely for an explanation then I would have provided one, but contrary to your supposition, it's not my life's quest to prove your ignorance to you. If you wish to be taken seriously on this subject, you should use <strong>precise</strong> terms (which so far you have strenuously avoided), and expect the subject to become very complex very quickly. I didn't start this page to explain the flaws in theories of morality which have been abandoned by philosophers decades ago.
      </p>
      <p>
        My criticism holds:
      </p>
      <p>
        You're trying to reduce people's utility to some simplified concept of "good", which is dubious at best (ie, known to be impossible). First you used "survival" now you've broadened it to "success", neither of which are acceptable. (The proper <em>technical term</em> is "utility" and it is understood as making <em>no preconceptions</em> about what a person desires.) Then you claim that this "good" is universal, when it's nothing of the kind, so you can aggregate the resulting simplified utility functions into a global utility function, thus rescuing utilitarianism. And all this you do with handwaving arguments and a righteous refusal to use (or learn?!) accepted technical terms.
      </p>
      <p>
        Utilitarianism is hopeless. If it could be rescued, philosophers would have done so long, long ago. Just because you're trying to create an intuitive "minimal" morality doesn't mean your intuition is good enough to get the job done. Just because people have an instinctive bent for Utilitarianism doesn't mean it can actually be turned into a proper morality. -- rk
      </p>
      <hr/>
      <p>
        So, I take it then that you <em>don't</em> have something better to propose.  And you can't put it here on this page because mere mortals don't have the intellect to grasp it without extensive study, making it the province of an elite.  <em>Sorry, access denied, you're not smart enough to understand [topic], and neither is anyone else as dumb as you are, so you'll have to just gaze longingly at the jargon we use in terse snippets and just trust that we, the custodians of wisdom, will look after it for you.</em>
      </p>
      <p>
        You didn't get what I wrote, so you slapped a buzzword label on it and discounted it as hopeless.  You don't know how to formulate a simple, understandable explanation of morality, so you kissed that off as something requiring specialized study.
      </p>
      <p>
        My proposition stands until you submit something better.  I don't have any particular ego on this.  I want a compact, usable definition that can be applied in life.  Don't even start with that "well, it's just too complex" varnish.  It's not complex to me, and I rather imagine it's not complex to a number of the other readers.  Arrogance buys you nothing.  I'm calling your bluff.  Show me.  Show the other readers.  Do you have the goods or not?
      </p>
      <p>
        -- <a href="GarryHamilton.html">GarryHamilton</a>
      </p>
      <p>
        :) Your grandstanding is almost endearing, given how I do something similar on physics. (With the crucial differences that I'm not afraid to learn the physics terminology, that my accusations have a lot more precision and substance, and that physicists have less reason to be excused than philosophers.)
      </p>
      <p>
        "greatest good for the greatest number" huh? Well how do you deal with the scenario of a large (perhaps even infinite) number of sadists who desire to torture an innocent person to death? Being unable to handle this scenario correctly is only the most obvious of the many grievous flaws of Utilitarianism.
      </p>
      <p>
        See Killing For Trivial Gains (<a href="http://www.geocities.com/Athens/Olympus/2178/killing.html).">http://www.geocities.com/Athens/Olympus/2178/killing.html).</a> Actually, there's several papers on that site you should read up on as intro material. -- rk
      </p>
      <hr/>
      <p>
        You give no context.  Any context I propose is unlikely to be acceptable.  What I said does not equate to "greatest number" except as a reference to encompassing scope.  I'm sure there is a system of mathematics that could express the above scenario as vectors.  Of course without a context it would be meaningless.
      </p>
      <p>
        Is the entire universe made up of sadists?  Clearly not.  How large a "relevant scope" are you willing to allow?
      </p>
      <p>
        We could, I suppose, allow this to degenerate into a discussion of "why Garry is wrong" but I don't see that this benefits any audience beyond Garry and his critic.  I kind of had this impression that there was supposed to be some more general interest served.
      </p>
      <p>
        I had presumed we were trying to nail down morality.  Maybe that's not the case?
      </p>
      <p>
        Somebody famous (Einstein?) once said, "You do not understand something unless you can explain it to your grandmother."
      </p>
      <p>
        My explanation, even as naive as it is, passes the grandmother test (and the eight-year-old test).
      </p>
      <p>
        If the rest of the readers of this page are all accomplished philosophers who congregate here to rub one PhD thesis against the other, then I humbly apologize for intruding on your august congress.
      </p>
      <p>
        Otherwise, perhaps there is someone who can formulate a lucid proposition that covers the ground without too much academic mysticism?
      </p>
      <p>
        -- gh
      </p>
      <p>
        The context is irrelevant because such behaviour is immoral regardless of context. It's immoral whether there's a single sadist involved, a thousand, a billion or even an infinite number of them. You haven't provided any justification (and you won't because there isn't any) why there should be a threshold number of sadists beyond which torture becomes a moral activity. Same thing for their enjoyment of it. Whether it's a one-time marginal enjoyment, or whether the sadists get orgasmic pleasure from it for the rest of their infinitely long lives, there is no threshold enjoyment (or combination number of people * enjoyment) beyond which gratuitous torture of an innocent person is moral. I provided all the context necessary and you wasted the opportunity to defend your position (perhaps because you now realize it is indefensible).
      </p>
      <p>
        We're not trying to "nail down" morality here, but to provide a <strong>rigorous</strong> basis for it. That's why the title of the page is <strong>Axiomatic</strong>Morality. So while it's not necessary to be a philosophy PhD to help on this page, it would help to actually be interested in its stated subject. -- rk
      </p>
      <p>
        Oh, don't worry, I would never attempt such a justification.  The idea of sadism being moral is patently silly.  The trouble is, you do, in fact, need a context.  In the absence of a context, "sadism is bad" becomes an arbitrary opinion.  <em>Why</em> is sadism bad?  Because it offends God?  I seem to recall that, from your point of view, this is not a valid argument.
      </p>
      <p>
        Why should I attempt a justification for sadism?  It would take an absurdly contrived scenario.  Having a million bad guys doesn't make a bad idea good.  Asking me to prove it's good is ridiculous.
      </p>
      <p>
        So, why is it bad?  Because you think suffering is a bad idea?  Because you have the math that shows this will destroy the universe if it's extrapolated?  Because some guy who wrote a book said so?  If you believe there is some "absolute" at work, then no discussion is required, it becomes that way because you declare it.
      </p>
      <p>
        If I say that it's bad because it introduces vectors that reduce survival in a greater context, then you get to pick at what I mean by "vector" or "context" or "survival" or whatever, since it doesn't map to your "technical" terminology.  And that way you get to continue avoiding saying anything meaningful.  So be it.
      </p>
      <p>
        Suddenly I find myself uninterested in pursuing this, at least with you.  I can't foresee any useful content developing.  You continue to spout bilge while alleging that you seek "rigor" and that one must "actually be interested" to participate.  Why don't you wait here for some of your elite buddies to come along to hash it out with you.  It will be interesting to watch and see what you believe is "rigor" in defining morality.  Oh, and make sure you lambaste my "ignorance" or "immaturity" or whatever you feel will make you feel the most superior.
      </p>
      <p>
        I'm done with this. -- gh
      </p>
      <p>
        Good. Now can we move this irrelevant and acrimonious discussion elsewhere; another page if not off wiki entirely? [done] -- rk
      </p>
      <hr/>
      <p>
        Every so often my mind returns to the scene of the crime.
      </p>
      <p>
        Aggregate?  No.  Nobody said anything about aggregation.  Greatest good is not something as childish as (num_people * effect).  Greatest good is not some club you beat people with.  It is a guiding principle.  For the individual.  Morality is not a group thing.  Morality fails to the degree it is "adopted" by groups, especially with any accompanying enforcement.
      </p>
      <p>
        Groups can't think.  Or rather, shouldn't.  Resulting vectors always tend to be biased toward the only thing groups have in common:  their frailties.
      </p>
      <p>
        Morality (that set of "best practices" of conduct) is only really valid when practiced by the individual.  It's the principle that governs decisions, especially those affecting more than just one's self.  It's an effort to extrapolate eventual effects from one's causes, and to temper one's causes and direct them such that these effects have the greatest benefit-to-harm ratio.
      </p>
      <p>
        Of course, it's subject to GIGO <em>(</em><a href="GarbageInGarbageOut.html">GarbageInGarbageOut</a>)<em>, but if the </em>intent<em> is not destructive, eventually the bad data can be purged.</em>
      </p>
      <p>
        -- <a href="GarryHamilton.html">GarryHamilton</a>
      </p>
      <p>
        Morality is a group function, <em>by definition</em>. A morality is a set of rules governing the interrelationships between members of a society.
      </p>
      <p>
        And what is "the greatest benefit-to-harm ratio" supposed to mean if it does not mean anything specific like num_people * effect?
      </p>
      <p>
        The problem of course, is you're trying to reach for an incorrect conception of morality. But you know that every time your hand reaches out for it, it either gets burned or I'll slap it away. That's why you're constantly trying to reach for the specific ("greatest good for the greatest number", "greatest benefit-to-harm ratio") then pulling back into the vague and general ("guiding principle", "not something as childish as ...").
      </p>
      <p>
        You have to stop trying to reach for Utilitarianism (just accept for the moment that this is the name of the bush you're constantly beating around) and consider something radically different. Like Human Rights and Rawlsian Morality. -- rk
      </p>
      <hr/>
      <p>
        Good luck trying to get a group to agree on a workable morality.  Or perhaps you figure you can just impose this workable morality from your position of authority?  Legislate it?  Good luck, dude.  You're gonna need it.
      </p>
      <p>
        Man, Richard, you just don't get it.  All your mind seems to do is "snap to grid" on something you read in a book.  I keep giving you credit for more perception than you evidently employ.  I know it's really tough on you when I insist on using simple English words whose meanings are not distorted by some pathological effort to jargonize.
      </p>
      <p>
        And then, gripped by whatever your passions are, you don't seem to be able to just talk about what you believe is the right way to frame this; you lash out and fall back on the "I can't possibly be wrong!  I already know all the important stuff!" reasoning (?) and spout more jargon.
      </p>
      <p>
        I'm always suspicious of arguments that can't be expressed in plain English.  It's nearly always a sign that the arguer either doesn't have a firm grip on the concept or is just lazy.
      </p>
      <p>
        <em>Or perhaps a sign that the argument is being held by educated people.  Often abstractions etc. require new terminology.  You can't expect to learn in a few minutes what others have spent years on.  Almost nothing of intellectual complexity can be discussed in a lowest common denominator fashion.  This doesn't mean that uneducated people can't be involved; it just means it will take longer (perhaps a great deal), and that part of the discussion will have to be education in foundations.  Your statement flies in the face of reason.  Or perhaps it is simply too strong.  If you really understand something, regardless of complexity, you should be able to explain it to some degree in very simple language.  However, the "some degree" may be quite limited, and for detailed discussion this becomes impossible.</em> -- 65.93.96.123
      </p>
      <p>
        Just for fun, I'm going to read some Rawls.
      </p>
      <p>
        I hope he has something worthwhile to say, cuz you're doing a piss-poor job.
      </p>
      <hr/>
      <p>
        In response to 65.93.96.123 above:
      </p>
      <p>
        Now, looka here, you, don't go muddying the waters with a bunch of rational discourse!  Stop making sense!  (I'm quite well aware that nomenclature is necessary.  I can even grasp it, sometimes.)  You're right, of course, my statement is too strong, but remember, I'm having a conversation with someone for whom hostility seems to be the only operational wavelength.
      </p>
      <p>
        One of the characteristics of hostility is an inability to deal in truth.  In fact, a hostility case will deny that such a thing even exists, and argue himself ashen in defense of that position.  Mind you, when the "truth" can be used to brutalize or emotionally maim, then, of course, one is <em>obliged</em> to tell the truth.
      </p>
      <p>
        I'm sort of hoping that someone who's not afraid to talk with an amateur will step in and create an actual forum, but with an anger case in the room, that may never happen.
      </p>
      <p>
        I may be short on "accepted" terminology, but I learn fast.  One of the reasons I balk at jargonistic obfuscation is that, over and over in my career I've found that some "new" idea (with a new label) is simply an old idea repainted.  Once I get it ("Oh, is <em>that</em> all they're doing!") I can adopt the nomenclature as appropriate and converse with its subscribers.
      </p>
      <p>
        However, I never, <em>never</em> hold my understanding over someone else as the measure of my superiority, using the buzzwords as bricks to pummel their tiny, inadequate brains into submission.  That's a tool for people whose control mechanism requires the nullification of all perceived opponents.
      </p>
      <p>
        If you have some actual signal for this discussion, it would be the first I've seen beyond my own pathetic mental meanderings.
      </p>
      <p>
        I don't know why I would have thought that more than a decade of in-your-face involvement with real people in real rehab and educational situations would qualify me for any part of a discussion of what might be a valid approach to morality.  Perhaps I should have spent my time reading about it from a distance.  I tend to forget that anecdotal "evidence" is the first thing to be discarded in academic discussions.
      </p>
      <p>
        Oh, my, I seem to be ranting.  Well, 65.93.96.123, please be not offended.  If you wish to help illuminate the subject, by all means do.  That would at least make two of us.
      </p>
      <p>
        -- <a href="GarryHamilton.html">GarryHamilton</a>
      </p>
      <p>
        I suppose it's quite narcisistic of me to like you since your style of argument here reminds me so much of my own. :)
      </p>
      <p>
        The reasons why I don't want to explain everything from the ground up are many-fold. Chief among them is that I am lazy. On the heels of that is that I don't have that firm a grasp on the subject.
      </p>
      <p>
        I could learn what Rawls has to say about it but since I already know that some of his key arguments are fatally flawed, I would be lying if I repeated them to someone who couldn't understand the flaws. And if you did understand their flaws, you'd hardly find them convincing.
      </p>
      <p>
        And given how tedious and unsatisfying Rawls is to me, I'm more interested in going at the problem on my own. I don't have a good enough grasp on the subject to explain it to someone <em>to my own satisfaction</em>, just enough of a grasp of the framework involved to try to work on it a little. (The only thing I retain from Rawls is most of his assumptions and goals, not the arguments in between.)
      </p>
      <p>
        Btw, terminology in philosophy tends to be essential to it. I have discussed philosophy before knowing the proper terminology and it's a lot easier when you have terms like 'qualia' or 'reflective equilibrium' to refer to concepts you couldn't place a name to before. Learning the terminology is an excellent reason to read <a href="TheoryOfJustice.html">TheoryOfJustice</a>. -- rk
      </p>
      <hr/>
      <p>
        This page stands as evidence for the claim that "to every complex problem there exists a solution that is at once simple, obvious, beautiful, and completely wrong." --<a href="JamesDennett.html">JamesDennett</a>
      </p>
      <hr/>
      <p>
        <a href="CategoryPhilosophy.html">CategoryPhilosophy</a>
      </p>
    </div>
  </body>
</html>