<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <base href="/mount/ultralaser_home/Projects/c2_wiki_recovery/out/">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
  </head>
  <body>
    <div class="page">
      <h1>
        <img src="wiki.gif" />
        Two Dimensional Rendezvous
      </h1>
      <p>
        From <a href="AlgorithmsWanted.html">AlgorithmsWanted</a>:
      </p>
      <p>
        Suppose you have a collection of points in a two dimensional space. Given another point, just how fast can you find the closest one from the set?
      </p>
      <p>
        Obviously you can do it in <strong>O(n)</strong> just by scanning through them all, applying the metric, and keeping the closest. However, if you're going to do this lots of times, maybe you can precompute something and do the search more quickly.
      </p>
      <p>
        Good things:
      </p>
      <ul>
        <li>
           you may be comparing another set against the original set, allowing some commonality of calculation.
        </li>
      </ul>
      <p>
        Bad things:
      </p>
      <ul>
        <li>
           The points in the original set may move.
        </li>
      </ul>
      <hr/>
      <p>
        Consider <a href="EuclideanProximitySearchEngine.html">EuclideanProximitySearchEngine</a> (generalizing up to N-dimensional space). A "movement" in this case would consist of removing the old point and adding the new one, perhaps lazily. That page also discusses finding points nearest to a line, a plane, a volume... and performing simple transforms on the dimensions (e.g. giving distance in one dimension more or less relevance than distance in another dimension).
      </p>
      <hr/>
      <p>
        I think you need to be more specific (including "how often do they move?"); there is a vast literature on nearest neighbor and clustering algorithms, which are critical in any number of fields, such as neural net applications (e.g. radial basis vectors in e.g. OCR) and physics simulation (e.g. collision detection).
      </p>
      <p>
        Note also "Why so many clustering algorithms: a position paper" <a href="http://portal.acm.org/citation.cfm?id=568575&dl=ACM&coll=GUIDE">http://portal.acm.org/citation.cfm?id=568575&dl=ACM&coll=GUIDE</a>
      </p>
      <p>
        clustering algorithms overview
        <a href="http://genome.imim.es/~eblanco/seminars/docs/clustering/index_types.html">http://genome.imim.es/~eblanco/seminars/docs/clustering/index_types.html</a>
      </p>
      <p>
        An Analysis of Recent Work on Clustering Algorithms
        <a href="http://citeseer.ist.psu.edu/fasulo99analysi.html">http://citeseer.ist.psu.edu/fasulo99analysi.html</a>
      </p>
      <p>
        -- <a href="DougMerritt.html">DougMerritt</a>
      </p>
      <hr/>
      <p>
        Divide your space into boxes. Add a point to the box it is in. Nearest point will be in the same box or a nearby one. There are more complex schemes that rest on this basis.
      </p>
      <p>
        If the volume is too large, and the points cluster, then the problem resists this approach in its simplest form.  Sometimes you can't have a predetermined set of buckets.  QuadTrees look better, but is there another approach.
      </p>
      <p>
        Sometimes there is no good size of grid to use - lots of grid points means too much memory, not many grid points means everything is close to the same grid point.
      </p>
      <p>
        The question concerns the zillions of grid points idea.  how do you avoid the overhead of grid points with no data points nearby.
      </p>
      <p>
        <strong></strong>QuadTrees<strong></strong>
      </p>
      <p>
        I think you might want something like QuadTrees. See Google for lots of references, including <a href="http://www.ics.uci.edu/~eppstein/gina/quadtree.html.">http://www.ics.uci.edu/~eppstein/gina/quadtree.html.</a> In particular, this:
      </p>
      <dl>
        <dt> </dt>
        <dd>"Encoding astronomical coordinates with quadtrees can provide significant improvements in efficiency when accessing sources near a given direction and can aid in the correlation of positions from different astronomical catalogs."</dd>
      </dl>
      <p>
        looks quite close to your problem as described above.
      </p>
      <p>
        The idea would be to severely restrict the number of points you actually had to look at by looking at regions increasingly close to your point - at this point you only need to know if the segment is empty or not. Once you get "close enough", switch to the linear search through the points you've located. What's "quicker" depends on the density distribution of your points. If you're really lucky (i.e. have a "nice" distribution), you'll get down to just one point in the first part...
      </p>
      <hr/>
      <p>
        Where's the time go now? Is it driven by the number of points, or the complexity of your distance metric? If the former, you're going to have to do something to reduce the points looked at - which suggests something like QuadTree. If the latter, can you use an approximation initially?
      </p>
      <p>
        What about precomputing distances from each point to all points on a grid/lattice - keep a distance-sorted list of data points for each grid point, then using the nearest grid point to the point of interest to quickly discard (binary chop?) most points from consideration?
      </p>
      <p>
        <strong>Hmm.. actually, you can precompute what to discard. Any point that's further away than the next grid point in that direction (ish, I hope you see what I mean), can't be the nearest point. So, the lists are of "nearish" points that are worth examining. So I think this is the same as a </strong>QuadTree, with the points attached to the smallest subdivision. See below<em>.</em>
      </p>
      <hr/>
      <p>
        <em>Does the distribution vary over time, or is it pretty static (for a given run)? If so, you could have a non-linear grid that's more dense where the points are more dense. This I think means an adaptive quad tree, with more subdivisions where the points are dense. I'm sure there are algorithms for this</em>
      </p>
      <p>
        <em>And yes, google searches for "Adaptive Quadtrees" get hits. This looks relevant </em><a href="http://www.science.gmu.edu/~aantunes/tree.html.">http://www.science.gmu.edu/~aantunes/tree.html.</a> Sounds like it's worth talking to your local astrophysics department<em></em>
      </p>
      <hr/>
      <p>
        <strong></strong><a href="DelaunayTriangulation.html">DelaunayTriangulation</a><strong></strong>
      </p>
      <p>
        Another sort of approach is to maintain a <a href="DelaunayTriangulation.html">DelaunayTriangulation</a> of the pointset. To find the existing point closest to a new point, add the new point to the triangulation. The closest point will share an edge with the new point.
      </p>
      <p>
        A <a href="DelaunayTriangulation.html">DelaunayTriangulation</a> can be built in O(NlogN) time, and insertions can be done in (amortized?) O(logN) time.
      </p>
      <p>
        For other ideas, look to the GIS literature, for example <a href="http://citeseer.nj.nec.com/al-daoud95applying.html">http://citeseer.nj.nec.com/al-daoud95applying.html</a>
      </p>
      <p>
        In general, you want the *dual* to a Delaunay triangulation: a <a href="VoronoiDiagram.html">VoronoiDiagram</a>. A Voronoi diagram is a set of (possibly unbounded) polygons that cover the plain. Each of your original points is in exactly one polygon, and that polygon is the set of points closest to that original point.  
      </p>
      <p>
        And please use someone else's Delaunay code. It can be horribly tricky to get right, especially with floating-point coordinates. There's plenty of code out there; I'm partial to Jonathan Shewchuk's triangle. Don't underestimate the difficulty of getting a *correct* answer to a "nearest neighbor" query. In many apps, absolutely correct isn't too important, but in some it's critical.
      </p>
      <hr/>
      <p>
        All good ideas. What about the efficiency of the triangulations given that the points can move.  Adding points to a <a href="DelaunayTriangulation.html">DelaunayTriangulation</a> is so icky to code ...
      </p>
      <hr/>
      <p>
        <strong>1 dimensional sorting</strong>
      </p>
      <p>
        Here's an algorithm that might possibly be the <a href="SimplestThing.html">SimplestThing</a> that could possibly work.
      </p>
      <p>
        Instead of scanning every point in the list,
        sort the list by X coordinate,
        find the point in the list with the closest X coordinate,
        and scan left and right from that point.
        Then exit early as soon as you hit points where the X coordinate alone is
        further away than the closest point you've seen so far.
      </p>
      <p>
        Setup:
      </p>
      <ul>
        <li>
           Add 2 extra "dummy" points to your set: one with x,y = -inf, the other with x,y = +inf.
        </li>
        <li>
           Make a list A of all n+2 points in the set, sorted by X position.
        </li>
      </ul>
      <p>
        (If the set is very tall and skinny, perhaps better to sort by Y position).
      </p>
      <p>
        Find closest point in the set to point P:
      </p>
      <ul>
        <li>
           ASSERT( there are at least 3 points in the list A).
        </li>
        <li>
           Set L and R and M to the index of the point with the closest X position. O(log n)
        </li>
        <li>
           set dL = dR = dM = distance( P, A[L] )
        </li>
        <li>
           set Lx = abs(P.X - A[L].x)
        </li>
        <li>
           set Rx = abs(P.X - A[R].x)
        </li>
      </ul>
      <code>
        // Loop invariants:<br/>
        // M is the index of the the closest point we've seen so far.<br/>
        do{<br/>
        // Is L or R closer to P, in the X direction ?<br/>
        // (Comparing absolute distance( dL < dR ) is slower)<br/>
        if( Lx < Rx ){<br/>
        // L is closer; scan list to the left<br/>
        L = L - 1;<br/>
        Lx = abs(P.X - A[L].x);<br/>
        dL = distance( P, A[L] );<br/>
        if( dL < dM ){<br/>
        M = L<br/>
        dM = dL<br/>
        }<br/>
        }else{<br/>
        // R is closer; scan list to the right<br/>
        R = R + 1;<br/>
        Rx = abs(P.X - A[R].x)<br/>
        dR = distance( P, A[R] );<br/>
        if( dR < dM ){<br/>
        M = R<br/>
        dM = dR<br/>
        }<br/>
        }<br/>
        }while( (Lx < dM) or (Rx < dM) );<br/>
      </code>
      <p>
        Looks like I need a <a href="OnceAndOnlyOnce.html">OnceAndOnlyOnce</a> refactoring of the commonality between the 2 branches of that if().
      </p>
      <p>
        It's pretty easy to come up with pathological cases where this algorithm
        searches all N points, O(n), but I think for evenly distributed points it runs for O(n^(1/2)) (Is that right ?).
        Not quite as good as O(log n), but far better than O(n).
      </p>
      <p>
        -- <a href="DavidCary.html">DavidCary</a>
      </p>
      <hr/>
      <p>
        <strong>two dimensional sorting</strong>
      </p>
      <p>
        Is it possible to make two-dimensional <a href="SkipList.html">SkipList</a>s ? <em>I don't think so, I tried to come up with an algorithm some time ago, but failed. But it would be great wouldn't it?</em> -- <a href="GunnarZarncke.html">GunnarZarncke</a>
      </p>
      <p>
        See
        "sorting algorithms for two dimensional arrays" at the bottom of <a href="SortingAlgorithms.html">SortingAlgorithms</a>. "<a href="BrokenLink.html">BrokenLink</a>" - can't find the link in that page.
      </p>
      <p>
        See <a href="TwoDimensionalRangeQuery.html">TwoDimensionalRangeQuery</a>
      </p>
      <hr/>
      <p>
        <a href="CategoryAlgorithm.html">CategoryAlgorithm</a>
      </p>
    </div>
  </body>
</html>