(A simple analysis of why EgalitarianCompensation is destined to result in less productivity and cheating using my limited knowledge of GameTheory) -- BillCaputo
----
(quoted from EgalitarianCompensation)
''* This is how the US Army conducts the Ranger training. Squads of 10-13 "rate" everyone on the team in numerical order from best to worst. The lowest 2-3 people get "peered out". This occurs in each of 4 training phases, which take place in Florida, Georgia, and Utah. It can be circumvented in at least 2 ways. The first is if part of the team is already a cohort, for (a real) example, 10 cadidiots from West Point in a team. The second is by the team agreeing to a circular rating, where everyone in the team cooperates to ensure that all ratings total identically. I know this because my ranger buddy (class 14/89) was peered out on the first scenario, then taught the second to us in the class he joined later! So overall, peer rating is a good idea, but not a silver bullet. ''
----
The circumventions mentioned for peer ranking while discussing the Ranger Course example  in the EgalitarianCompensation discussion (requoted for convenience above) prompted me to look at this from a Game Theory perspective. There is a binary payoff in the Ranger course example, so I used that here for simplicity.

My conclusion: The highest overall utility for each individual comes from cooperating (i.e. cheating).

Here are some simple matrices:

1) when you will '''not''' get the payoff (i.e. the vote will go against you) on an honest vote:

					rest of the team

				honest	|	cohort	|	team
		-------------------------------------------------------
		honest	|	0	|	.5	|	1
	y	-------------------------------------------------------
	o	cohort	|	0	|	.5	|	1
	u	-------------------------------------------------------
		team	|	0	|	.5	|	1

If everyone else is honest, you get no payoff. If a cohort (a clique or partial voting block) forms, I modelled it as a 50/50 chance (in or out) of getting the payoff. If a team vote (or total voting block) forms, you get the maximum payoff. Note that none of these are based on how '''you''' vote -- only on how the rest of the team votes.

2) when you '''will''' get the payoff (i.e. you would get voted in) on an honest vote:

					rest of the team

				honest	|	cohort	|	team
		-------------------------------------------------------
		honest	|	1	|	.5	|	1
	y	-------------------------------------------------------
	o	cohort	|	1	|	.5	|	1
	u	-------------------------------------------------------
		team	|	1	|	.5	|	1

If  everyone else is honest you get the payoff. If a cohort forms, its 50/50 whether you will be a part of it and so get the payoff, if a complete voting block forms you will get the payoff. Again your actual vote has no effect on the outcome.

So, one's own vote does not affect one's own outcome. That is only affected by the the others' vote.

However, one can choose to encourage the team toward honesty or cheating '''before''' the actual vote.

Thus, if you are not doing well, your best chance to get voted in is to encourage cheating (i.e. campaign for a voting block to form with you in it), because otherwise you have no chance of getting the payoff.

OTOH if you are destined to get the payoff via honesty, then encouraging cheating holds no advantage for you -- except that it leaves open the possibility that a partial block could form '''against''' you, thus making the only sure strategy (if you suspect potential cooperation) is to ensure one is in it. I am guessing this explains the motivation of the Ranger Buddy mentioned in the anecdote referenced above.

We can further assume that you would only be honest if you weren't in a voting block (either through ignorance or morality), so we can simplify:

1) when you will '''not''' get the payoff on an honest vote:

					rest of team

				honest/clique	|	team
		--------------------------------------------
	y	honest	|	.25		|	1
	o	--------------------------------------------
	u	cheat	|	.5		|	1


2) when you '''will''' get the payoff on an honest vote:

					rest of team

				honest/clique	|	team
		--------------------------------------------
	y	honest	|	.5		|	1
	o	--------------------------------------------
	u	cheat	|	.75		|	1

IOW if you cheat its probably because you feel that the team vote is going to cheat in your favor, so I weighted the odds in your favor to account for your campaigning.

Thus there is a strongly dominant strategy for the individual to cheat, and for the team to vote for the team. (To get more accurate, we would need to weigh in the effort needed to campaign for a complete (team) vote vs. a clique (partial vote).

In short, this system seems to encourage cheating no matter what (according to my admittedly somewhat limited game theory knowledge) :-)

Note too that this '''doesn't''' necessarily encourage cooperation on the task the group is assigned to do -- the cooperatoin is only in regard to scoring. 

Thus, my feeling is that this wouldn't be a good compensation strategy for a team for very long -- at best it would work until the team became aware of the optimal strategy (game theory assumes optimal play).

What's even worse, is that because it doesn't say anything about collaborating for the work produced, but only during the evaluation, it will in the long term have a bad effect on productivity (assuming that people will be content to ''appear'' to work, because they won't ''actuall have'' to work to get the payoff). 

Now to truly analyze this as a compensation strategy we would have to analyze this as a Repeating Game since the knowledge of how voting occurred last time will affect the likelihood of voting a certain way the next time. This would involve introducing the possibility that threats, deterrents, reputation and brinksmanship would all play a role. However, I think the fact that each iteration has the same strongly dominant strategy, makes it likely that over enough iterations, the game would settle into the equilibrium of everyone cooperating (i.e. cheating).

This would also imply that this type of compensation has the best chance in classroom environments (including Ranger courses) when the group doesn't have time to learn the system, or to learn to trust one another (and there is only one vote). 

Finally, Notice that the Ranger Buddy optimized in just 2 iterations.

For those interested, here is a glossary of common Game Theory terms: http://www.agsm.unsw.edu.au/~bobm/teaching/SET/glossary.html

----
Contributers: BillCaputo
----
See also: CompensationGame EgalitarianCompensation
----
CategoryAnalysis CategoryGame
