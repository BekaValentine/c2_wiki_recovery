Under Construction. This will be to clear up some repeated misconceptions about my view of "good evidence". --top

----

Let's categorize evidence into three categories:

* Theoretical evidence

* Empirical evidence

* Experiential Evidence ("like')
** Personal Preference
** Popularity

Ideally, a given tool/methodology will score well in all three. It is not proper to call a tool "good" if it only scores in one category.

--top

''Personal evidence is not the same as popularity. Someone can personally claim that a tool is wonderful in a niche, even if it is not popular. An example would be someone who personally prefers table oriented programming tools that they hand crafted, which not many people use yet. They personally recommend these tools since they have had luck with it. They can even provide good examples. But popularity on the other hand doesn't equate to "personal evidence". Popularity is "numbers of people", not personal.''

Fair enough. I've made adjustments to the list.

------------------

'''Burden of Thoroughness'''

If one uses rigorous metrics to create or promote a tool, that still is not enough to claim "net better" because the "net" portion has not been rigorously demonstrated. The existence of a given metric against tool Y is not sufficient proof to say that X is net better than Y just because there is currently insufficient rigor for Y or against X.

It's true that it's unrealistic to expect somebody to measure something via every possible metric because we cannot know if we exhausted all metrics. However, some kind of approach or survey for identifying the thoroughness of metrics that have been provided would need to done. To obtain "net" in "net better", the claimer has the burden of showing the provided metrics are relatively thorough. Perfectly thorough is probably unobtainable, but sufficiently thorough is. 

True, there may always be disagreement over how thorough the given metrics are and it may involve subjective judgment. But a list of evidence that uses a large quantity and wide variety of metrics will have a better reception than a small or uniform list metrics.

--top
